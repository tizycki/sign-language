{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "from utils.data_augmentation import rotate_keypoints_sequence\n",
    "from utils.keypoints import read_keypoints, rescale_keypoints, keypoints_sequence_padding\n",
    "\n",
    "from model.datasets import SequenceKeypointsDataset\n",
    "from model.transforms import RotateKeypointsSequence, KeypointsSequencePadding\n",
    "from model.models import SequenceRecognitionNet\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_FILES_PATH = [\n",
    "    './data/labels/sequence/sequence_labelsSep-16-2020_0516.json',\n",
    "    './data/labels/sequence/sequence_labelsSep-16-2020_1930.json',\n",
    "    './data/labels/sequence/sequence_labelsSep-18-2020_0447.json'\n",
    "]\n",
    "JSON_KEYPOINTS_BASE_PATH = './data/keypoints'\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "N_EPOCHS = 3000\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.00001\n",
    "\n",
    "LABEL_OCCURENCES_MIN = 10\n",
    "SEQUENCE_LENGTH_MAX = 50\n",
    "NUM_CLASSES = 11\n",
    "\n",
    "# label_map = {\n",
    "#     'Meet': 0,\n",
    "#     'Name': 1,\n",
    "#     'Hearing person': 2,\n",
    "#     'Good day': 3,\n",
    "#     'You': 4,\n",
    "#     'See you around': 5,\n",
    "#     'Thank you': 6,\n",
    "#     'Hello': 7,\n",
    "#     'Bye bye': 8,\n",
    "#     'Tom': 9,\n",
    "#     'Woman': 10,\n",
    "#     'Nice': 11,\n",
    "#     'Man': 12,\n",
    "#     'I': 13,\n",
    "#     'My': 14\n",
    "# } \n",
    "\n",
    "label_map = {\n",
    "    'Meet': 0,\n",
    "    'Name': 1,\n",
    "    'Good day': 2,\n",
    "    'See you around': 3,\n",
    "    'Thank you': 4,\n",
    "    'Hello': 5,\n",
    "    'Bye bye': 6,\n",
    "    'Tom': 7,\n",
    "    'Nice': 8,\n",
    "    'I': 9,\n",
    "    'My': 10\n",
    "} \n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_path</th>\n",
       "      <th>image_path</th>\n",
       "      <th>keypoints_path</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/rendered_video/internal_resource_fps10/...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>Hello</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/rendered_video/internal_resource_fps10/...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>Hello</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/rendered_video/internal_resource_fps10/...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>Hello</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/rendered_video/internal_resource_fps10/...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>Hello</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/rendered_video/internal_resource_fps10/...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>Hello</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          video_path  \\\n",
       "0  ./data/rendered_video/internal_resource_fps10/...   \n",
       "1  ./data/rendered_video/internal_resource_fps10/...   \n",
       "2  ./data/rendered_video/internal_resource_fps10/...   \n",
       "3  ./data/rendered_video/internal_resource_fps10/...   \n",
       "4  ./data/rendered_video/internal_resource_fps10/...   \n",
       "\n",
       "                                          image_path  \\\n",
       "0  [/home/tom/Desktop/projects/sign-language/data...   \n",
       "1  [/home/tom/Desktop/projects/sign-language/data...   \n",
       "2  [/home/tom/Desktop/projects/sign-language/data...   \n",
       "3  [/home/tom/Desktop/projects/sign-language/data...   \n",
       "4  [/home/tom/Desktop/projects/sign-language/data...   \n",
       "\n",
       "                                      keypoints_path  label  label_id  \n",
       "0  [/home/tom/Desktop/projects/sign-language/data...  Hello         5  \n",
       "1  [/home/tom/Desktop/projects/sign-language/data...  Hello         5  \n",
       "2  [/home/tom/Desktop/projects/sign-language/data...  Hello         5  \n",
       "3  [/home/tom/Desktop/projects/sign-language/data...  Hello         5  \n",
       "4  [/home/tom/Desktop/projects/sign-language/data...  Hello         5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack label files\n",
    "labels_json = []\n",
    "\n",
    "for label_file in JSON_FILES_PATH:\n",
    "    with open(label_file, 'r') as f:\n",
    "        for row in f.readlines():\n",
    "            labels_json.append(json.loads(row))\n",
    "\n",
    "            \n",
    "# Fix labels\n",
    "            \n",
    "# Convert into DataFrame\n",
    "df = pd.concat(\n",
    "    [pd.DataFrame(item) for item in labels_json],\n",
    "    axis=0\n",
    ").drop(columns=['id'])\n",
    "\n",
    "# Drop ignore labels\n",
    "df = df[~df.label.isin(['ignore', '<random movements>', 'My name'])]\n",
    "\n",
    "# Drop low freq classes\n",
    "labels_freq = df.label.value_counts()\n",
    "low_freq_labels = labels_freq[(labels_freq < LABEL_OCCURENCES_MIN)].index.tolist()\n",
    "df = df[~(df.label.isin(low_freq_labels))]\n",
    "\n",
    "df = df[df.label.isin(list(label_map.keys()))]\n",
    "\n",
    "# Get label ID\n",
    "df['label_id'] = df.label.map(label_map)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_path</th>\n",
       "      <th>image_path</th>\n",
       "      <th>keypoints_path</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>./data/rendered_video/internal_resource_2328_f...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>I</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>./data/rendered_video/internal_resource_2334_f...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>My</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>./data/rendered_video/internal_resource_fps10/...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>I</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>./data/rendered_video/internal_resource_fps10/...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>I</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>./data/rendered_video/internal_resource_2328_f...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>I</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>./data/rendered_video/internal_resource_2328_f...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>Good day</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>./data/rendered_video/internal_resource_2334_f...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>Tom</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>./data/rendered_video/internal_resource_fps10/...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>Good day</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./data/rendered_video/internal_resource_fps10/...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>Good day</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>./data/rendered_video/internal_resource_2334_f...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>[/home/tom/Desktop/projects/sign-language/data...</td>\n",
       "      <td>Good day</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            video_path  \\\n",
       "29   ./data/rendered_video/internal_resource_2328_f...   \n",
       "87   ./data/rendered_video/internal_resource_2334_f...   \n",
       "39   ./data/rendered_video/internal_resource_fps10/...   \n",
       "95   ./data/rendered_video/internal_resource_fps10/...   \n",
       "30   ./data/rendered_video/internal_resource_2328_f...   \n",
       "..                                                 ...   \n",
       "25   ./data/rendered_video/internal_resource_2328_f...   \n",
       "232  ./data/rendered_video/internal_resource_2334_f...   \n",
       "27   ./data/rendered_video/internal_resource_fps10/...   \n",
       "16   ./data/rendered_video/internal_resource_fps10/...   \n",
       "66   ./data/rendered_video/internal_resource_2334_f...   \n",
       "\n",
       "                                            image_path  \\\n",
       "29   [/home/tom/Desktop/projects/sign-language/data...   \n",
       "87   [/home/tom/Desktop/projects/sign-language/data...   \n",
       "39   [/home/tom/Desktop/projects/sign-language/data...   \n",
       "95   [/home/tom/Desktop/projects/sign-language/data...   \n",
       "30   [/home/tom/Desktop/projects/sign-language/data...   \n",
       "..                                                 ...   \n",
       "25   [/home/tom/Desktop/projects/sign-language/data...   \n",
       "232  [/home/tom/Desktop/projects/sign-language/data...   \n",
       "27   [/home/tom/Desktop/projects/sign-language/data...   \n",
       "16   [/home/tom/Desktop/projects/sign-language/data...   \n",
       "66   [/home/tom/Desktop/projects/sign-language/data...   \n",
       "\n",
       "                                        keypoints_path     label  label_id  \\\n",
       "29   [/home/tom/Desktop/projects/sign-language/data...         I         9   \n",
       "87   [/home/tom/Desktop/projects/sign-language/data...        My        10   \n",
       "39   [/home/tom/Desktop/projects/sign-language/data...         I         9   \n",
       "95   [/home/tom/Desktop/projects/sign-language/data...         I         9   \n",
       "30   [/home/tom/Desktop/projects/sign-language/data...         I         9   \n",
       "..                                                 ...       ...       ...   \n",
       "25   [/home/tom/Desktop/projects/sign-language/data...  Good day         2   \n",
       "232  [/home/tom/Desktop/projects/sign-language/data...       Tom         7   \n",
       "27   [/home/tom/Desktop/projects/sign-language/data...  Good day         2   \n",
       "16   [/home/tom/Desktop/projects/sign-language/data...  Good day         2   \n",
       "66   [/home/tom/Desktop/projects/sign-language/data...  Good day         2   \n",
       "\n",
       "     length  \n",
       "29       14  \n",
       "87       15  \n",
       "39       15  \n",
       "95       15  \n",
       "30       15  \n",
       "..      ...  \n",
       "25       42  \n",
       "232      43  \n",
       "27       45  \n",
       "16       46  \n",
       "66       48  \n",
       "\n",
       "[546 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'] = df.image_path.apply(lambda x: len(x))\n",
    "df.sort_values(by='length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello             67\n",
      "Thank you         65\n",
      "Good day          62\n",
      "Tom               59\n",
      "Meet              57\n",
      "Name              53\n",
      "My                52\n",
      "Nice              51\n",
      "I                 36\n",
      "See you around    23\n",
      "Bye bye           21\n",
      "Name: label, dtype: int64\n",
      "5     67\n",
      "4     65\n",
      "2     62\n",
      "7     59\n",
      "0     57\n",
      "1     53\n",
      "10    52\n",
      "8     51\n",
      "9     36\n",
      "3     23\n",
      "6     21\n",
      "Name: label_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.label.value_counts())\n",
    "print(df.label_id.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(df_train):\n",
    "    class_sample_count = np.array([len(np.where(df_train.label_id==t)[0]) for t in np.unique(df_train.label_id)])\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in df_train.label_id])\n",
    "\n",
    "    return torch.from_numpy(samples_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "# Create Transformer\n",
    "keypoints_sequence_transform_train = transforms.Compose([\n",
    "    RotateKeypointsSequence(-30, 30),\n",
    "    KeypointsSequencePadding(SEQUENCE_LENGTH_MAX)\n",
    "])\n",
    "keypoints_sequence_transform_test = transforms.Compose([\n",
    "    KeypointsSequencePadding(SEQUENCE_LENGTH_MAX)\n",
    "])\n",
    "\n",
    "# Initialize Datasets\n",
    "ds_train = SequenceKeypointsDataset(df_train, keypoints_sequence_transform_train)\n",
    "ds_test = SequenceKeypointsDataset(df_test, keypoints_sequence_transform_test)\n",
    "\n",
    "# Initialize Sampler\n",
    "sampler = torch.utils.data.WeightedRandomSampler(get_weights(df_train), df_train.shape[0])\n",
    "\n",
    "# Initialize DataLoader\n",
    "train_dl = torch.utils.data.DataLoader(ds_train, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "test_dl = torch.utils.data.DataLoader(ds_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Model params\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = SequenceRecognitionNet(NUM_CLASSES).to(DEVICE)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hello             56\n",
       "Tom               51\n",
       "Thank you         51\n",
       "My                46\n",
       "Name              46\n",
       "Meet              45\n",
       "Good day          40\n",
       "Nice              38\n",
       "I                 28\n",
       "See you around    18\n",
       "Bye bye           17\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good day          22\n",
       "Thank you         14\n",
       "Nice              13\n",
       "Meet              12\n",
       "Hello             11\n",
       "Tom                8\n",
       "I                  8\n",
       "Name               7\n",
       "My                 6\n",
       "See you around     5\n",
       "Bye bye            4\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(model, data_loader, print_info=False):\n",
    "    \n",
    "    collect_results = []\n",
    "    collect_targets = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        X, y = batch\n",
    "        X = X.float().to(DEVICE)\n",
    "        y = y.float().to(DEVICE).detach().cpu().numpy()\n",
    "\n",
    "        pred = model(X)\n",
    "        pred = F.softmax(pred, dim=0)\n",
    "        collect_results.append(pred.detach().cpu().numpy())\n",
    "        collect_targets.append(y)\n",
    "\n",
    "    preds_proba = np.concatenate(collect_results)\n",
    "    preds = preds_proba.argmax(axis=1)\n",
    "    targets = np.concatenate(collect_targets)\n",
    "\n",
    "    ll = log_loss(targets, preds_proba)\n",
    "    acc = accuracy_score(targets, preds)\n",
    "\n",
    "    \n",
    "    if print_info:\n",
    "        print(\"test log-loss: {}\".format(ll))\n",
    "        print(\"overall accuracy:  {}\".format(acc))\n",
    "\n",
    "    return ll, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH=1\n",
      "train: loss=2.385907916847719 acc=0.6169724770642202\n",
      "test: loss=2.3863244280902616 acc=0.6284403669724771\n",
      "EPOCH=2\n",
      "train: loss=2.372283762748088 acc=0.6995412844036697\n",
      "test: loss=2.37380380368014 acc=0.7064220183486238\n",
      "EPOCH=3\n",
      "train: loss=2.3582047945862517 acc=0.7247706422018348\n",
      "test: loss=2.357435061844117 acc=0.7385321100917431\n",
      "EPOCH=4\n",
      "train: loss=2.3356982223484493 acc=0.731651376146789\n",
      "test: loss=2.336757191824257 acc=0.6972477064220184\n",
      "EPOCH=5\n",
      "train: loss=2.308962539795342 acc=0.6215596330275229\n",
      "test: loss=2.3082973262585633 acc=0.6834862385321101\n",
      "EPOCH=6\n",
      "train: loss=2.2681227960717787 acc=0.7110091743119266\n",
      "test: loss=2.262190096422073 acc=0.7477064220183486\n",
      "EPOCH=7\n",
      "train: loss=2.1989481465532146 acc=0.7041284403669725\n",
      "test: loss=2.2045396700364734 acc=0.7431192660550459\n",
      "EPOCH=8\n",
      "train: loss=2.120684069504432 acc=0.7454128440366973\n",
      "test: loss=2.126212941397221 acc=0.7293577981651376\n",
      "EPOCH=9\n",
      "train: loss=2.0253742050140278 acc=0.7568807339449541\n",
      "test: loss=2.0327136210345347 acc=0.7293577981651376\n",
      "EPOCH=10\n",
      "train: loss=1.9160760608288125 acc=0.7431192660550459\n",
      "test: loss=1.9194274071706545 acc=0.7408256880733946\n",
      "EPOCH=11\n",
      "train: loss=1.8042424457882522 acc=0.6903669724770642\n",
      "test: loss=1.7906953851017384 acc=0.7155963302752294\n",
      "EPOCH=12\n",
      "train: loss=1.6452517495789658 acc=0.8027522935779816\n",
      "test: loss=1.6614348532956675 acc=0.7591743119266054\n",
      "EPOCH=13\n",
      "train: loss=1.538238651025186 acc=0.75\n",
      "test: loss=1.5327144688969359 acc=0.805045871559633\n",
      "EPOCH=14\n",
      "train: loss=1.4197787146229264 acc=0.7752293577981652\n",
      "test: loss=1.4006981097776956 acc=0.7958715596330275\n",
      "EPOCH=15\n",
      "train: loss=1.2999199786044042 acc=0.768348623853211\n",
      "test: loss=1.268120441619956 acc=0.8348623853211009\n",
      "EPOCH=16\n",
      "train: loss=1.2194777867936213 acc=0.7660550458715596\n",
      "test: loss=1.1705879315460495 acc=0.8279816513761468\n",
      "EPOCH=17\n",
      "train: loss=1.1372435650010722 acc=0.8256880733944955\n",
      "test: loss=1.096757134918226 acc=0.8486238532110092\n",
      "EPOCH=18\n",
      "train: loss=1.038693845648011 acc=0.8142201834862385\n",
      "test: loss=0.9987061323786001 acc=0.8394495412844036\n",
      "EPOCH=19\n",
      "train: loss=1.0055349633576127 acc=0.7637614678899083\n",
      "test: loss=0.9296587480385916 acc=0.841743119266055\n",
      "EPOCH=20\n",
      "train: loss=0.9197971510846134 acc=0.8004587155963303\n",
      "test: loss=0.8886003913614181 acc=0.8440366972477065\n",
      "EPOCH=21\n",
      "train: loss=0.8683162294840867 acc=0.805045871559633\n",
      "test: loss=0.8232498043515813 acc=0.8532110091743119\n",
      "EPOCH=22\n",
      "train: loss=0.8413216980738104 acc=0.7981651376146789\n",
      "test: loss=0.7863845149174743 acc=0.8623853211009175\n",
      "EPOCH=23\n",
      "train: loss=0.7665683998290552 acc=0.841743119266055\n",
      "test: loss=0.7542083217258301 acc=0.8646788990825688\n",
      "EPOCH=24\n",
      "train: loss=0.7637345827859613 acc=0.7821100917431193\n",
      "test: loss=0.700631865753083 acc=0.8486238532110092\n",
      "EPOCH=25\n",
      "train: loss=0.7141008663478248 acc=0.7981651376146789\n",
      "test: loss=0.6958474526010933 acc=0.8486238532110092\n",
      "EPOCH=26\n",
      "train: loss=0.7227823357055083 acc=0.8142201834862385\n",
      "test: loss=0.6428670152304096 acc=0.8623853211009175\n",
      "EPOCH=27\n",
      "train: loss=0.6475131672149131 acc=0.8532110091743119\n",
      "test: loss=0.6406793293688412 acc=0.8325688073394495\n",
      "EPOCH=28\n",
      "train: loss=0.6592815210914598 acc=0.8302752293577982\n",
      "test: loss=0.5988321511946414 acc=0.8669724770642202\n",
      "EPOCH=29\n",
      "train: loss=0.6188466681270014 acc=0.8394495412844036\n",
      "test: loss=0.5957966529926576 acc=0.8555045871559633\n",
      "EPOCH=30\n",
      "train: loss=0.6319336656720267 acc=0.8142201834862385\n",
      "test: loss=0.5712756192602149 acc=0.8463302752293578\n",
      "EPOCH=31\n",
      "train: loss=0.5328593872308116 acc=0.8509174311926605\n",
      "test: loss=0.5720420437480468 acc=0.823394495412844\n",
      "EPOCH=32\n",
      "train: loss=0.5696955668705798 acc=0.8279816513761468\n",
      "test: loss=0.5480616619434515 acc=0.8509174311926605\n",
      "EPOCH=33\n",
      "train: loss=0.5507791691861295 acc=0.8394495412844036\n",
      "test: loss=0.5452244900585657 acc=0.8486238532110092\n",
      "EPOCH=34\n",
      "train: loss=0.5418075988616008 acc=0.8577981651376146\n",
      "test: loss=0.5060988654160377 acc=0.8715596330275229\n",
      "EPOCH=35\n",
      "train: loss=0.5321732584489595 acc=0.8555045871559633\n",
      "test: loss=0.525483385476053 acc=0.8623853211009175\n",
      "EPOCH=36\n",
      "train: loss=0.49925655426901827 acc=0.8646788990825688\n",
      "test: loss=0.5093369084119865 acc=0.8646788990825688\n",
      "EPOCH=37\n",
      "train: loss=0.5196488829385147 acc=0.8463302752293578\n",
      "test: loss=0.48536215114851544 acc=0.8646788990825688\n",
      "EPOCH=38\n",
      "train: loss=0.4644026755944851 acc=0.8990825688073395\n",
      "test: loss=0.48212106267861815 acc=0.8646788990825688\n",
      "EPOCH=39\n",
      "train: loss=0.48869179110811733 acc=0.8784403669724771\n",
      "test: loss=0.49127495399496834 acc=0.8646788990825688\n",
      "EPOCH=40\n",
      "train: loss=0.4979707243993297 acc=0.8715596330275229\n",
      "test: loss=0.4554337644906834 acc=0.8738532110091743\n",
      "EPOCH=41\n",
      "train: loss=0.44974942972729787 acc=0.8922018348623854\n",
      "test: loss=0.46410146901819754 acc=0.8555045871559633\n",
      "EPOCH=42\n",
      "train: loss=0.4468798760341805 acc=0.8784403669724771\n",
      "test: loss=0.4768348825270942 acc=0.8623853211009175\n",
      "EPOCH=43\n",
      "train: loss=0.44581846042574647 acc=0.8715596330275229\n",
      "test: loss=0.4709520881670877 acc=0.8646788990825688\n",
      "EPOCH=44\n",
      "train: loss=0.44933955828710503 acc=0.8876146788990825\n",
      "test: loss=0.461090679950115 acc=0.8600917431192661\n",
      "EPOCH=45\n",
      "train: loss=0.4506395449263787 acc=0.8738532110091743\n",
      "test: loss=0.42252440278529435 acc=0.8807339449541285\n",
      "EPOCH=46\n",
      "train: loss=0.4042604216235613 acc=0.9036697247706422\n",
      "test: loss=0.42735305979288263 acc=0.8853211009174312\n",
      "EPOCH=47\n",
      "train: loss=0.4050713572341419 acc=0.8899082568807339\n",
      "test: loss=0.44634073483116854 acc=0.8600917431192661\n",
      "EPOCH=48\n",
      "train: loss=0.4629330488622462 acc=0.8577981651376146\n",
      "test: loss=0.4153915706994183 acc=0.8807339449541285\n",
      "EPOCH=49\n",
      "train: loss=0.4334146187367311 acc=0.8784403669724771\n",
      "test: loss=0.4405571152253179 acc=0.8876146788990825\n",
      "EPOCH=50\n",
      "train: loss=0.35220983824767427 acc=0.9220183486238532\n",
      "test: loss=0.4156312660694362 acc=0.8807339449541285\n",
      "EPOCH=51\n",
      "train: loss=0.3910937379797869 acc=0.8990825688073395\n",
      "test: loss=0.41767905522757337 acc=0.8761467889908257\n",
      "EPOCH=52\n",
      "train: loss=0.4124135522304291 acc=0.8853211009174312\n",
      "test: loss=0.4218288711208098 acc=0.8715596330275229\n",
      "EPOCH=53\n",
      "train: loss=0.36660184567567783 acc=0.8899082568807339\n",
      "test: loss=0.39494922924722725 acc=0.8623853211009175\n",
      "EPOCH=54\n",
      "train: loss=0.36316634601712605 acc=0.9059633027522935\n",
      "test: loss=0.3991222321968996 acc=0.8646788990825688\n",
      "EPOCH=55\n",
      "train: loss=0.35285342200189285 acc=0.9128440366972477\n",
      "test: loss=0.40108179169762537 acc=0.8600917431192661\n",
      "EPOCH=56\n",
      "train: loss=0.38127153646948514 acc=0.8807339449541285\n",
      "test: loss=0.3994166475700411 acc=0.8761467889908257\n",
      "EPOCH=57\n",
      "train: loss=0.3010007488891619 acc=0.9059633027522935\n",
      "test: loss=0.40520994868311055 acc=0.8600917431192661\n",
      "EPOCH=58\n",
      "train: loss=0.4783075381206015 acc=0.8279816513761468\n",
      "test: loss=0.3874201743047548 acc=0.8692660550458715\n",
      "EPOCH=59\n",
      "train: loss=0.3058480761706009 acc=0.9174311926605505\n",
      "test: loss=0.39837811428918973 acc=0.8646788990825688\n",
      "EPOCH=60\n",
      "train: loss=0.30634754544701814 acc=0.9059633027522935\n",
      "test: loss=0.37869789753666727 acc=0.8623853211009175\n",
      "EPOCH=61\n",
      "train: loss=0.38710272713423355 acc=0.8646788990825688\n",
      "test: loss=0.3623672783259439 acc=0.8899082568807339\n",
      "EPOCH=62\n",
      "train: loss=0.35392790538933844 acc=0.8830275229357798\n",
      "test: loss=0.3504079376937984 acc=0.8646788990825688\n",
      "EPOCH=63\n",
      "train: loss=0.3482717732237246 acc=0.8876146788990825\n",
      "test: loss=0.3697046215153073 acc=0.8715596330275229\n",
      "EPOCH=64\n",
      "train: loss=0.32046448494737045 acc=0.9036697247706422\n",
      "test: loss=0.35418174354708754 acc=0.8692660550458715\n",
      "EPOCH=65\n",
      "train: loss=0.4018060173193172 acc=0.8577981651376146\n",
      "test: loss=0.37528348654517135 acc=0.8600917431192661\n",
      "EPOCH=66\n",
      "train: loss=0.27469319058502084 acc=0.9174311926605505\n",
      "test: loss=0.3724612409351479 acc=0.8692660550458715\n",
      "EPOCH=67\n",
      "train: loss=0.34033146135080733 acc=0.8944954128440367\n",
      "test: loss=0.38945704874253634 acc=0.8577981651376146\n",
      "EPOCH=68\n",
      "train: loss=0.27309000843077463 acc=0.9311926605504587\n",
      "test: loss=0.3622342427234473 acc=0.8784403669724771\n",
      "EPOCH=69\n",
      "train: loss=0.347115934189754 acc=0.8853211009174312\n",
      "test: loss=0.34640127064851367 acc=0.8600917431192661\n",
      "EPOCH=70\n",
      "train: loss=0.2821310753298607 acc=0.9128440366972477\n",
      "test: loss=0.3568277083884139 acc=0.8784403669724771\n",
      "EPOCH=71\n",
      "train: loss=0.3169935067668087 acc=0.8807339449541285\n",
      "test: loss=0.34891162743634935 acc=0.8830275229357798\n",
      "EPOCH=72\n",
      "train: loss=0.2424322416957301 acc=0.9197247706422018\n",
      "test: loss=0.3402019640918898 acc=0.8830275229357798\n",
      "EPOCH=73\n",
      "train: loss=0.2682692478480322 acc=0.9220183486238532\n",
      "test: loss=0.34314263530300904 acc=0.8692660550458715\n",
      "EPOCH=74\n",
      "train: loss=0.295599661828494 acc=0.8990825688073395\n",
      "test: loss=0.3522875753560834 acc=0.8532110091743119\n",
      "EPOCH=75\n",
      "train: loss=0.23927131865078524 acc=0.9128440366972477\n",
      "test: loss=0.3638116171566979 acc=0.8509174311926605\n",
      "EPOCH=76\n",
      "train: loss=0.2537635869664031 acc=0.9151376146788991\n",
      "test: loss=0.32759710640695644 acc=0.8646788990825688\n",
      "EPOCH=77\n",
      "train: loss=0.3652480236141688 acc=0.8646788990825688\n",
      "test: loss=0.32737373784873336 acc=0.8738532110091743\n",
      "EPOCH=78\n",
      "train: loss=0.25542621907629626 acc=0.9311926605504587\n",
      "test: loss=0.34016751975633863 acc=0.8646788990825688\n",
      "EPOCH=79\n",
      "train: loss=0.3302695253670884 acc=0.8807339449541285\n",
      "test: loss=0.31924363936980066 acc=0.8830275229357798\n",
      "EPOCH=80\n",
      "train: loss=0.25975007609461026 acc=0.926605504587156\n",
      "test: loss=0.3343489302147111 acc=0.8555045871559633\n",
      "EPOCH=81\n",
      "train: loss=0.3617506071576985 acc=0.8692660550458715\n",
      "test: loss=0.3679011413595776 acc=0.8600917431192661\n",
      "EPOCH=82\n",
      "train: loss=0.3347905871440729 acc=0.8761467889908257\n",
      "test: loss=0.3398429455932223 acc=0.8692660550458715\n",
      "EPOCH=83\n",
      "train: loss=0.22901902368803265 acc=0.926605504587156\n",
      "test: loss=0.37773814839989145 acc=0.8600917431192661\n",
      "EPOCH=84\n",
      "train: loss=0.25782799985475513 acc=0.9013761467889908\n",
      "test: loss=0.3333291853551775 acc=0.8692660550458715\n",
      "EPOCH=85\n",
      "train: loss=0.25520136219377515 acc=0.9174311926605505\n",
      "test: loss=0.3490055963017074 acc=0.8577981651376146\n",
      "EPOCH=86\n",
      "train: loss=0.27779080807242046 acc=0.9059633027522935\n",
      "test: loss=0.3159124929646277 acc=0.8715596330275229\n",
      "EPOCH=87\n",
      "train: loss=0.20171888073473215 acc=0.9311926605504587\n",
      "test: loss=0.341389027584161 acc=0.8692660550458715\n",
      "EPOCH=88\n",
      "train: loss=0.3207390470941708 acc=0.8922018348623854\n",
      "test: loss=0.34338691884717465 acc=0.8738532110091743\n",
      "EPOCH=89\n",
      "train: loss=0.19018194487226545 acc=0.9518348623853211\n",
      "test: loss=0.3170151508931517 acc=0.8761467889908257\n",
      "EPOCH=90\n",
      "train: loss=0.21795157698109113 acc=0.9311926605504587\n",
      "test: loss=0.29155447055642286 acc=0.8830275229357798\n",
      "EPOCH=91\n",
      "train: loss=0.2740978777518807 acc=0.9128440366972477\n",
      "test: loss=0.2973692710194982 acc=0.8692660550458715\n",
      "EPOCH=92\n",
      "train: loss=0.2617237996312666 acc=0.9013761467889908\n",
      "test: loss=0.3384580157349824 acc=0.8738532110091743\n",
      "EPOCH=93\n",
      "train: loss=0.26319077795418405 acc=0.908256880733945\n",
      "test: loss=0.3275340041333255 acc=0.8646788990825688\n",
      "EPOCH=94\n",
      "train: loss=0.2492446793809879 acc=0.8990825688073395\n",
      "test: loss=0.32380869700130155 acc=0.8646788990825688\n",
      "EPOCH=95\n",
      "train: loss=0.2763111229186665 acc=0.9059633027522935\n",
      "test: loss=0.34748752061541965 acc=0.8555045871559633\n",
      "EPOCH=96\n",
      "train: loss=0.25691501975340936 acc=0.9105504587155964\n",
      "test: loss=0.3134464832762264 acc=0.8738532110091743\n",
      "EPOCH=97\n",
      "train: loss=0.1903069635991081 acc=0.9334862385321101\n",
      "test: loss=0.35692432629683596 acc=0.8646788990825688\n",
      "EPOCH=98\n",
      "train: loss=0.2002456424484289 acc=0.9288990825688074\n",
      "test: loss=0.32196468126607913 acc=0.8577981651376146\n",
      "EPOCH=99\n",
      "train: loss=0.28767371262201274 acc=0.8761467889908257\n",
      "test: loss=0.3282981152800641 acc=0.8692660550458715\n",
      "EPOCH=100\n",
      "train: loss=0.2638339829530221 acc=0.8899082568807339\n",
      "test: loss=0.3200074937832734 acc=0.8600917431192661\n",
      "EPOCH=101\n",
      "train: loss=0.26242862012708046 acc=0.9059633027522935\n",
      "test: loss=0.3261963923108885 acc=0.8646788990825688\n",
      "EPOCH=102\n",
      "train: loss=0.2942351247428958 acc=0.8830275229357798\n",
      "test: loss=0.2977639385019114 acc=0.8738532110091743\n",
      "EPOCH=103\n",
      "train: loss=0.23402810767503912 acc=0.908256880733945\n",
      "test: loss=0.32740008596144243 acc=0.8669724770642202\n",
      "EPOCH=104\n",
      "train: loss=0.2876577596119397 acc=0.8944954128440367\n",
      "test: loss=0.33798528626330737 acc=0.8532110091743119\n",
      "EPOCH=105\n",
      "train: loss=0.20953617709248412 acc=0.9243119266055045\n",
      "test: loss=0.3344028034315745 acc=0.8532110091743119\n",
      "EPOCH=106\n",
      "train: loss=0.24935944290707393 acc=0.9105504587155964\n",
      "test: loss=0.35283697655854623 acc=0.8509174311926605\n",
      "EPOCH=107\n",
      "train: loss=0.25712523472541704 acc=0.9105504587155964\n",
      "test: loss=0.31188330553727567 acc=0.8692660550458715\n",
      "EPOCH=108\n",
      "train: loss=0.19731299382512438 acc=0.9403669724770642\n",
      "test: loss=0.32663980147361044 acc=0.8807339449541285\n",
      "EPOCH=109\n",
      "train: loss=0.24104460986760853 acc=0.908256880733945\n",
      "test: loss=0.354178209078056 acc=0.8577981651376146\n",
      "EPOCH=110\n",
      "train: loss=0.1836997111224948 acc=0.926605504587156\n",
      "test: loss=0.32346680898479946 acc=0.8715596330275229\n",
      "EPOCH=111\n",
      "train: loss=0.24665328685075835 acc=0.9105504587155964\n",
      "test: loss=0.3164081017818108 acc=0.8669724770642202\n",
      "EPOCH=112\n",
      "train: loss=0.24300144507180965 acc=0.8944954128440367\n",
      "test: loss=0.3419701209808275 acc=0.8577981651376146\n",
      "EPOCH=113\n",
      "train: loss=0.27847740069326626 acc=0.8876146788990825\n",
      "test: loss=0.31929003030962605 acc=0.8715596330275229\n",
      "EPOCH=114\n",
      "train: loss=0.22043393985886975 acc=0.9174311926605505\n",
      "test: loss=0.2864769927427331 acc=0.8853211009174312\n",
      "EPOCH=115\n",
      "train: loss=0.14783018881630888 acc=0.9587155963302753\n",
      "test: loss=0.31601177752776943 acc=0.8738532110091743\n",
      "EPOCH=116\n",
      "train: loss=0.2762396547403264 acc=0.8784403669724771\n",
      "test: loss=0.3444194884323891 acc=0.8669724770642202\n",
      "EPOCH=117\n",
      "train: loss=0.2306635253052422 acc=0.9013761467889908\n",
      "test: loss=0.3433918387268231 acc=0.8463302752293578\n",
      "EPOCH=118\n",
      "train: loss=0.22301473318380352 acc=0.9220183486238532\n",
      "test: loss=0.30953736897370604 acc=0.8600917431192661\n",
      "EPOCH=119\n",
      "train: loss=0.20078593069819856 acc=0.9288990825688074\n",
      "test: loss=0.2999992888179712 acc=0.8761467889908257\n",
      "EPOCH=120\n",
      "train: loss=0.2106237608144127 acc=0.908256880733945\n",
      "test: loss=0.33861355478338656 acc=0.8600917431192661\n",
      "EPOCH=121\n",
      "train: loss=0.19745592726771682 acc=0.9334862385321101\n",
      "test: loss=0.31177590021536095 acc=0.8715596330275229\n",
      "EPOCH=122\n",
      "train: loss=0.21567115810951715 acc=0.9174311926605505\n",
      "test: loss=0.3330205383205852 acc=0.8555045871559633\n",
      "EPOCH=123\n",
      "train: loss=0.2397970895739357 acc=0.9059633027522935\n",
      "test: loss=0.32076911902149396 acc=0.8509174311926605\n",
      "EPOCH=124\n",
      "train: loss=0.2029025427504116 acc=0.9174311926605505\n",
      "test: loss=0.28354215877110733 acc=0.8853211009174312\n",
      "EPOCH=125\n",
      "train: loss=0.19920923880073726 acc=0.926605504587156\n",
      "test: loss=0.2980649219255469 acc=0.8807339449541285\n",
      "EPOCH=126\n",
      "train: loss=0.2225686731734799 acc=0.9174311926605505\n",
      "test: loss=0.3058266655774987 acc=0.8715596330275229\n",
      "EPOCH=127\n",
      "train: loss=0.2281451613817065 acc=0.9220183486238532\n",
      "test: loss=0.33170435693595746 acc=0.8669724770642202\n",
      "EPOCH=128\n",
      "train: loss=0.20761359055402595 acc=0.9288990825688074\n",
      "test: loss=0.3103858615425811 acc=0.8738532110091743\n",
      "EPOCH=129\n",
      "train: loss=0.2022003727890328 acc=0.9220183486238532\n",
      "test: loss=0.30798315400143694 acc=0.8715596330275229\n",
      "EPOCH=130\n",
      "train: loss=0.24348230053129313 acc=0.8967889908256881\n",
      "test: loss=0.30321879373665955 acc=0.8669724770642202\n",
      "EPOCH=131\n",
      "train: loss=0.16562294374048722 acc=0.9288990825688074\n",
      "test: loss=0.36648642670349435 acc=0.8486238532110092\n",
      "EPOCH=132\n",
      "train: loss=0.2658352287464635 acc=0.8990825688073395\n",
      "test: loss=0.3047879517419569 acc=0.8646788990825688\n",
      "EPOCH=133\n",
      "train: loss=0.3080356581863771 acc=0.8692660550458715\n",
      "test: loss=0.3277636643243076 acc=0.8577981651376146\n",
      "EPOCH=134\n",
      "train: loss=0.22151708844458723 acc=0.9197247706422018\n",
      "test: loss=0.2794143339181682 acc=0.8853211009174312\n",
      "EPOCH=135\n",
      "train: loss=0.18557805643185013 acc=0.9357798165137615\n",
      "test: loss=0.27717480871690503 acc=0.8830275229357798\n",
      "EPOCH=136\n",
      "train: loss=0.20114196862697942 acc=0.9197247706422018\n",
      "test: loss=0.2862077744620523 acc=0.8738532110091743\n",
      "EPOCH=137\n",
      "train: loss=0.16442298528954363 acc=0.9403669724770642\n",
      "test: loss=0.3111405076953248 acc=0.8761467889908257\n",
      "EPOCH=138\n",
      "train: loss=0.24861330806661583 acc=0.8944954128440367\n",
      "test: loss=0.3142618887269161 acc=0.8807339449541285\n",
      "EPOCH=139\n",
      "train: loss=0.23332865315819826 acc=0.9105504587155964\n",
      "test: loss=0.3181407187971797 acc=0.8600917431192661\n",
      "EPOCH=140\n",
      "train: loss=0.14602165104109757 acc=0.9564220183486238\n",
      "test: loss=0.28858358045735416 acc=0.8761467889908257\n",
      "EPOCH=141\n",
      "train: loss=0.22196554185768805 acc=0.9128440366972477\n",
      "test: loss=0.33516172754439183 acc=0.8623853211009175\n",
      "EPOCH=142\n",
      "train: loss=0.16078790272992233 acc=0.9426605504587156\n",
      "test: loss=0.3229575974342512 acc=0.8669724770642202\n",
      "EPOCH=143\n",
      "train: loss=0.2170570449440149 acc=0.9151376146788991\n",
      "test: loss=0.3209812898882832 acc=0.8623853211009175\n",
      "EPOCH=144\n",
      "train: loss=0.19301502999072023 acc=0.9334862385321101\n",
      "test: loss=0.351046018388876 acc=0.8463302752293578\n",
      "EPOCH=145\n",
      "train: loss=0.26043772798988807 acc=0.8830275229357798\n",
      "test: loss=0.3223649236446563 acc=0.8623853211009175\n",
      "EPOCH=146\n",
      "train: loss=0.24515382989894208 acc=0.9059633027522935\n",
      "test: loss=0.26791826563855026 acc=0.8853211009174312\n",
      "EPOCH=147\n",
      "train: loss=0.23124551842630947 acc=0.9036697247706422\n",
      "test: loss=0.30949624340039444 acc=0.8830275229357798\n",
      "EPOCH=148\n",
      "train: loss=0.24477403585876487 acc=0.8922018348623854\n",
      "test: loss=0.3015844464434974 acc=0.8784403669724771\n",
      "EPOCH=149\n",
      "train: loss=0.1922128957450462 acc=0.9243119266055045\n",
      "test: loss=0.2800906628888013 acc=0.8784403669724771\n",
      "EPOCH=150\n",
      "train: loss=0.2762689207373056 acc=0.8853211009174312\n",
      "test: loss=0.33686901875197184 acc=0.8669724770642202\n",
      "EPOCH=151\n",
      "train: loss=0.2006303723369247 acc=0.9197247706422018\n",
      "test: loss=0.30849384763203475 acc=0.8646788990825688\n",
      "EPOCH=152\n",
      "train: loss=0.18488597278852517 acc=0.926605504587156\n",
      "test: loss=0.2863218693852071 acc=0.8853211009174312\n",
      "EPOCH=153\n",
      "train: loss=0.22689978797686117 acc=0.9059633027522935\n",
      "test: loss=0.3197554157780218 acc=0.8715596330275229\n",
      "EPOCH=154\n",
      "train: loss=0.18471157343790748 acc=0.9334862385321101\n",
      "test: loss=0.29063870389750307 acc=0.8899082568807339\n",
      "EPOCH=155\n",
      "train: loss=0.1882112543093789 acc=0.9311926605504587\n",
      "test: loss=0.28209386613344917 acc=0.8738532110091743\n",
      "EPOCH=156\n",
      "train: loss=0.161438314010945 acc=0.9472477064220184\n",
      "test: loss=0.28987083155564697 acc=0.8807339449541285\n",
      "EPOCH=157\n",
      "train: loss=0.20863565573534604 acc=0.9220183486238532\n",
      "test: loss=0.31476037583268723 acc=0.8600917431192661\n",
      "EPOCH=158\n",
      "train: loss=0.17743007490931514 acc=0.9357798165137615\n",
      "test: loss=0.3005555753068353 acc=0.8646788990825688\n",
      "EPOCH=159\n",
      "train: loss=0.1773716117442032 acc=0.9243119266055045\n",
      "test: loss=0.271043985074845 acc=0.8669724770642202\n",
      "EPOCH=160\n",
      "train: loss=0.1451463285716408 acc=0.944954128440367\n",
      "test: loss=0.3113687113248138 acc=0.8738532110091743\n",
      "EPOCH=161\n",
      "train: loss=0.17974293694456353 acc=0.9311926605504587\n",
      "test: loss=0.2887117751631921 acc=0.8692660550458715\n",
      "EPOCH=162\n",
      "train: loss=0.19215852083339338 acc=0.9288990825688074\n",
      "test: loss=0.3196479301107276 acc=0.8715596330275229\n",
      "EPOCH=163\n",
      "train: loss=0.22208015791391833 acc=0.9151376146788991\n",
      "test: loss=0.3373592690605586 acc=0.8532110091743119\n",
      "EPOCH=164\n",
      "train: loss=0.16257816458731364 acc=0.9357798165137615\n",
      "test: loss=0.27458520680055776 acc=0.8784403669724771\n",
      "EPOCH=165\n",
      "train: loss=0.14703952055436967 acc=0.9518348623853211\n",
      "test: loss=0.3168237798847358 acc=0.8715596330275229\n",
      "EPOCH=166\n",
      "train: loss=0.13403955842290957 acc=0.9472477064220184\n",
      "test: loss=0.30027920716359763 acc=0.8853211009174312\n",
      "EPOCH=167\n",
      "train: loss=0.16224995776973286 acc=0.944954128440367\n",
      "test: loss=0.34327454656837175 acc=0.8555045871559633\n",
      "EPOCH=168\n",
      "train: loss=0.25495670555848277 acc=0.8967889908256881\n",
      "test: loss=0.29815786966075997 acc=0.8876146788990825\n",
      "EPOCH=169\n",
      "train: loss=0.12558536647552793 acc=0.9495412844036697\n",
      "test: loss=0.3059581324780684 acc=0.8646788990825688\n",
      "EPOCH=170\n",
      "train: loss=0.21083858330521796 acc=0.9174311926605505\n",
      "test: loss=0.29609268721369014 acc=0.8761467889908257\n",
      "EPOCH=171\n",
      "train: loss=0.17813992727166114 acc=0.9311926605504587\n",
      "test: loss=0.32015094738229843 acc=0.8646788990825688\n",
      "EPOCH=172\n",
      "train: loss=0.156854588178482 acc=0.9357798165137615\n",
      "test: loss=0.29176504926409846 acc=0.8646788990825688\n",
      "EPOCH=173\n",
      "train: loss=0.25111243837794006 acc=0.9105504587155964\n",
      "test: loss=0.3137446278596094 acc=0.8646788990825688\n",
      "EPOCH=174\n",
      "train: loss=0.23825600692284668 acc=0.9036697247706422\n",
      "test: loss=0.2903447137684844 acc=0.8830275229357798\n",
      "EPOCH=175\n",
      "train: loss=0.22538751122275294 acc=0.9128440366972477\n",
      "test: loss=0.3007261997515151 acc=0.8784403669724771\n",
      "EPOCH=176\n",
      "train: loss=0.2013668523503747 acc=0.9220183486238532\n",
      "test: loss=0.29476072805407866 acc=0.8600917431192661\n",
      "EPOCH=177\n",
      "train: loss=0.22118993382306026 acc=0.9013761467889908\n",
      "test: loss=0.29991294259572326 acc=0.8623853211009175\n",
      "EPOCH=178\n",
      "train: loss=0.17632394930859252 acc=0.9334862385321101\n",
      "test: loss=0.31119693605466986 acc=0.8623853211009175\n",
      "EPOCH=179\n",
      "train: loss=0.14919801936752966 acc=0.9334862385321101\n",
      "test: loss=0.2675814825589074 acc=0.8738532110091743\n",
      "EPOCH=180\n",
      "train: loss=0.23271574519640126 acc=0.9036697247706422\n",
      "test: loss=0.3013524500470777 acc=0.8692660550458715\n",
      "EPOCH=181\n",
      "train: loss=0.22742143803933595 acc=0.908256880733945\n",
      "test: loss=0.3245702282816896 acc=0.8646788990825688\n",
      "EPOCH=182\n",
      "train: loss=0.25430060008144095 acc=0.9059633027522935\n",
      "test: loss=0.31368691542380733 acc=0.8784403669724771\n",
      "EPOCH=183\n",
      "train: loss=0.20211273612381073 acc=0.926605504587156\n",
      "test: loss=0.3423045535383929 acc=0.8555045871559633\n",
      "EPOCH=184\n",
      "train: loss=0.16373218726378314 acc=0.9357798165137615\n",
      "test: loss=0.29566024812280006 acc=0.8784403669724771\n",
      "EPOCH=185\n",
      "train: loss=0.13324803320814674 acc=0.9518348623853211\n",
      "test: loss=0.23361214919922857 acc=0.8967889908256881\n",
      "EPOCH=186\n",
      "train: loss=0.2505548956692277 acc=0.908256880733945\n",
      "test: loss=0.2966867073556583 acc=0.8761467889908257\n",
      "EPOCH=187\n",
      "train: loss=0.16456266551232468 acc=0.944954128440367\n",
      "test: loss=0.2833800326416751 acc=0.8853211009174312\n",
      "EPOCH=188\n",
      "train: loss=0.1466045561025917 acc=0.9403669724770642\n",
      "test: loss=0.24449883585042148 acc=0.8967889908256881\n",
      "EPOCH=189\n",
      "train: loss=0.23572621191294 acc=0.9174311926605505\n",
      "test: loss=0.29286669426073997 acc=0.8715596330275229\n",
      "EPOCH=190\n",
      "train: loss=0.2208265739463217 acc=0.8967889908256881\n",
      "test: loss=0.3291127119769336 acc=0.8509174311926605\n",
      "EPOCH=191\n",
      "train: loss=0.15676498235866723 acc=0.9311926605504587\n",
      "test: loss=0.3245719322598267 acc=0.8715596330275229\n",
      "EPOCH=192\n",
      "train: loss=0.17066886279180804 acc=0.9288990825688074\n",
      "test: loss=0.29505309978637984 acc=0.8876146788990825\n",
      "EPOCH=193\n",
      "train: loss=0.1521021098955412 acc=0.9334862385321101\n",
      "test: loss=0.32277446812661037 acc=0.8577981651376146\n",
      "EPOCH=194\n",
      "train: loss=0.19544682142942008 acc=0.9197247706422018\n",
      "test: loss=0.29179800390812666 acc=0.8738532110091743\n",
      "EPOCH=195\n",
      "train: loss=0.16352417984859097 acc=0.9380733944954128\n",
      "test: loss=0.32890408450941255 acc=0.8761467889908257\n",
      "EPOCH=196\n",
      "train: loss=0.19579147423456944 acc=0.9174311926605505\n",
      "test: loss=0.25579615420250684 acc=0.8967889908256881\n",
      "EPOCH=197\n",
      "train: loss=0.11752862233909815 acc=0.9564220183486238\n",
      "test: loss=0.25698103774097236 acc=0.8853211009174312\n",
      "EPOCH=198\n",
      "train: loss=0.22394333228404412 acc=0.9311926605504587\n",
      "test: loss=0.2998627670344998 acc=0.8669724770642202\n",
      "EPOCH=199\n",
      "train: loss=0.1985399906610036 acc=0.9311926605504587\n",
      "test: loss=0.2617483043471778 acc=0.8899082568807339\n",
      "EPOCH=200\n",
      "train: loss=0.15061453445642498 acc=0.9495412844036697\n",
      "test: loss=0.29135628913410605 acc=0.8692660550458715\n",
      "EPOCH=201\n",
      "train: loss=0.15137071291604015 acc=0.9403669724770642\n",
      "test: loss=0.2858006348833463 acc=0.8784403669724771\n",
      "EPOCH=202\n",
      "train: loss=0.21692816915122737 acc=0.9105504587155964\n",
      "test: loss=0.2885701275927016 acc=0.8830275229357798\n",
      "EPOCH=203\n",
      "train: loss=0.2422429445822226 acc=0.9128440366972477\n",
      "test: loss=0.2777505225302287 acc=0.9036697247706422\n",
      "EPOCH=204\n",
      "train: loss=0.2029988342174038 acc=0.9311926605504587\n",
      "test: loss=0.2959556852225806 acc=0.8669724770642202\n",
      "EPOCH=205\n",
      "train: loss=0.18525003316656052 acc=0.9197247706422018\n",
      "test: loss=0.33435658192625234 acc=0.8555045871559633\n",
      "EPOCH=206\n",
      "train: loss=0.19431964005562438 acc=0.9311926605504587\n",
      "test: loss=0.2448105507778272 acc=0.908256880733945\n",
      "EPOCH=207\n",
      "train: loss=0.17179955967595276 acc=0.9128440366972477\n",
      "test: loss=0.2839848711452234 acc=0.8600917431192661\n",
      "EPOCH=208\n",
      "train: loss=0.22971166692248646 acc=0.9128440366972477\n",
      "test: loss=0.28576944370178387 acc=0.8784403669724771\n",
      "EPOCH=209\n",
      "train: loss=0.25036767641230606 acc=0.9128440366972477\n",
      "test: loss=0.31419569813194365 acc=0.8555045871559633\n",
      "EPOCH=210\n",
      "train: loss=0.1291568773337923 acc=0.9472477064220184\n",
      "test: loss=0.29241950134691036 acc=0.8692660550458715\n",
      "EPOCH=211\n",
      "train: loss=0.19904155166828794 acc=0.9311926605504587\n",
      "test: loss=0.3063553334196855 acc=0.8830275229357798\n",
      "EPOCH=212\n",
      "train: loss=0.18745888046712147 acc=0.9220183486238532\n",
      "test: loss=0.31395199063824375 acc=0.8692660550458715\n",
      "EPOCH=213\n",
      "train: loss=0.1781322123226081 acc=0.944954128440367\n",
      "test: loss=0.25168048359586914 acc=0.8899082568807339\n",
      "EPOCH=214\n",
      "train: loss=0.1450120522394498 acc=0.9426605504587156\n",
      "test: loss=0.3014568657260629 acc=0.8692660550458715\n",
      "EPOCH=215\n",
      "train: loss=0.2307608690031807 acc=0.9013761467889908\n",
      "test: loss=0.31122060137359653 acc=0.8646788990825688\n",
      "EPOCH=216\n",
      "train: loss=0.19277434381310135 acc=0.9105504587155964\n",
      "test: loss=0.27853794779751084 acc=0.8669724770642202\n",
      "EPOCH=217\n",
      "train: loss=0.1244531880686803 acc=0.9541284403669725\n",
      "test: loss=0.2636440224574438 acc=0.8853211009174312\n",
      "EPOCH=218\n",
      "train: loss=0.19467864436846907 acc=0.9311926605504587\n",
      "test: loss=0.2835652775574071 acc=0.8922018348623854\n",
      "EPOCH=219\n",
      "train: loss=0.1890250361793858 acc=0.9197247706422018\n",
      "test: loss=0.26375379960067546 acc=0.8922018348623854\n",
      "EPOCH=220\n",
      "train: loss=0.16626545004290608 acc=0.9357798165137615\n",
      "test: loss=0.24851502220573732 acc=0.8899082568807339\n",
      "EPOCH=221\n",
      "train: loss=0.15913957471557955 acc=0.9426605504587156\n",
      "test: loss=0.2763764302460365 acc=0.8853211009174312\n",
      "EPOCH=222\n",
      "train: loss=0.08133636397709729 acc=0.9793577981651376\n",
      "test: loss=0.2744574854461139 acc=0.8899082568807339\n",
      "EPOCH=223\n",
      "train: loss=0.26401969886898313 acc=0.9105504587155964\n",
      "test: loss=0.26015743003074426 acc=0.8922018348623854\n",
      "EPOCH=224\n",
      "train: loss=0.17664001512270608 acc=0.926605504587156\n",
      "test: loss=0.286210252203893 acc=0.8761467889908257\n",
      "EPOCH=225\n",
      "train: loss=0.1921919979094557 acc=0.9357798165137615\n",
      "test: loss=0.29781394043663917 acc=0.8692660550458715\n",
      "EPOCH=226\n",
      "train: loss=0.2086059826814653 acc=0.9105504587155964\n",
      "test: loss=0.2581651548841412 acc=0.9013761467889908\n",
      "EPOCH=227\n",
      "train: loss=0.23605658990963105 acc=0.9243119266055045\n",
      "test: loss=0.30016941407113623 acc=0.8761467889908257\n",
      "EPOCH=228\n",
      "train: loss=0.12241605109648561 acc=0.9564220183486238\n",
      "test: loss=0.3057300663098835 acc=0.8784403669724771\n",
      "EPOCH=229\n",
      "train: loss=0.18101393122074136 acc=0.9197247706422018\n",
      "test: loss=0.2505635621347156 acc=0.8990825688073395\n",
      "EPOCH=230\n",
      "train: loss=0.2225984496586936 acc=0.9105504587155964\n",
      "test: loss=0.2777483044400221 acc=0.8738532110091743\n",
      "EPOCH=231\n",
      "train: loss=0.2094776125838816 acc=0.9128440366972477\n",
      "test: loss=0.22885031157519892 acc=0.8990825688073395\n",
      "EPOCH=232\n",
      "train: loss=0.151716866285826 acc=0.944954128440367\n",
      "test: loss=0.28887797145737276 acc=0.8738532110091743\n",
      "EPOCH=233\n",
      "train: loss=0.19290673743716874 acc=0.9105504587155964\n",
      "test: loss=0.2392588242859714 acc=0.8922018348623854\n",
      "EPOCH=234\n",
      "train: loss=0.13976219501521225 acc=0.9518348623853211\n",
      "test: loss=0.3238951436843588 acc=0.8623853211009175\n",
      "EPOCH=235\n",
      "train: loss=0.18740964462934348 acc=0.9151376146788991\n",
      "test: loss=0.26354865863407007 acc=0.8853211009174312\n",
      "EPOCH=236\n",
      "train: loss=0.21088632140792157 acc=0.9403669724770642\n",
      "test: loss=0.27675873239482146 acc=0.8692660550458715\n",
      "EPOCH=237\n",
      "train: loss=0.20236794600380797 acc=0.9128440366972477\n",
      "test: loss=0.27293505829764236 acc=0.8807339449541285\n",
      "EPOCH=238\n",
      "train: loss=0.15156015190664043 acc=0.9495412844036697\n",
      "test: loss=0.27071689311074854 acc=0.8807339449541285\n",
      "EPOCH=239\n",
      "train: loss=0.29999796715092486 acc=0.8830275229357798\n",
      "test: loss=0.2774675460442662 acc=0.8715596330275229\n",
      "EPOCH=240\n",
      "train: loss=0.12047675420528714 acc=0.9610091743119266\n",
      "test: loss=0.30039399490626506 acc=0.8646788990825688\n",
      "EPOCH=241\n",
      "train: loss=0.16691266293636964 acc=0.9243119266055045\n",
      "test: loss=0.3242467205338634 acc=0.8669724770642202\n",
      "EPOCH=242\n",
      "train: loss=0.16003592800771155 acc=0.944954128440367\n",
      "test: loss=0.2754884095235153 acc=0.8830275229357798\n",
      "EPOCH=243\n",
      "train: loss=0.19032486093169348 acc=0.9288990825688074\n",
      "test: loss=0.26888184663199954 acc=0.8761467889908257\n",
      "EPOCH=244\n",
      "train: loss=0.2100276517172766 acc=0.908256880733945\n",
      "test: loss=0.2518159046107136 acc=0.8876146788990825\n",
      "EPOCH=245\n",
      "train: loss=0.11354873769305898 acc=0.9564220183486238\n",
      "test: loss=0.310500327510329 acc=0.8738532110091743\n",
      "EPOCH=246\n",
      "train: loss=0.1536416337887812 acc=0.9403669724770642\n",
      "test: loss=0.2607033765509443 acc=0.8761467889908257\n",
      "EPOCH=247\n",
      "train: loss=0.16605861896930793 acc=0.9288990825688074\n",
      "test: loss=0.3131258365950651 acc=0.8738532110091743\n",
      "EPOCH=248\n",
      "train: loss=0.18421839790462055 acc=0.9288990825688074\n",
      "test: loss=0.31345166893292703 acc=0.8692660550458715\n",
      "EPOCH=249\n",
      "train: loss=0.20692273892685523 acc=0.9036697247706422\n",
      "test: loss=0.23168545444933764 acc=0.8990825688073395\n",
      "EPOCH=250\n",
      "train: loss=0.15615090994648811 acc=0.9311926605504587\n",
      "test: loss=0.3415485796538548 acc=0.8600917431192661\n",
      "EPOCH=251\n",
      "train: loss=0.18843119270078634 acc=0.9197247706422018\n",
      "test: loss=0.2873718717916282 acc=0.8944954128440367\n",
      "EPOCH=252\n",
      "train: loss=0.11588234049472683 acc=0.944954128440367\n",
      "test: loss=0.236198465993532 acc=0.8922018348623854\n",
      "EPOCH=253\n",
      "train: loss=0.15798585124823206 acc=0.9311926605504587\n",
      "test: loss=0.325676126506862 acc=0.8692660550458715\n",
      "EPOCH=254\n",
      "train: loss=0.13210237025502572 acc=0.9518348623853211\n",
      "test: loss=0.2730431709507669 acc=0.8853211009174312\n",
      "EPOCH=255\n",
      "train: loss=0.13725149972304754 acc=0.9564220183486238\n",
      "test: loss=0.29154102048031133 acc=0.9013761467889908\n",
      "EPOCH=256\n",
      "train: loss=0.1936365108285939 acc=0.926605504587156\n",
      "test: loss=0.29820281985660796 acc=0.8623853211009175\n",
      "EPOCH=257\n",
      "train: loss=0.2704557539372517 acc=0.8944954128440367\n",
      "test: loss=0.2183806824954176 acc=0.8990825688073395\n",
      "EPOCH=258\n",
      "train: loss=0.10689537658972188 acc=0.9610091743119266\n",
      "test: loss=0.2292453968570995 acc=0.8899082568807339\n",
      "EPOCH=259\n",
      "train: loss=0.16938337181098673 acc=0.9174311926605505\n",
      "test: loss=0.2334636221683782 acc=0.9036697247706422\n",
      "EPOCH=260\n",
      "train: loss=0.1424489234864423 acc=0.9495412844036697\n",
      "test: loss=0.2503339318388901 acc=0.8853211009174312\n",
      "EPOCH=261\n",
      "train: loss=0.18404420167203087 acc=0.9243119266055045\n",
      "test: loss=0.3041794058139672 acc=0.8692660550458715\n",
      "EPOCH=262\n",
      "train: loss=0.12207958493038008 acc=0.9495412844036697\n",
      "test: loss=0.3383767851693449 acc=0.8738532110091743\n",
      "EPOCH=263\n",
      "train: loss=0.18409823059045352 acc=0.9243119266055045\n",
      "test: loss=0.25825046801818696 acc=0.8899082568807339\n",
      "EPOCH=264\n",
      "train: loss=0.0885643553809668 acc=0.9610091743119266\n",
      "test: loss=0.30070855874522817 acc=0.8646788990825688\n",
      "EPOCH=265\n",
      "train: loss=0.13039763722367412 acc=0.9495412844036697\n",
      "test: loss=0.332737596835519 acc=0.8600917431192661\n",
      "EPOCH=266\n",
      "train: loss=0.1267312550755728 acc=0.9518348623853211\n",
      "test: loss=0.32510235739330945 acc=0.8807339449541285\n",
      "EPOCH=267\n",
      "train: loss=0.09092799609120013 acc=0.9747706422018348\n",
      "test: loss=0.2537693658686575 acc=0.8922018348623854\n",
      "EPOCH=268\n",
      "train: loss=0.186272400255014 acc=0.926605504587156\n",
      "test: loss=0.3096353798465048 acc=0.8761467889908257\n",
      "EPOCH=269\n",
      "train: loss=0.20853435610081064 acc=0.9311926605504587\n",
      "test: loss=0.2696623454376444 acc=0.8784403669724771\n",
      "EPOCH=270\n",
      "train: loss=0.18537713495701882 acc=0.9334862385321101\n",
      "test: loss=0.32101616687514606 acc=0.8715596330275229\n",
      "EPOCH=271\n",
      "train: loss=0.15207249888521907 acc=0.9426605504587156\n",
      "test: loss=0.25427033449184644 acc=0.8944954128440367\n",
      "EPOCH=272\n",
      "train: loss=0.19391625585728758 acc=0.9288990825688074\n",
      "test: loss=0.28359203953615764 acc=0.8853211009174312\n",
      "EPOCH=273\n",
      "train: loss=0.16171363013023665 acc=0.9403669724770642\n",
      "test: loss=0.3389427491922973 acc=0.8669724770642202\n",
      "EPOCH=274\n",
      "train: loss=0.17362939898668667 acc=0.9243119266055045\n",
      "test: loss=0.26895215702051606 acc=0.8784403669724771\n",
      "EPOCH=275\n",
      "train: loss=0.15937610568157015 acc=0.9541284403669725\n",
      "test: loss=0.2810881251610362 acc=0.8669724770642202\n",
      "EPOCH=276\n",
      "train: loss=0.15224375642569551 acc=0.9311926605504587\n",
      "test: loss=0.2676909808649484 acc=0.8899082568807339\n",
      "EPOCH=277\n",
      "train: loss=0.24662017310717904 acc=0.9151376146788991\n",
      "test: loss=0.2711153810843735 acc=0.8944954128440367\n",
      "EPOCH=278\n",
      "train: loss=0.14368778286495018 acc=0.9357798165137615\n",
      "test: loss=0.2832970849010171 acc=0.8853211009174312\n",
      "EPOCH=279\n",
      "train: loss=0.1858129185712156 acc=0.926605504587156\n",
      "test: loss=0.2610665774359413 acc=0.8876146788990825\n",
      "EPOCH=280\n",
      "train: loss=0.19899740764413792 acc=0.908256880733945\n",
      "test: loss=0.2899196119286066 acc=0.8692660550458715\n",
      "EPOCH=281\n",
      "train: loss=0.1216042689139084 acc=0.9495412844036697\n",
      "test: loss=0.3199020599395317 acc=0.8761467889908257\n",
      "EPOCH=282\n",
      "train: loss=0.14389064668466967 acc=0.9472477064220184\n",
      "test: loss=0.227982539733224 acc=0.8967889908256881\n",
      "EPOCH=283\n",
      "train: loss=0.19751853116174317 acc=0.9151376146788991\n",
      "test: loss=0.2728801653299662 acc=0.8830275229357798\n",
      "EPOCH=284\n",
      "train: loss=0.17480671153577798 acc=0.9334862385321101\n",
      "test: loss=0.30905118803406506 acc=0.8853211009174312\n",
      "EPOCH=285\n",
      "train: loss=0.15471917334319207 acc=0.9403669724770642\n",
      "test: loss=0.2710424884340469 acc=0.8784403669724771\n",
      "EPOCH=286\n",
      "train: loss=0.13679147945231326 acc=0.9472477064220184\n",
      "test: loss=0.2707414623764389 acc=0.8738532110091743\n",
      "EPOCH=287\n",
      "train: loss=0.1707120507514579 acc=0.9357798165137615\n",
      "test: loss=0.2729499426266425 acc=0.8967889908256881\n",
      "EPOCH=288\n",
      "train: loss=0.21768054603219789 acc=0.9243119266055045\n",
      "test: loss=0.26905072201431257 acc=0.8807339449541285\n",
      "EPOCH=289\n",
      "train: loss=0.17499774777544855 acc=0.944954128440367\n",
      "test: loss=0.2775544226159193 acc=0.8807339449541285\n",
      "EPOCH=290\n",
      "train: loss=0.17959403485470166 acc=0.9357798165137615\n",
      "test: loss=0.2713948364741149 acc=0.8784403669724771\n",
      "EPOCH=291\n",
      "train: loss=0.20803194013975693 acc=0.9288990825688074\n",
      "test: loss=0.2757190198079349 acc=0.8944954128440367\n",
      "EPOCH=292\n",
      "train: loss=0.13011062369114898 acc=0.9518348623853211\n",
      "test: loss=0.25146907697528464 acc=0.8807339449541285\n",
      "EPOCH=293\n",
      "train: loss=0.12559508783862108 acc=0.9564220183486238\n",
      "test: loss=0.2567476273070176 acc=0.8944954128440367\n",
      "EPOCH=294\n",
      "train: loss=0.1494730670444357 acc=0.9472477064220184\n",
      "test: loss=0.26703234430382616 acc=0.8899082568807339\n",
      "EPOCH=295\n",
      "train: loss=0.17245193848261983 acc=0.9174311926605505\n",
      "test: loss=0.20025766749496718 acc=0.9059633027522935\n",
      "EPOCH=296\n",
      "train: loss=0.21313177177331952 acc=0.908256880733945\n",
      "test: loss=0.2509290239898911 acc=0.8899082568807339\n",
      "EPOCH=297\n",
      "train: loss=0.14518806918568167 acc=0.9564220183486238\n",
      "test: loss=0.2952406372667401 acc=0.8761467889908257\n",
      "EPOCH=298\n",
      "train: loss=0.1587257146226905 acc=0.944954128440367\n",
      "test: loss=0.29464722407095745 acc=0.8922018348623854\n",
      "EPOCH=299\n",
      "train: loss=0.18184389952848398 acc=0.9380733944954128\n",
      "test: loss=0.28226731034509844 acc=0.8853211009174312\n",
      "EPOCH=300\n",
      "train: loss=0.15955341879212634 acc=0.9403669724770642\n",
      "test: loss=0.25085645447595073 acc=0.8738532110091743\n",
      "EPOCH=301\n",
      "train: loss=0.20442438252464387 acc=0.9197247706422018\n",
      "test: loss=0.24463552756241733 acc=0.8922018348623854\n",
      "EPOCH=302\n",
      "train: loss=0.14792622290829763 acc=0.9541284403669725\n",
      "test: loss=0.27518692765180547 acc=0.8853211009174312\n",
      "EPOCH=303\n",
      "train: loss=0.24203109139307025 acc=0.8990825688073395\n",
      "test: loss=0.2746008959753738 acc=0.8807339449541285\n",
      "EPOCH=304\n",
      "train: loss=0.18234964995415848 acc=0.9334862385321101\n",
      "test: loss=0.32514443363553125 acc=0.8623853211009175\n",
      "EPOCH=305\n",
      "train: loss=0.1412692735220998 acc=0.9288990825688074\n",
      "test: loss=0.2399104616054955 acc=0.8944954128440367\n",
      "EPOCH=306\n",
      "train: loss=0.19896460192136414 acc=0.9174311926605505\n",
      "test: loss=0.3139299722140161 acc=0.8830275229357798\n",
      "EPOCH=307\n",
      "train: loss=0.16054472878189344 acc=0.9403669724770642\n",
      "test: loss=0.27767778083331757 acc=0.8784403669724771\n",
      "EPOCH=308\n",
      "train: loss=0.2703733783945477 acc=0.8876146788990825\n",
      "test: loss=0.2704778098321188 acc=0.8807339449541285\n",
      "EPOCH=309\n",
      "train: loss=0.1831230776487104 acc=0.9220183486238532\n",
      "test: loss=0.28657360238662805 acc=0.8853211009174312\n",
      "EPOCH=310\n",
      "train: loss=0.20693693226991747 acc=0.9197247706422018\n",
      "test: loss=0.2435598087913226 acc=0.8853211009174312\n",
      "EPOCH=311\n",
      "train: loss=0.17929028858066343 acc=0.944954128440367\n",
      "test: loss=0.3013774247947988 acc=0.8784403669724771\n",
      "EPOCH=312\n",
      "train: loss=0.14825809649022795 acc=0.944954128440367\n",
      "test: loss=0.25500535361817667 acc=0.8853211009174312\n",
      "EPOCH=313\n",
      "train: loss=0.17057504079551078 acc=0.9380733944954128\n",
      "test: loss=0.2779925809662447 acc=0.8830275229357798\n",
      "EPOCH=314\n",
      "train: loss=0.2506561860556649 acc=0.9220183486238532\n",
      "test: loss=0.2705727689466983 acc=0.8944954128440367\n",
      "EPOCH=315\n",
      "train: loss=0.18307262277357364 acc=0.9334862385321101\n",
      "test: loss=0.30474283509990024 acc=0.8784403669724771\n",
      "EPOCH=316\n",
      "train: loss=0.13867592251537772 acc=0.9357798165137615\n",
      "test: loss=0.35352954230951483 acc=0.8646788990825688\n",
      "EPOCH=317\n",
      "train: loss=0.18504201293177358 acc=0.9403669724770642\n",
      "test: loss=0.23759805494975128 acc=0.8990825688073395\n",
      "EPOCH=318\n",
      "train: loss=0.15540800302693247 acc=0.926605504587156\n",
      "test: loss=0.21579593122272533 acc=0.9151376146788991\n",
      "EPOCH=319\n",
      "train: loss=0.14201567840523013 acc=0.9426605504587156\n",
      "test: loss=0.28145920262348384 acc=0.8715596330275229\n",
      "EPOCH=320\n",
      "train: loss=0.09228227171064665 acc=0.9564220183486238\n",
      "test: loss=0.27309993739296584 acc=0.8922018348623854\n",
      "EPOCH=321\n",
      "train: loss=0.14012804131666712 acc=0.9541284403669725\n",
      "test: loss=0.2974881103716044 acc=0.8853211009174312\n",
      "EPOCH=322\n",
      "train: loss=0.17399988877188088 acc=0.944954128440367\n",
      "test: loss=0.2506317342403427 acc=0.8876146788990825\n",
      "EPOCH=323\n",
      "train: loss=0.16340796594538626 acc=0.9357798165137615\n",
      "test: loss=0.25818693944498744 acc=0.8876146788990825\n",
      "EPOCH=324\n",
      "train: loss=0.10541575995843872 acc=0.9678899082568807\n",
      "test: loss=0.29501476187469494 acc=0.8807339449541285\n",
      "EPOCH=325\n",
      "train: loss=0.18752618875823296 acc=0.926605504587156\n",
      "test: loss=0.22755651842762806 acc=0.908256880733945\n",
      "EPOCH=326\n",
      "train: loss=0.1577095212237574 acc=0.9334862385321101\n",
      "test: loss=0.26269239257717303 acc=0.8830275229357798\n",
      "EPOCH=327\n",
      "train: loss=0.16835955485349055 acc=0.9403669724770642\n",
      "test: loss=0.2929761495544917 acc=0.8876146788990825\n",
      "EPOCH=328\n",
      "train: loss=0.09906038168652104 acc=0.963302752293578\n",
      "test: loss=0.27867629411341116 acc=0.8784403669724771\n",
      "EPOCH=329\n",
      "train: loss=0.14256793084436853 acc=0.9357798165137615\n",
      "test: loss=0.302583906365924 acc=0.8807339449541285\n",
      "EPOCH=330\n",
      "train: loss=0.19563720535774357 acc=0.9243119266055045\n",
      "test: loss=0.24676054585744894 acc=0.8967889908256881\n",
      "EPOCH=331\n",
      "train: loss=0.1920402925471198 acc=0.9288990825688074\n",
      "test: loss=0.2702292616513694 acc=0.8944954128440367\n",
      "EPOCH=332\n",
      "train: loss=0.0965856661542705 acc=0.9678899082568807\n",
      "test: loss=0.25088461635217185 acc=0.9105504587155964\n",
      "EPOCH=333\n",
      "train: loss=0.1559045390451266 acc=0.9403669724770642\n",
      "test: loss=0.2942989428377211 acc=0.8899082568807339\n",
      "EPOCH=334\n",
      "train: loss=0.13109667474252135 acc=0.9518348623853211\n",
      "test: loss=0.25750929246310744 acc=0.9036697247706422\n",
      "EPOCH=335\n",
      "train: loss=0.12103455871101779 acc=0.9472477064220184\n",
      "test: loss=0.272893341797296 acc=0.8899082568807339\n",
      "EPOCH=336\n",
      "train: loss=0.12541664611442496 acc=0.9495412844036697\n",
      "test: loss=0.25169868665552686 acc=0.8990825688073395\n",
      "EPOCH=337\n",
      "train: loss=0.2041003221493481 acc=0.9220183486238532\n",
      "test: loss=0.27221056246446923 acc=0.8853211009174312\n",
      "EPOCH=338\n",
      "train: loss=0.17681740719054045 acc=0.9288990825688074\n",
      "test: loss=0.279573818353791 acc=0.8761467889908257\n",
      "EPOCH=339\n",
      "train: loss=0.23990350488585072 acc=0.9059633027522935\n",
      "test: loss=0.283367815958457 acc=0.8876146788990825\n",
      "EPOCH=340\n",
      "train: loss=0.15496292452393232 acc=0.9495412844036697\n",
      "test: loss=0.3114860376358092 acc=0.8807339449541285\n",
      "EPOCH=341\n",
      "train: loss=0.2498108640506867 acc=0.9013761467889908\n",
      "test: loss=0.2680917732597303 acc=0.9013761467889908\n",
      "EPOCH=342\n",
      "train: loss=0.12713232299323496 acc=0.9655963302752294\n",
      "test: loss=0.2357755896308763 acc=0.8944954128440367\n",
      "EPOCH=343\n",
      "train: loss=0.1810250150374421 acc=0.9311926605504587\n",
      "test: loss=0.2568183504192844 acc=0.8944954128440367\n",
      "EPOCH=344\n",
      "train: loss=0.12327927959046305 acc=0.9587155963302753\n",
      "test: loss=0.25680685954715166 acc=0.8830275229357798\n",
      "EPOCH=345\n",
      "train: loss=0.16066326361601357 acc=0.9357798165137615\n",
      "test: loss=0.24615913722397065 acc=0.8899082568807339\n",
      "EPOCH=346\n",
      "train: loss=0.12124840241272716 acc=0.9495412844036697\n",
      "test: loss=0.3021182759525034 acc=0.8876146788990825\n",
      "EPOCH=347\n",
      "train: loss=0.10487669271643535 acc=0.9610091743119266\n",
      "test: loss=0.3389274600570009 acc=0.8738532110091743\n",
      "EPOCH=348\n",
      "train: loss=0.16015916878505645 acc=0.9357798165137615\n",
      "test: loss=0.29412221412036954 acc=0.8738532110091743\n",
      "EPOCH=349\n",
      "train: loss=0.13110814156499187 acc=0.9541284403669725\n",
      "test: loss=0.3021850190860095 acc=0.8784403669724771\n",
      "EPOCH=350\n",
      "train: loss=0.11785711575687327 acc=0.944954128440367\n",
      "test: loss=0.34950575168443027 acc=0.8692660550458715\n",
      "EPOCH=351\n",
      "train: loss=0.1041693298597864 acc=0.9701834862385321\n",
      "test: loss=0.2562234815558088 acc=0.8944954128440367\n",
      "EPOCH=352\n",
      "train: loss=0.15479132717084723 acc=0.9334862385321101\n",
      "test: loss=0.26444050453607343 acc=0.8876146788990825\n",
      "EPOCH=353\n",
      "train: loss=0.1336048777572689 acc=0.9334862385321101\n",
      "test: loss=0.2016061922334471 acc=0.9174311926605505\n",
      "EPOCH=354\n",
      "train: loss=0.1358278027708963 acc=0.9495412844036697\n",
      "test: loss=0.24412273700903997 acc=0.8876146788990825\n",
      "EPOCH=355\n",
      "train: loss=0.18756631533519588 acc=0.9243119266055045\n",
      "test: loss=0.22960219145557834 acc=0.8967889908256881\n",
      "EPOCH=356\n",
      "train: loss=0.16383617102489872 acc=0.9495412844036697\n",
      "test: loss=0.26733832798695045 acc=0.8876146788990825\n",
      "EPOCH=357\n",
      "train: loss=0.13988823630370786 acc=0.9426605504587156\n",
      "test: loss=0.24925538764115565 acc=0.8899082568807339\n",
      "EPOCH=358\n",
      "train: loss=0.1020568395746921 acc=0.9610091743119266\n",
      "test: loss=0.23221193844372892 acc=0.9013761467889908\n",
      "EPOCH=359\n",
      "train: loss=0.14838304424508386 acc=0.9288990825688074\n",
      "test: loss=0.2395653680551461 acc=0.908256880733945\n",
      "EPOCH=360\n",
      "train: loss=0.13127472350193123 acc=0.9587155963302753\n",
      "test: loss=0.2918405795500326 acc=0.8830275229357798\n",
      "EPOCH=361\n",
      "train: loss=0.21479001558795055 acc=0.8990825688073395\n",
      "test: loss=0.2846840591426106 acc=0.8899082568807339\n",
      "EPOCH=362\n",
      "train: loss=0.1891263510326869 acc=0.9243119266055045\n",
      "test: loss=0.2379847946960619 acc=0.8967889908256881\n",
      "EPOCH=363\n",
      "train: loss=0.09938663314160627 acc=0.9678899082568807\n",
      "test: loss=0.24239010748796438 acc=0.8876146788990825\n",
      "EPOCH=364\n",
      "train: loss=0.18506774632936904 acc=0.9288990825688074\n",
      "test: loss=0.24643159464673345 acc=0.9013761467889908\n",
      "EPOCH=365\n",
      "train: loss=0.22339640799582938 acc=0.9036697247706422\n",
      "test: loss=0.27216179191276224 acc=0.8807339449541285\n",
      "EPOCH=366\n",
      "train: loss=0.22515853959908394 acc=0.9243119266055045\n",
      "test: loss=0.282715815553443 acc=0.8944954128440367\n",
      "EPOCH=367\n",
      "train: loss=0.15581703374587344 acc=0.9403669724770642\n",
      "test: loss=0.2152890001700163 acc=0.9105504587155964\n",
      "EPOCH=368\n",
      "train: loss=0.1345953868226399 acc=0.9518348623853211\n",
      "test: loss=0.2676372757201903 acc=0.9013761467889908\n",
      "EPOCH=369\n",
      "train: loss=0.18412166327384608 acc=0.9380733944954128\n",
      "test: loss=0.26108942585938716 acc=0.8853211009174312\n",
      "EPOCH=370\n",
      "train: loss=0.15316596818030426 acc=0.944954128440367\n",
      "test: loss=0.2554745521193948 acc=0.8990825688073395\n",
      "EPOCH=371\n",
      "train: loss=0.14740241344939814 acc=0.9311926605504587\n",
      "test: loss=0.2351872028577487 acc=0.8990825688073395\n",
      "EPOCH=372\n",
      "train: loss=0.10944211309556233 acc=0.9518348623853211\n",
      "test: loss=0.2165612637210364 acc=0.908256880733945\n",
      "EPOCH=373\n",
      "train: loss=0.16493386396511453 acc=0.9357798165137615\n",
      "test: loss=0.2717286616967355 acc=0.8899082568807339\n",
      "EPOCH=374\n",
      "train: loss=0.1326882331682414 acc=0.9495412844036697\n",
      "test: loss=0.25836371297037813 acc=0.8944954128440367\n",
      "EPOCH=375\n",
      "train: loss=0.1523508244197116 acc=0.9357798165137615\n",
      "test: loss=0.2543757711425469 acc=0.8944954128440367\n",
      "EPOCH=376\n",
      "train: loss=0.1420330984418423 acc=0.9518348623853211\n",
      "test: loss=0.26921389027358184 acc=0.8944954128440367\n",
      "EPOCH=377\n",
      "train: loss=0.14832490357450867 acc=0.9380733944954128\n",
      "test: loss=0.26300256016879864 acc=0.8853211009174312\n",
      "EPOCH=378\n",
      "train: loss=0.2006612520537509 acc=0.9288990825688074\n",
      "test: loss=0.30552246984803766 acc=0.8784403669724771\n",
      "EPOCH=379\n",
      "train: loss=0.16758662566213534 acc=0.9380733944954128\n",
      "test: loss=0.28026630815901843 acc=0.8922018348623854\n",
      "EPOCH=380\n",
      "train: loss=0.11867562188508826 acc=0.9472477064220184\n",
      "test: loss=0.3132584893746602 acc=0.8669724770642202\n",
      "EPOCH=381\n",
      "train: loss=0.10627407924998172 acc=0.9587155963302753\n",
      "test: loss=0.23091721191158782 acc=0.9013761467889908\n",
      "EPOCH=382\n",
      "train: loss=0.17082194029848652 acc=0.9357798165137615\n",
      "test: loss=0.2766192397756941 acc=0.8853211009174312\n",
      "EPOCH=383\n",
      "train: loss=0.14491144606460632 acc=0.963302752293578\n",
      "test: loss=0.3621118765701801 acc=0.8555045871559633\n",
      "EPOCH=384\n",
      "train: loss=0.15935126176375022 acc=0.9288990825688074\n",
      "test: loss=0.26634187440779644 acc=0.9036697247706422\n",
      "EPOCH=385\n",
      "train: loss=0.10851509253192244 acc=0.9495412844036697\n",
      "test: loss=0.2436106490814255 acc=0.8853211009174312\n",
      "EPOCH=386\n",
      "train: loss=0.22876139441677298 acc=0.9197247706422018\n",
      "test: loss=0.2661056835623871 acc=0.8876146788990825\n",
      "EPOCH=387\n",
      "train: loss=0.15520436358108877 acc=0.9334862385321101\n",
      "test: loss=0.2599192976688084 acc=0.8944954128440367\n",
      "EPOCH=388\n",
      "train: loss=0.12891979240564685 acc=0.9472477064220184\n",
      "test: loss=0.2300762637812836 acc=0.9013761467889908\n",
      "EPOCH=389\n",
      "train: loss=0.17289983594954533 acc=0.9288990825688074\n",
      "test: loss=0.24592972285141126 acc=0.9036697247706422\n",
      "EPOCH=390\n",
      "train: loss=0.101221691635503 acc=0.963302752293578\n",
      "test: loss=0.28895384033778154 acc=0.8807339449541285\n",
      "EPOCH=391\n",
      "train: loss=0.1281163281704443 acc=0.9610091743119266\n",
      "test: loss=0.2718988031631477 acc=0.8990825688073395\n",
      "EPOCH=392\n",
      "train: loss=0.1377717692995972 acc=0.9495412844036697\n",
      "test: loss=0.2908203534177121 acc=0.8692660550458715\n",
      "EPOCH=393\n",
      "train: loss=0.14067186659770559 acc=0.944954128440367\n",
      "test: loss=0.27800965406555134 acc=0.8876146788990825\n",
      "EPOCH=394\n",
      "train: loss=0.12859655790017033 acc=0.9541284403669725\n",
      "test: loss=0.2752980255495819 acc=0.8853211009174312\n",
      "EPOCH=395\n",
      "train: loss=0.1401589987596618 acc=0.9426605504587156\n",
      "test: loss=0.31120821459069387 acc=0.8784403669724771\n",
      "EPOCH=396\n",
      "train: loss=0.22136232659827398 acc=0.9197247706422018\n",
      "test: loss=0.2572129093720901 acc=0.8899082568807339\n",
      "EPOCH=397\n",
      "train: loss=0.18332607656289546 acc=0.9288990825688074\n",
      "test: loss=0.26014489317180034 acc=0.8853211009174312\n",
      "EPOCH=398\n",
      "train: loss=0.17290187730529955 acc=0.9426605504587156\n",
      "test: loss=0.2619112996225974 acc=0.8876146788990825\n",
      "EPOCH=399\n",
      "train: loss=0.13811671300523337 acc=0.9426605504587156\n",
      "test: loss=0.2649433890623344 acc=0.9013761467889908\n",
      "EPOCH=400\n",
      "train: loss=0.10037559181511574 acc=0.9587155963302753\n",
      "test: loss=0.28176414618394413 acc=0.8967889908256881\n",
      "EPOCH=401\n",
      "train: loss=0.15912127360829434 acc=0.9380733944954128\n",
      "test: loss=0.2676920564527986 acc=0.8922018348623854\n",
      "EPOCH=402\n",
      "train: loss=0.1691575589236331 acc=0.944954128440367\n",
      "test: loss=0.26539281191944303 acc=0.8761467889908257\n",
      "EPOCH=403\n",
      "train: loss=0.13727876123430302 acc=0.9587155963302753\n",
      "test: loss=0.27813943107389066 acc=0.8899082568807339\n",
      "EPOCH=404\n",
      "train: loss=0.17924708147031262 acc=0.9288990825688074\n",
      "test: loss=0.2489042330388037 acc=0.8876146788990825\n",
      "EPOCH=405\n",
      "train: loss=0.11503205716296419 acc=0.9610091743119266\n",
      "test: loss=0.30974961986773614 acc=0.8738532110091743\n",
      "EPOCH=406\n",
      "train: loss=0.1487614225578741 acc=0.9426605504587156\n",
      "test: loss=0.2601484908491755 acc=0.8876146788990825\n",
      "EPOCH=407\n",
      "train: loss=0.18346208588139568 acc=0.9197247706422018\n",
      "test: loss=0.2794465337497601 acc=0.8899082568807339\n",
      "EPOCH=408\n",
      "train: loss=0.15537115846336746 acc=0.9403669724770642\n",
      "test: loss=0.24856006410348247 acc=0.8899082568807339\n",
      "EPOCH=409\n",
      "train: loss=0.23854176646210443 acc=0.908256880733945\n",
      "test: loss=0.2638074454596141 acc=0.8899082568807339\n",
      "EPOCH=410\n",
      "train: loss=0.09258669957195115 acc=0.9678899082568807\n",
      "test: loss=0.2637171292851749 acc=0.8853211009174312\n",
      "EPOCH=411\n",
      "train: loss=0.18675351236371052 acc=0.9288990825688074\n",
      "test: loss=0.32264095850397323 acc=0.8669724770642202\n",
      "EPOCH=412\n",
      "train: loss=0.20859441056324532 acc=0.908256880733945\n",
      "test: loss=0.23209257779693923 acc=0.9059633027522935\n",
      "EPOCH=413\n",
      "train: loss=0.19521411894429525 acc=0.9288990825688074\n",
      "test: loss=0.30727870679633834 acc=0.8899082568807339\n",
      "EPOCH=414\n",
      "train: loss=0.20172002199932088 acc=0.9220183486238532\n",
      "test: loss=0.24203716241100862 acc=0.9036697247706422\n",
      "EPOCH=415\n",
      "train: loss=0.15642649025845323 acc=0.9380733944954128\n",
      "test: loss=0.3553601015102618 acc=0.8577981651376146\n",
      "EPOCH=416\n",
      "train: loss=0.15721390870814686 acc=0.9288990825688074\n",
      "test: loss=0.26696363297617415 acc=0.8853211009174312\n",
      "EPOCH=417\n",
      "train: loss=0.128455346726201 acc=0.9357798165137615\n",
      "test: loss=0.25364352795644945 acc=0.9105504587155964\n",
      "EPOCH=418\n",
      "train: loss=0.18260376351149568 acc=0.9311926605504587\n",
      "test: loss=0.25558559118987517 acc=0.8944954128440367\n",
      "EPOCH=419\n",
      "train: loss=0.190084018819403 acc=0.9357798165137615\n",
      "test: loss=0.30016959764286005 acc=0.8944954128440367\n",
      "EPOCH=420\n",
      "train: loss=0.09810906943795787 acc=0.9701834862385321\n",
      "test: loss=0.28929284422392665 acc=0.8876146788990825\n",
      "EPOCH=421\n",
      "train: loss=0.09762539913145403 acc=0.9564220183486238\n",
      "test: loss=0.21568728085532204 acc=0.9013761467889908\n",
      "EPOCH=422\n",
      "train: loss=0.1561466483429369 acc=0.9541284403669725\n",
      "test: loss=0.23572674640309774 acc=0.908256880733945\n",
      "EPOCH=423\n",
      "train: loss=0.13997575301881712 acc=0.9564220183486238\n",
      "test: loss=0.23672646532332822 acc=0.9174311926605505\n",
      "EPOCH=424\n",
      "train: loss=0.15590404948373277 acc=0.9334862385321101\n",
      "test: loss=0.2780071582165836 acc=0.8922018348623854\n",
      "EPOCH=425\n",
      "train: loss=0.23652736162381516 acc=0.9151376146788991\n",
      "test: loss=0.24741000105212738 acc=0.9036697247706422\n",
      "EPOCH=426\n",
      "train: loss=0.13209493524884774 acc=0.9426605504587156\n",
      "test: loss=0.2610729322200746 acc=0.8967889908256881\n",
      "EPOCH=427\n",
      "train: loss=0.0967111326683083 acc=0.9724770642201835\n",
      "test: loss=0.21880144319571856 acc=0.9059633027522935\n",
      "EPOCH=428\n",
      "train: loss=0.09436974084868278 acc=0.9655963302752294\n",
      "test: loss=0.2078614456492412 acc=0.9151376146788991\n",
      "EPOCH=429\n",
      "train: loss=0.16378142979124505 acc=0.9472477064220184\n",
      "test: loss=0.22549528509557787 acc=0.9013761467889908\n",
      "EPOCH=430\n",
      "train: loss=0.12056931910701969 acc=0.9541284403669725\n",
      "test: loss=0.2662035565442655 acc=0.8922018348623854\n",
      "EPOCH=431\n",
      "train: loss=0.20941332807633883 acc=0.9197247706422018\n",
      "test: loss=0.22669637041617619 acc=0.9059633027522935\n",
      "EPOCH=432\n",
      "train: loss=0.10487498195889887 acc=0.9610091743119266\n",
      "test: loss=0.31950819867221886 acc=0.8669724770642202\n",
      "EPOCH=433\n",
      "train: loss=0.11505907459890213 acc=0.9564220183486238\n",
      "test: loss=0.27131976563542015 acc=0.8876146788990825\n",
      "EPOCH=434\n",
      "train: loss=0.21317514391632902 acc=0.9174311926605505\n",
      "test: loss=0.2662971045460843 acc=0.8967889908256881\n",
      "EPOCH=435\n",
      "train: loss=0.17862805391089956 acc=0.9174311926605505\n",
      "test: loss=0.27697069396487733 acc=0.8830275229357798\n",
      "EPOCH=436\n",
      "train: loss=0.19021238554619319 acc=0.9311926605504587\n",
      "test: loss=0.2807825666727572 acc=0.8922018348623854\n",
      "EPOCH=437\n",
      "train: loss=0.1369836753491877 acc=0.9403669724770642\n",
      "test: loss=0.24686706937432784 acc=0.9036697247706422\n",
      "EPOCH=438\n",
      "train: loss=0.15866296689825143 acc=0.9288990825688074\n",
      "test: loss=0.3258295989784558 acc=0.8853211009174312\n",
      "EPOCH=439\n",
      "train: loss=0.09495648158775802 acc=0.9610091743119266\n",
      "test: loss=0.2671440131800617 acc=0.8967889908256881\n",
      "EPOCH=440\n",
      "train: loss=0.19055135880917795 acc=0.926605504587156\n",
      "test: loss=0.2542702841647945 acc=0.9013761467889908\n",
      "EPOCH=441\n",
      "train: loss=0.11637730867324286 acc=0.9564220183486238\n",
      "test: loss=0.30406363355956795 acc=0.8967889908256881\n",
      "EPOCH=442\n",
      "train: loss=0.10949807415731037 acc=0.9541284403669725\n",
      "test: loss=0.3443118370151544 acc=0.8555045871559633\n",
      "EPOCH=443\n",
      "train: loss=0.17388380927347447 acc=0.9334862385321101\n",
      "test: loss=0.24708318468936877 acc=0.908256880733945\n",
      "EPOCH=444\n",
      "train: loss=0.09532849729291848 acc=0.963302752293578\n",
      "test: loss=0.31122038250874867 acc=0.8876146788990825\n",
      "EPOCH=445\n",
      "train: loss=0.17879679294241616 acc=0.9311926605504587\n",
      "test: loss=0.2678705659311926 acc=0.8922018348623854\n",
      "EPOCH=446\n",
      "train: loss=0.10132843017556294 acc=0.9678899082568807\n",
      "test: loss=0.2870053944800565 acc=0.8853211009174312\n",
      "EPOCH=447\n",
      "train: loss=0.12997453740455836 acc=0.9518348623853211\n",
      "test: loss=0.28065102364703143 acc=0.8944954128440367\n",
      "EPOCH=448\n",
      "train: loss=0.149557004949163 acc=0.9357798165137615\n",
      "test: loss=0.2252377877295388 acc=0.9059633027522935\n",
      "EPOCH=449\n",
      "train: loss=0.15463659277847622 acc=0.9403669724770642\n",
      "test: loss=0.275080922593075 acc=0.8830275229357798\n",
      "EPOCH=450\n",
      "train: loss=0.10894999795560999 acc=0.9495412844036697\n",
      "test: loss=0.2255728558194959 acc=0.9059633027522935\n",
      "EPOCH=451\n",
      "train: loss=0.17362996492343155 acc=0.926605504587156\n",
      "test: loss=0.3069138993892427 acc=0.8830275229357798\n",
      "EPOCH=452\n",
      "train: loss=0.0967302043171773 acc=0.9610091743119266\n",
      "test: loss=0.2535539054835911 acc=0.8944954128440367\n",
      "EPOCH=453\n",
      "train: loss=0.14847375074008426 acc=0.9564220183486238\n",
      "test: loss=0.2746329681246734 acc=0.8876146788990825\n",
      "EPOCH=454\n",
      "train: loss=0.1929405862779854 acc=0.9311926605504587\n",
      "test: loss=0.21650843913171638 acc=0.9151376146788991\n",
      "EPOCH=455\n",
      "train: loss=0.17686341518461404 acc=0.9243119266055045\n",
      "test: loss=0.25854783297524847 acc=0.8990825688073395\n",
      "EPOCH=456\n",
      "train: loss=0.18934252305673796 acc=0.926605504587156\n",
      "test: loss=0.247314766623628 acc=0.9013761467889908\n",
      "EPOCH=457\n",
      "train: loss=0.12436083485907878 acc=0.9426605504587156\n",
      "test: loss=0.23578355045319102 acc=0.9105504587155964\n",
      "EPOCH=458\n",
      "train: loss=0.16740457945382847 acc=0.9357798165137615\n",
      "test: loss=0.3238302690565702 acc=0.8784403669724771\n",
      "EPOCH=459\n",
      "train: loss=0.12691501151375012 acc=0.9587155963302753\n",
      "test: loss=0.22821374980261916 acc=0.9036697247706422\n",
      "EPOCH=460\n",
      "train: loss=0.16056252874140364 acc=0.926605504587156\n",
      "test: loss=0.21779736920472414 acc=0.9059633027522935\n",
      "EPOCH=461\n",
      "train: loss=0.1849053473013543 acc=0.9243119266055045\n",
      "test: loss=0.2856886135851401 acc=0.9013761467889908\n",
      "EPOCH=462\n",
      "train: loss=0.08192918257776283 acc=0.9724770642201835\n",
      "test: loss=0.22943641602449635 acc=0.9036697247706422\n",
      "EPOCH=463\n",
      "train: loss=0.1260424454180021 acc=0.9380733944954128\n",
      "test: loss=0.1888012091368952 acc=0.9197247706422018\n",
      "EPOCH=464\n",
      "train: loss=0.21697251745685303 acc=0.9174311926605505\n",
      "test: loss=0.24954652303585043 acc=0.8967889908256881\n",
      "EPOCH=465\n",
      "train: loss=0.13552011816472187 acc=0.944954128440367\n",
      "test: loss=0.3061454930737134 acc=0.8807339449541285\n",
      "EPOCH=466\n",
      "train: loss=0.14596659964658645 acc=0.9380733944954128\n",
      "test: loss=0.28755959219952365 acc=0.8830275229357798\n",
      "EPOCH=467\n",
      "train: loss=0.11266093484970068 acc=0.9495412844036697\n",
      "test: loss=0.24137130344372287 acc=0.8990825688073395\n",
      "EPOCH=468\n",
      "train: loss=0.13236631120515616 acc=0.9495412844036697\n",
      "test: loss=0.23391607660579744 acc=0.8990825688073395\n",
      "EPOCH=469\n",
      "train: loss=0.2682123534059189 acc=0.9105504587155964\n",
      "test: loss=0.24411898527375034 acc=0.9013761467889908\n",
      "EPOCH=470\n",
      "train: loss=0.11148870917960073 acc=0.9564220183486238\n",
      "test: loss=0.2442908954981844 acc=0.8944954128440367\n",
      "EPOCH=471\n",
      "train: loss=0.17177121711251966 acc=0.9288990825688074\n",
      "test: loss=0.24481540182772102 acc=0.8899082568807339\n",
      "EPOCH=472\n",
      "train: loss=0.1791963222383781 acc=0.9357798165137615\n",
      "test: loss=0.2447589105351601 acc=0.8967889908256881\n",
      "EPOCH=473\n",
      "train: loss=0.12905298825133363 acc=0.9472477064220184\n",
      "test: loss=0.21738273141694459 acc=0.9105504587155964\n",
      "EPOCH=474\n",
      "train: loss=0.21104173424487083 acc=0.926605504587156\n",
      "test: loss=0.26809585432095656 acc=0.8990825688073395\n",
      "EPOCH=475\n",
      "train: loss=0.23384819792450512 acc=0.9243119266055045\n",
      "test: loss=0.2620097621603595 acc=0.8922018348623854\n",
      "EPOCH=476\n",
      "train: loss=0.13902989749993278 acc=0.944954128440367\n",
      "test: loss=0.24198062724211952 acc=0.9105504587155964\n",
      "EPOCH=477\n",
      "train: loss=0.15681632362259573 acc=0.9426605504587156\n",
      "test: loss=0.23493536804556128 acc=0.8922018348623854\n",
      "EPOCH=478\n",
      "train: loss=0.16347111188386124 acc=0.944954128440367\n",
      "test: loss=0.3029628392213407 acc=0.8738532110091743\n",
      "EPOCH=479\n",
      "train: loss=0.08339639159095065 acc=0.9678899082568807\n",
      "test: loss=0.2641365783243516 acc=0.8922018348623854\n",
      "EPOCH=480\n",
      "train: loss=0.15449631585666565 acc=0.9564220183486238\n",
      "test: loss=0.27594775805904914 acc=0.9013761467889908\n",
      "EPOCH=481\n",
      "train: loss=0.15229218747283102 acc=0.9357798165137615\n",
      "test: loss=0.28642544041611373 acc=0.8830275229357798\n",
      "EPOCH=482\n",
      "train: loss=0.12533072613445723 acc=0.9403669724770642\n",
      "test: loss=0.25889666710913645 acc=0.8990825688073395\n",
      "EPOCH=483\n",
      "train: loss=0.12579023490440544 acc=0.9518348623853211\n",
      "test: loss=0.30813459843486496 acc=0.8876146788990825\n",
      "EPOCH=484\n",
      "train: loss=0.15529446631541846 acc=0.9472477064220184\n",
      "test: loss=0.24612977366532515 acc=0.9036697247706422\n",
      "EPOCH=485\n",
      "train: loss=0.142942915116047 acc=0.9541284403669725\n",
      "test: loss=0.28945943420004616 acc=0.8922018348623854\n",
      "EPOCH=486\n",
      "train: loss=0.1612046301437131 acc=0.9380733944954128\n",
      "test: loss=0.24097506670399801 acc=0.9036697247706422\n",
      "EPOCH=487\n",
      "train: loss=0.16530791293589145 acc=0.9311926605504587\n",
      "test: loss=0.21035493562993313 acc=0.9013761467889908\n",
      "EPOCH=488\n",
      "train: loss=0.09541936473048815 acc=0.9587155963302753\n",
      "test: loss=0.27895101229808994 acc=0.8853211009174312\n",
      "EPOCH=489\n",
      "train: loss=0.07879203759497783 acc=0.963302752293578\n",
      "test: loss=0.2577998061172811 acc=0.8899082568807339\n",
      "EPOCH=490\n",
      "train: loss=0.1614500200244951 acc=0.9518348623853211\n",
      "test: loss=0.25305616798157554 acc=0.8853211009174312\n",
      "EPOCH=491\n",
      "train: loss=0.09658291796748632 acc=0.963302752293578\n",
      "test: loss=0.2643801354766578 acc=0.8944954128440367\n",
      "EPOCH=492\n",
      "train: loss=0.11022215554100935 acc=0.9518348623853211\n",
      "test: loss=0.2881968666679365 acc=0.8899082568807339\n",
      "EPOCH=493\n",
      "train: loss=0.1698203161657226 acc=0.944954128440367\n",
      "test: loss=0.2200236326311852 acc=0.908256880733945\n",
      "EPOCH=494\n",
      "train: loss=0.07067784191047143 acc=0.9701834862385321\n",
      "test: loss=0.27126765383887885 acc=0.9059633027522935\n",
      "EPOCH=495\n",
      "train: loss=0.10515087992142695 acc=0.9587155963302753\n",
      "test: loss=0.2653493742856944 acc=0.8944954128440367\n",
      "EPOCH=496\n",
      "train: loss=0.10752047399057996 acc=0.9518348623853211\n",
      "test: loss=0.21668066556573753 acc=0.9105504587155964\n",
      "EPOCH=497\n",
      "train: loss=0.1767461442486722 acc=0.9426605504587156\n",
      "test: loss=0.29352525163601306 acc=0.8944954128440367\n",
      "EPOCH=498\n",
      "train: loss=0.15287145594973764 acc=0.9426605504587156\n",
      "test: loss=0.2109648177175869 acc=0.926605504587156\n",
      "EPOCH=499\n",
      "train: loss=0.14036042279973515 acc=0.9334862385321101\n",
      "test: loss=0.2625820129739935 acc=0.8922018348623854\n",
      "EPOCH=500\n",
      "train: loss=0.16620584921701667 acc=0.9334862385321101\n",
      "test: loss=0.2519483292078334 acc=0.8990825688073395\n",
      "EPOCH=501\n",
      "train: loss=0.16178832744691363 acc=0.9403669724770642\n",
      "test: loss=0.29559564981186737 acc=0.8990825688073395\n",
      "EPOCH=502\n",
      "train: loss=0.2045532567713739 acc=0.9174311926605505\n",
      "test: loss=0.25515601382404396 acc=0.8899082568807339\n",
      "EPOCH=503\n",
      "train: loss=0.2266692743070196 acc=0.9174311926605505\n",
      "test: loss=0.2677118591375906 acc=0.8944954128440367\n",
      "EPOCH=504\n",
      "train: loss=0.1841870179326655 acc=0.9036697247706422\n",
      "test: loss=0.299428531462461 acc=0.8853211009174312\n",
      "EPOCH=505\n",
      "train: loss=0.20137421252370286 acc=0.9380733944954128\n",
      "test: loss=0.27931873878983626 acc=0.8899082568807339\n",
      "EPOCH=506\n",
      "train: loss=0.1250167408650609 acc=0.9472477064220184\n",
      "test: loss=0.2490215252904888 acc=0.9013761467889908\n",
      "EPOCH=507\n",
      "train: loss=0.13551818649970793 acc=0.9472477064220184\n",
      "test: loss=0.24908937854264054 acc=0.8944954128440367\n",
      "EPOCH=508\n",
      "train: loss=0.14685596025864528 acc=0.9495412844036697\n",
      "test: loss=0.2376502474704195 acc=0.9013761467889908\n",
      "EPOCH=509\n",
      "train: loss=0.14314576299490736 acc=0.9541284403669725\n",
      "test: loss=0.25897222309748513 acc=0.9036697247706422\n",
      "EPOCH=510\n",
      "train: loss=0.13727089430428882 acc=0.9518348623853211\n",
      "test: loss=0.28181391184211113 acc=0.8876146788990825\n",
      "EPOCH=511\n",
      "train: loss=0.17042650746390067 acc=0.9334862385321101\n",
      "test: loss=0.2645987821455632 acc=0.908256880733945\n",
      "EPOCH=512\n",
      "train: loss=0.1482858818132821 acc=0.9426605504587156\n",
      "test: loss=0.3150330883145101 acc=0.8738532110091743\n",
      "EPOCH=513\n",
      "train: loss=0.19608241009156982 acc=0.9243119266055045\n",
      "test: loss=0.2800021238191461 acc=0.8922018348623854\n",
      "EPOCH=514\n",
      "train: loss=0.17190416913372936 acc=0.9472477064220184\n",
      "test: loss=0.2841996553979619 acc=0.8922018348623854\n",
      "EPOCH=515\n",
      "train: loss=0.1893419079419884 acc=0.9174311926605505\n",
      "test: loss=0.24460376042770948 acc=0.8944954128440367\n",
      "EPOCH=516\n",
      "train: loss=0.08607091609814102 acc=0.9610091743119266\n",
      "test: loss=0.25231262216933575 acc=0.8967889908256881\n",
      "EPOCH=517\n",
      "train: loss=0.195605154324863 acc=0.9311926605504587\n",
      "test: loss=0.28542642812393004 acc=0.8922018348623854\n",
      "EPOCH=518\n",
      "train: loss=0.15826888989396576 acc=0.9311926605504587\n",
      "test: loss=0.23712806481643392 acc=0.9151376146788991\n",
      "EPOCH=519\n",
      "train: loss=0.12227765465659908 acc=0.9541284403669725\n",
      "test: loss=0.26947563726789403 acc=0.8990825688073395\n",
      "EPOCH=520\n",
      "train: loss=0.13384994388740434 acc=0.9380733944954128\n",
      "test: loss=0.21614289607616588 acc=0.9105504587155964\n",
      "EPOCH=521\n",
      "train: loss=0.14933794880866405 acc=0.9403669724770642\n",
      "test: loss=0.37277912327787677 acc=0.8623853211009175\n",
      "EPOCH=522\n",
      "train: loss=0.19211350237961594 acc=0.9311926605504587\n",
      "test: loss=0.27284104105367213 acc=0.8967889908256881\n",
      "EPOCH=523\n",
      "train: loss=0.1155733770893714 acc=0.9610091743119266\n",
      "test: loss=0.25004149777863116 acc=0.8967889908256881\n",
      "EPOCH=524\n",
      "train: loss=0.10922415885146254 acc=0.9564220183486238\n",
      "test: loss=0.2766398828850316 acc=0.8967889908256881\n",
      "EPOCH=525\n",
      "train: loss=0.1533928109893632 acc=0.9472477064220184\n",
      "test: loss=0.2900036055938525 acc=0.8853211009174312\n",
      "EPOCH=526\n",
      "train: loss=0.24073254625589566 acc=0.9151376146788991\n",
      "test: loss=0.2532110003343343 acc=0.8899082568807339\n",
      "EPOCH=527\n",
      "train: loss=0.16310679645065565 acc=0.9403669724770642\n",
      "test: loss=0.2587665355491043 acc=0.8807339449541285\n",
      "EPOCH=528\n",
      "train: loss=0.135246068695661 acc=0.9564220183486238\n",
      "test: loss=0.2685026992757899 acc=0.8967889908256881\n",
      "EPOCH=529\n",
      "train: loss=0.12230682466910563 acc=0.9518348623853211\n",
      "test: loss=0.273592082285565 acc=0.8990825688073395\n",
      "EPOCH=530\n",
      "train: loss=0.10929550940703926 acc=0.9587155963302753\n",
      "test: loss=0.25054193922457396 acc=0.9105504587155964\n",
      "EPOCH=531\n",
      "train: loss=0.1484461495320391 acc=0.9403669724770642\n",
      "test: loss=0.28797521876988946 acc=0.9036697247706422\n",
      "EPOCH=532\n",
      "train: loss=0.15083783982029803 acc=0.9357798165137615\n",
      "test: loss=0.2756949841963914 acc=0.8922018348623854\n",
      "EPOCH=533\n",
      "train: loss=0.14998441439601978 acc=0.9380733944954128\n",
      "test: loss=0.2832818333017125 acc=0.8876146788990825\n",
      "EPOCH=534\n",
      "train: loss=0.13191797341008737 acc=0.9541284403669725\n",
      "test: loss=0.3072754093877446 acc=0.8876146788990825\n",
      "EPOCH=535\n",
      "train: loss=0.13268715988460258 acc=0.944954128440367\n",
      "test: loss=0.24907680279707972 acc=0.908256880733945\n",
      "EPOCH=536\n",
      "train: loss=0.08629461543029215 acc=0.9701834862385321\n",
      "test: loss=0.3272806250492457 acc=0.8784403669724771\n",
      "EPOCH=537\n",
      "train: loss=0.20085910890529715 acc=0.9311926605504587\n",
      "test: loss=0.30645295224398306 acc=0.8876146788990825\n",
      "EPOCH=538\n",
      "train: loss=0.209529789912341 acc=0.9334862385321101\n",
      "test: loss=0.2722896559095772 acc=0.9036697247706422\n",
      "EPOCH=539\n",
      "train: loss=0.11978109403444999 acc=0.944954128440367\n",
      "test: loss=0.2918515669444095 acc=0.8830275229357798\n",
      "EPOCH=540\n",
      "train: loss=0.1637046839337876 acc=0.9426605504587156\n",
      "test: loss=0.29543518384296497 acc=0.9105504587155964\n",
      "EPOCH=541\n",
      "train: loss=0.12295655870228364 acc=0.944954128440367\n",
      "test: loss=0.2851925373842501 acc=0.8967889908256881\n",
      "EPOCH=542\n",
      "train: loss=0.15539286513691294 acc=0.9403669724770642\n",
      "test: loss=0.23145314625249883 acc=0.9220183486238532\n",
      "EPOCH=543\n",
      "train: loss=0.12479619952335572 acc=0.9564220183486238\n",
      "test: loss=0.24174224548959183 acc=0.8922018348623854\n",
      "EPOCH=544\n",
      "train: loss=0.16603646743408043 acc=0.9472477064220184\n",
      "test: loss=0.24493803182342988 acc=0.9013761467889908\n",
      "EPOCH=545\n",
      "train: loss=0.056713146112699606 acc=0.9793577981651376\n",
      "test: loss=0.26315417185494583 acc=0.8967889908256881\n",
      "EPOCH=546\n",
      "train: loss=0.1305640825317994 acc=0.9495412844036697\n",
      "test: loss=0.2980000935190884 acc=0.9059633027522935\n",
      "EPOCH=547\n",
      "train: loss=0.18474862691301697 acc=0.9334862385321101\n",
      "test: loss=0.2604532050666317 acc=0.9128440366972477\n",
      "EPOCH=548\n",
      "train: loss=0.11761889460427354 acc=0.9541284403669725\n",
      "test: loss=0.28679174292300746 acc=0.8944954128440367\n",
      "EPOCH=549\n",
      "train: loss=0.20322378792375223 acc=0.9220183486238532\n",
      "test: loss=0.29243111768093594 acc=0.8876146788990825\n",
      "EPOCH=550\n",
      "train: loss=0.16517769016580458 acc=0.9288990825688074\n",
      "test: loss=0.3072910431162586 acc=0.8990825688073395\n",
      "EPOCH=551\n",
      "train: loss=0.14670574752903795 acc=0.9518348623853211\n",
      "test: loss=0.27126311107999507 acc=0.8944954128440367\n",
      "EPOCH=552\n",
      "train: loss=0.1292195181212216 acc=0.9518348623853211\n",
      "test: loss=0.23293522462316552 acc=0.9013761467889908\n",
      "EPOCH=553\n",
      "train: loss=0.19454733504220456 acc=0.9357798165137615\n",
      "test: loss=0.2322399648509714 acc=0.9036697247706422\n",
      "EPOCH=554\n",
      "train: loss=0.12139893055509701 acc=0.9541284403669725\n",
      "test: loss=0.2661097241036887 acc=0.908256880733945\n",
      "EPOCH=555\n",
      "train: loss=0.0967155805219444 acc=0.9587155963302753\n",
      "test: loss=0.24137033631437643 acc=0.8967889908256881\n",
      "EPOCH=556\n",
      "train: loss=0.2515723565105298 acc=0.9013761467889908\n",
      "test: loss=0.2963505808528079 acc=0.9059633027522935\n",
      "EPOCH=557\n",
      "train: loss=0.22095701988888614 acc=0.9059633027522935\n",
      "test: loss=0.23816885516288 acc=0.9105504587155964\n",
      "EPOCH=558\n",
      "train: loss=0.10422521953314137 acc=0.9678899082568807\n",
      "test: loss=0.26504822213850365 acc=0.8990825688073395\n",
      "EPOCH=559\n",
      "train: loss=0.14472578271731004 acc=0.9495412844036697\n",
      "test: loss=0.2498597298091176 acc=0.9013761467889908\n",
      "EPOCH=560\n",
      "train: loss=0.18276395202018775 acc=0.944954128440367\n",
      "test: loss=0.2819299684222589 acc=0.8876146788990825\n",
      "EPOCH=561\n",
      "train: loss=0.20185874195405637 acc=0.9311926605504587\n",
      "test: loss=0.21664756195836363 acc=0.9174311926605505\n",
      "EPOCH=562\n",
      "train: loss=0.23945894465654435 acc=0.9151376146788991\n",
      "test: loss=0.2415715567772783 acc=0.9174311926605505\n",
      "EPOCH=563\n",
      "train: loss=0.1941189261631213 acc=0.944954128440367\n",
      "test: loss=0.28006373538585005 acc=0.8830275229357798\n",
      "EPOCH=564\n",
      "train: loss=0.12622350046142997 acc=0.9518348623853211\n",
      "test: loss=0.2665416821816151 acc=0.8853211009174312\n",
      "EPOCH=565\n",
      "train: loss=0.18846428408170168 acc=0.9357798165137615\n",
      "test: loss=0.28449903701818324 acc=0.8990825688073395\n",
      "EPOCH=566\n",
      "train: loss=0.18331164818001291 acc=0.9357798165137615\n",
      "test: loss=0.26217765647716224 acc=0.908256880733945\n",
      "EPOCH=567\n",
      "train: loss=0.13757991692454674 acc=0.9426605504587156\n",
      "test: loss=0.3086326970493854 acc=0.8853211009174312\n",
      "EPOCH=568\n",
      "train: loss=0.1589340490749124 acc=0.9403669724770642\n",
      "test: loss=0.3260703024687822 acc=0.8899082568807339\n",
      "EPOCH=569\n",
      "train: loss=0.09308162725779902 acc=0.9564220183486238\n",
      "test: loss=0.2572985353571046 acc=0.9013761467889908\n",
      "EPOCH=570\n",
      "train: loss=0.18290057406475052 acc=0.9357798165137615\n",
      "test: loss=0.2504242338197906 acc=0.8784403669724771\n",
      "EPOCH=571\n",
      "train: loss=0.12216076492216313 acc=0.9541284403669725\n",
      "test: loss=0.22787922214867928 acc=0.9105504587155964\n",
      "EPOCH=572\n",
      "train: loss=0.14503754460582738 acc=0.944954128440367\n",
      "test: loss=0.29064803921716126 acc=0.8990825688073395\n",
      "EPOCH=573\n",
      "train: loss=0.14019528132722509 acc=0.9426605504587156\n",
      "test: loss=0.2628399911955946 acc=0.8967889908256881\n",
      "EPOCH=574\n",
      "train: loss=0.1446379789880018 acc=0.9495412844036697\n",
      "test: loss=0.25778038277248966 acc=0.8967889908256881\n",
      "EPOCH=575\n",
      "train: loss=0.17211432804229845 acc=0.9426605504587156\n",
      "test: loss=0.23796777219076468 acc=0.9128440366972477\n",
      "EPOCH=576\n",
      "train: loss=0.09330654237513143 acc=0.9655963302752294\n",
      "test: loss=0.25635713840661856 acc=0.9128440366972477\n",
      "EPOCH=577\n",
      "train: loss=0.16086114760289633 acc=0.9380733944954128\n",
      "test: loss=0.23178359785950053 acc=0.9105504587155964\n",
      "EPOCH=578\n",
      "train: loss=0.16052422007402092 acc=0.9403669724770642\n",
      "test: loss=0.21030105333185395 acc=0.9059633027522935\n",
      "EPOCH=579\n",
      "train: loss=0.14934304343288346 acc=0.9403669724770642\n",
      "test: loss=0.22376939482119695 acc=0.9151376146788991\n",
      "EPOCH=580\n",
      "train: loss=0.1637559699307789 acc=0.9311926605504587\n",
      "test: loss=0.20084824272636184 acc=0.9174311926605505\n",
      "EPOCH=581\n",
      "train: loss=0.0950792175232659 acc=0.9587155963302753\n",
      "test: loss=0.20168073766593259 acc=0.9128440366972477\n",
      "EPOCH=582\n",
      "train: loss=0.183646259655575 acc=0.926605504587156\n",
      "test: loss=0.25344765212298476 acc=0.8944954128440367\n",
      "EPOCH=583\n",
      "train: loss=0.12289217259484639 acc=0.9564220183486238\n",
      "test: loss=0.2696545448727288 acc=0.9059633027522935\n",
      "EPOCH=584\n",
      "train: loss=0.12268478271725143 acc=0.9495412844036697\n",
      "test: loss=0.2504873666485019 acc=0.8876146788990825\n",
      "EPOCH=585\n",
      "train: loss=0.22871820100013313 acc=0.9243119266055045\n",
      "test: loss=0.2687715230601839 acc=0.9105504587155964\n",
      "EPOCH=586\n",
      "train: loss=0.153935008381581 acc=0.9380733944954128\n",
      "test: loss=0.25575592438742506 acc=0.9128440366972477\n",
      "EPOCH=587\n",
      "train: loss=0.09534427558561495 acc=0.9587155963302753\n",
      "test: loss=0.24168996621417782 acc=0.9174311926605505\n",
      "EPOCH=588\n",
      "train: loss=0.1610867175696848 acc=0.9288990825688074\n",
      "test: loss=0.2967808480173957 acc=0.8967889908256881\n",
      "EPOCH=589\n",
      "train: loss=0.17770804420878558 acc=0.9403669724770642\n",
      "test: loss=0.2740897602870138 acc=0.8899082568807339\n",
      "EPOCH=590\n",
      "train: loss=0.13632556812946672 acc=0.9472477064220184\n",
      "test: loss=0.2563589462580572 acc=0.9059633027522935\n",
      "EPOCH=591\n",
      "train: loss=0.17546799414662112 acc=0.9220183486238532\n",
      "test: loss=0.28959477110500315 acc=0.8967889908256881\n",
      "EPOCH=592\n",
      "train: loss=0.1502187137757518 acc=0.9495412844036697\n",
      "test: loss=0.2399158936779673 acc=0.9036697247706422\n",
      "EPOCH=593\n",
      "train: loss=0.1507963039118017 acc=0.9518348623853211\n",
      "test: loss=0.3046835640621798 acc=0.8830275229357798\n",
      "EPOCH=594\n",
      "train: loss=0.10450692497819525 acc=0.9541284403669725\n",
      "test: loss=0.30934734236328815 acc=0.8922018348623854\n",
      "EPOCH=595\n",
      "train: loss=0.10603223659104218 acc=0.9564220183486238\n",
      "test: loss=0.19376862682619794 acc=0.9197247706422018\n",
      "EPOCH=596\n",
      "train: loss=0.166774506087962 acc=0.9426605504587156\n",
      "test: loss=0.2812132924483884 acc=0.9013761467889908\n",
      "EPOCH=597\n",
      "train: loss=0.19211969008601434 acc=0.9311926605504587\n",
      "test: loss=0.27878861994213655 acc=0.8876146788990825\n",
      "EPOCH=598\n",
      "train: loss=0.11204664822224557 acc=0.9541284403669725\n",
      "test: loss=0.2760538627072987 acc=0.908256880733945\n",
      "EPOCH=599\n",
      "train: loss=0.07883532538249674 acc=0.9655963302752294\n",
      "test: loss=0.25811378146921415 acc=0.9105504587155964\n",
      "EPOCH=600\n",
      "train: loss=0.1467572336218134 acc=0.9426605504587156\n",
      "test: loss=0.27023308228619547 acc=0.8944954128440367\n",
      "EPOCH=601\n",
      "train: loss=0.30214558565851346 acc=0.9013761467889908\n",
      "test: loss=0.2662172208424766 acc=0.8830275229357798\n",
      "EPOCH=602\n",
      "train: loss=0.13430812579459164 acc=0.9472477064220184\n",
      "test: loss=0.2540629736924379 acc=0.9013761467889908\n",
      "EPOCH=603\n",
      "train: loss=0.21971243516389716 acc=0.926605504587156\n",
      "test: loss=0.22071287972438605 acc=0.9059633027522935\n",
      "EPOCH=604\n",
      "train: loss=0.18411072457872873 acc=0.9357798165137615\n",
      "test: loss=0.21888053051921566 acc=0.9013761467889908\n",
      "EPOCH=605\n",
      "train: loss=0.2073244801581985 acc=0.9311926605504587\n",
      "test: loss=0.30207573887217093 acc=0.9013761467889908\n",
      "EPOCH=606\n",
      "train: loss=0.07805322262924734 acc=0.9655963302752294\n",
      "test: loss=0.29935522009668236 acc=0.9105504587155964\n",
      "EPOCH=607\n",
      "train: loss=0.19191865346318285 acc=0.9380733944954128\n",
      "test: loss=0.2893907157298786 acc=0.8922018348623854\n",
      "EPOCH=608\n",
      "train: loss=0.1430063205859186 acc=0.9541284403669725\n",
      "test: loss=0.24285400558308992 acc=0.8990825688073395\n",
      "EPOCH=609\n",
      "train: loss=0.11825994418850265 acc=0.9678899082568807\n",
      "test: loss=0.266880253733905 acc=0.8944954128440367\n",
      "EPOCH=610\n",
      "train: loss=0.13512005767561164 acc=0.9541284403669725\n",
      "test: loss=0.24535123899800215 acc=0.8967889908256881\n",
      "EPOCH=611\n",
      "train: loss=0.13712182172414178 acc=0.9518348623853211\n",
      "test: loss=0.2922598039705798 acc=0.8944954128440367\n",
      "EPOCH=612\n",
      "train: loss=0.11732424242108988 acc=0.9610091743119266\n",
      "test: loss=0.28171221109868966 acc=0.8944954128440367\n",
      "EPOCH=613\n",
      "train: loss=0.12268200111535973 acc=0.9541284403669725\n",
      "test: loss=0.27713508130782993 acc=0.8830275229357798\n",
      "EPOCH=614\n",
      "train: loss=0.1128002250438104 acc=0.9678899082568807\n",
      "test: loss=0.2752662286957693 acc=0.9059633027522935\n",
      "EPOCH=615\n",
      "train: loss=0.17866809254485236 acc=0.9472477064220184\n",
      "test: loss=0.25972188342749186 acc=0.9059633027522935\n",
      "EPOCH=616\n",
      "train: loss=0.07993082600722724 acc=0.9678899082568807\n",
      "test: loss=0.21146169142827997 acc=0.9105504587155964\n",
      "EPOCH=617\n",
      "train: loss=0.0994425427293465 acc=0.963302752293578\n",
      "test: loss=0.23447380750183047 acc=0.9174311926605505\n",
      "EPOCH=618\n",
      "train: loss=0.13909254546189498 acc=0.9472477064220184\n",
      "test: loss=0.29004527079412884 acc=0.908256880733945\n",
      "EPOCH=619\n",
      "train: loss=0.1786412996579059 acc=0.9357798165137615\n",
      "test: loss=0.24661631982126409 acc=0.9105504587155964\n",
      "EPOCH=620\n",
      "train: loss=0.1804350546652142 acc=0.9426605504587156\n",
      "test: loss=0.2536543398052664 acc=0.9059633027522935\n",
      "EPOCH=621\n",
      "train: loss=0.07809388860004539 acc=0.9655963302752294\n",
      "test: loss=0.23703295580023578 acc=0.8967889908256881\n",
      "EPOCH=622\n",
      "train: loss=0.16635211013436496 acc=0.9403669724770642\n",
      "test: loss=0.2685380402816027 acc=0.9036697247706422\n",
      "EPOCH=623\n",
      "train: loss=0.1322684525223961 acc=0.9472477064220184\n",
      "test: loss=0.2450238139214363 acc=0.9036697247706422\n",
      "EPOCH=624\n",
      "train: loss=0.1987497801525923 acc=0.9288990825688074\n",
      "test: loss=0.27980375401088553 acc=0.8830275229357798\n",
      "EPOCH=625\n",
      "train: loss=0.20954003895343967 acc=0.9243119266055045\n",
      "test: loss=0.29644807945290924 acc=0.8807339449541285\n",
      "EPOCH=626\n",
      "train: loss=0.21144545104227672 acc=0.9311926605504587\n",
      "test: loss=0.31460488067939535 acc=0.8990825688073395\n",
      "EPOCH=627\n",
      "train: loss=0.12163408036348698 acc=0.9587155963302753\n",
      "test: loss=0.310416830996007 acc=0.8922018348623854\n",
      "EPOCH=628\n",
      "train: loss=0.14413827471688045 acc=0.944954128440367\n",
      "test: loss=0.29288853937404397 acc=0.8807339449541285\n",
      "EPOCH=629\n",
      "train: loss=0.12209752219289094 acc=0.9655963302752294\n",
      "test: loss=0.27340246543708036 acc=0.9013761467889908\n",
      "EPOCH=630\n",
      "train: loss=0.11927349559038797 acc=0.9610091743119266\n",
      "test: loss=0.2811633300181641 acc=0.8899082568807339\n",
      "EPOCH=631\n",
      "train: loss=0.14353995677784498 acc=0.9426605504587156\n",
      "test: loss=0.2573237184407703 acc=0.908256880733945\n",
      "EPOCH=632\n",
      "train: loss=0.12875743228472722 acc=0.9564220183486238\n",
      "test: loss=0.3112703340184508 acc=0.8830275229357798\n",
      "EPOCH=633\n",
      "train: loss=0.07029082398113012 acc=0.9724770642201835\n",
      "test: loss=0.274632145004714 acc=0.9013761467889908\n",
      "EPOCH=634\n",
      "train: loss=0.16914899285161172 acc=0.9495412844036697\n",
      "test: loss=0.24531641455108336 acc=0.9036697247706422\n",
      "EPOCH=635\n",
      "train: loss=0.07633264903613769 acc=0.9610091743119266\n",
      "test: loss=0.2676305976253886 acc=0.8944954128440367\n",
      "EPOCH=636\n",
      "train: loss=0.1541558547189809 acc=0.944954128440367\n",
      "test: loss=0.2514648281268252 acc=0.8944954128440367\n",
      "EPOCH=637\n",
      "train: loss=0.15827588331899609 acc=0.9426605504587156\n",
      "test: loss=0.2619498670210421 acc=0.8944954128440367\n",
      "EPOCH=638\n",
      "train: loss=0.10031943930640679 acc=0.9564220183486238\n",
      "test: loss=0.2692490476874416 acc=0.9013761467889908\n",
      "EPOCH=639\n",
      "train: loss=0.14385529334971026 acc=0.9357798165137615\n",
      "test: loss=0.2595950891538401 acc=0.9036697247706422\n",
      "EPOCH=640\n",
      "train: loss=0.13879744284661655 acc=0.9495412844036697\n",
      "test: loss=0.355883387721603 acc=0.8830275229357798\n",
      "EPOCH=641\n",
      "train: loss=0.12808537127018554 acc=0.9655963302752294\n",
      "test: loss=0.20083310951045152 acc=0.9220183486238532\n",
      "EPOCH=642\n",
      "train: loss=0.11411791718938892 acc=0.9518348623853211\n",
      "test: loss=0.2741468805398721 acc=0.8990825688073395\n",
      "EPOCH=643\n",
      "train: loss=0.13198100358555356 acc=0.9564220183486238\n",
      "test: loss=0.28387724518381674 acc=0.8944954128440367\n",
      "EPOCH=644\n",
      "train: loss=0.21019890529487625 acc=0.9311926605504587\n",
      "test: loss=0.2588917503573475 acc=0.8967889908256881\n",
      "EPOCH=645\n",
      "train: loss=0.10061667168980959 acc=0.9587155963302753\n",
      "test: loss=0.23519651749068052 acc=0.9036697247706422\n",
      "EPOCH=646\n",
      "train: loss=0.12865915099085884 acc=0.9518348623853211\n",
      "test: loss=0.3394208319631287 acc=0.8876146788990825\n",
      "EPOCH=647\n",
      "train: loss=0.1563724833763702 acc=0.944954128440367\n",
      "test: loss=0.2994192059122905 acc=0.8922018348623854\n",
      "EPOCH=648\n",
      "train: loss=0.1727915316570875 acc=0.9426605504587156\n",
      "test: loss=0.2599056039918501 acc=0.8922018348623854\n",
      "EPOCH=649\n",
      "train: loss=0.2212856558410876 acc=0.9426605504587156\n",
      "test: loss=0.27509076951120104 acc=0.8990825688073395\n",
      "EPOCH=650\n",
      "train: loss=0.08950959613506829 acc=0.9541284403669725\n",
      "test: loss=0.27661897495689514 acc=0.8967889908256881\n",
      "EPOCH=651\n",
      "train: loss=0.17330919195392475 acc=0.9380733944954128\n",
      "test: loss=0.3034806226172812 acc=0.9105504587155964\n",
      "EPOCH=652\n",
      "train: loss=0.167650940201514 acc=0.9403669724770642\n",
      "test: loss=0.2928665103841111 acc=0.8899082568807339\n",
      "EPOCH=653\n",
      "train: loss=0.15982020424910792 acc=0.9472477064220184\n",
      "test: loss=0.3253180381617801 acc=0.8922018348623854\n",
      "EPOCH=654\n",
      "train: loss=0.14508524207196902 acc=0.9495412844036697\n",
      "test: loss=0.2020322216344973 acc=0.9174311926605505\n",
      "EPOCH=655\n",
      "train: loss=0.15886954501007514 acc=0.9357798165137615\n",
      "test: loss=0.26270397762160874 acc=0.8967889908256881\n",
      "EPOCH=656\n",
      "train: loss=0.1741421943354163 acc=0.9357798165137615\n",
      "test: loss=0.31261314513398064 acc=0.8830275229357798\n",
      "EPOCH=657\n",
      "train: loss=0.1868086353494815 acc=0.9426605504587156\n",
      "test: loss=0.25013165317925234 acc=0.9105504587155964\n",
      "EPOCH=658\n",
      "train: loss=0.18638372589642296 acc=0.9380733944954128\n",
      "test: loss=0.27091052971541446 acc=0.8922018348623854\n",
      "EPOCH=659\n",
      "train: loss=0.05993558196507699 acc=0.9724770642201835\n",
      "test: loss=0.3137320047742079 acc=0.8967889908256881\n",
      "EPOCH=660\n",
      "train: loss=0.13996289827382863 acc=0.9495412844036697\n",
      "test: loss=0.22281867224833565 acc=0.9105504587155964\n",
      "EPOCH=661\n",
      "train: loss=0.16924511966456296 acc=0.9380733944954128\n",
      "test: loss=0.32907933148834545 acc=0.8853211009174312\n",
      "EPOCH=662\n",
      "train: loss=0.2022342400603651 acc=0.9380733944954128\n",
      "test: loss=0.24839258063648287 acc=0.9036697247706422\n",
      "EPOCH=663\n",
      "train: loss=0.1124778909439963 acc=0.9541284403669725\n",
      "test: loss=0.21985912748404265 acc=0.908256880733945\n",
      "EPOCH=664\n",
      "train: loss=0.16039836450189818 acc=0.9518348623853211\n",
      "test: loss=0.27983226444994447 acc=0.9105504587155964\n",
      "EPOCH=665\n",
      "train: loss=0.14291789340314562 acc=0.9518348623853211\n",
      "test: loss=0.25006704557770754 acc=0.9151376146788991\n",
      "EPOCH=666\n",
      "train: loss=0.09472863115877352 acc=0.9610091743119266\n",
      "test: loss=0.2575313985863753 acc=0.8990825688073395\n",
      "EPOCH=667\n",
      "train: loss=0.1632554827777648 acc=0.9541284403669725\n",
      "test: loss=0.2850856019107813 acc=0.9013761467889908\n",
      "EPOCH=668\n",
      "train: loss=0.09261791326006602 acc=0.9655963302752294\n",
      "test: loss=0.309389887719826 acc=0.8830275229357798\n",
      "EPOCH=669\n",
      "train: loss=0.14078620812802312 acc=0.9495412844036697\n",
      "test: loss=0.2690681142692843 acc=0.9013761467889908\n",
      "EPOCH=670\n",
      "train: loss=0.0822437975184144 acc=0.963302752293578\n",
      "test: loss=0.20291305227989617 acc=0.9288990825688074\n",
      "EPOCH=671\n",
      "train: loss=0.07722457139425142 acc=0.9770642201834863\n",
      "test: loss=0.2565187880165531 acc=0.908256880733945\n",
      "EPOCH=672\n",
      "train: loss=0.05707900928059369 acc=0.9724770642201835\n",
      "test: loss=0.24122468259209565 acc=0.9036697247706422\n",
      "EPOCH=673\n",
      "train: loss=0.11445622809324621 acc=0.9564220183486238\n",
      "test: loss=0.2607997452847841 acc=0.9036697247706422\n",
      "EPOCH=674\n",
      "train: loss=0.093581892673994 acc=0.9655963302752294\n",
      "test: loss=0.2029332172314042 acc=0.9151376146788991\n",
      "EPOCH=675\n",
      "train: loss=0.094723458330794 acc=0.9541284403669725\n",
      "test: loss=0.30227544476149865 acc=0.8876146788990825\n",
      "EPOCH=676\n",
      "train: loss=0.06056426266260869 acc=0.9701834862385321\n",
      "test: loss=0.2833761908686423 acc=0.8899082568807339\n",
      "EPOCH=677\n",
      "train: loss=0.14739407207773292 acc=0.9334862385321101\n",
      "test: loss=0.25321787914527893 acc=0.9243119266055045\n",
      "EPOCH=678\n",
      "train: loss=0.11929750237242846 acc=0.9495412844036697\n",
      "test: loss=0.23247280921220762 acc=0.9105504587155964\n",
      "EPOCH=679\n",
      "train: loss=0.12551334705811842 acc=0.9495412844036697\n",
      "test: loss=0.21945300863051692 acc=0.9174311926605505\n",
      "EPOCH=680\n",
      "train: loss=0.12536468411758653 acc=0.9403669724770642\n",
      "test: loss=0.2943681442655991 acc=0.8922018348623854\n",
      "EPOCH=681\n",
      "train: loss=0.1565809879428348 acc=0.9495412844036697\n",
      "test: loss=0.27940080772773007 acc=0.908256880733945\n",
      "EPOCH=682\n",
      "train: loss=0.07067913982817912 acc=0.9724770642201835\n",
      "test: loss=0.2217185847118053 acc=0.9197247706422018\n",
      "EPOCH=683\n",
      "train: loss=0.23820049091429985 acc=0.9197247706422018\n",
      "test: loss=0.2392242546714509 acc=0.9197247706422018\n",
      "EPOCH=684\n",
      "train: loss=0.10870716883370393 acc=0.9655963302752294\n",
      "test: loss=0.2726412355416943 acc=0.9036697247706422\n",
      "EPOCH=685\n",
      "train: loss=0.28184142063308915 acc=0.8922018348623854\n",
      "test: loss=0.2717655222194317 acc=0.908256880733945\n",
      "EPOCH=686\n",
      "train: loss=0.09589868203219185 acc=0.9564220183486238\n",
      "test: loss=0.28417918220611615 acc=0.9036697247706422\n",
      "EPOCH=687\n",
      "train: loss=0.08639017329546915 acc=0.963302752293578\n",
      "test: loss=0.2569419825982996 acc=0.9128440366972477\n",
      "EPOCH=688\n",
      "train: loss=0.10424213319565727 acc=0.9655963302752294\n",
      "test: loss=0.248972894000484 acc=0.9013761467889908\n",
      "EPOCH=689\n",
      "train: loss=0.1700814412417843 acc=0.9380733944954128\n",
      "test: loss=0.2746583865531375 acc=0.9059633027522935\n",
      "EPOCH=690\n",
      "train: loss=0.1682266230089959 acc=0.9403669724770642\n",
      "test: loss=0.2148423087258347 acc=0.9105504587155964\n",
      "EPOCH=691\n",
      "train: loss=0.08412498180374892 acc=0.9610091743119266\n",
      "test: loss=0.2894901835727944 acc=0.8853211009174312\n",
      "EPOCH=692\n",
      "train: loss=0.1839963487687165 acc=0.9334862385321101\n",
      "test: loss=0.2463740043979943 acc=0.9105504587155964\n",
      "EPOCH=693\n",
      "train: loss=0.09273885941984278 acc=0.9587155963302753\n",
      "test: loss=0.2748592540551055 acc=0.908256880733945\n",
      "EPOCH=694\n",
      "train: loss=0.1198851839653814 acc=0.9518348623853211\n",
      "test: loss=0.23369701345790805 acc=0.8990825688073395\n",
      "EPOCH=695\n",
      "train: loss=0.08389377103239008 acc=0.9655963302752294\n",
      "test: loss=0.2688392422700911 acc=0.9059633027522935\n",
      "EPOCH=696\n",
      "train: loss=0.15270267168064666 acc=0.9472477064220184\n",
      "test: loss=0.26219182382233086 acc=0.9036697247706422\n",
      "EPOCH=697\n",
      "train: loss=0.11324946831594819 acc=0.963302752293578\n",
      "test: loss=0.2587190440433267 acc=0.9243119266055045\n",
      "EPOCH=698\n",
      "train: loss=0.09923112646085647 acc=0.9678899082568807\n",
      "test: loss=0.2957878503335996 acc=0.8990825688073395\n",
      "EPOCH=699\n",
      "train: loss=0.13902456305201508 acc=0.9495412844036697\n",
      "test: loss=0.2865983322200469 acc=0.8990825688073395\n",
      "EPOCH=700\n",
      "train: loss=0.2060967411525253 acc=0.9197247706422018\n",
      "test: loss=0.23027868572027188 acc=0.9151376146788991\n",
      "EPOCH=701\n",
      "train: loss=0.16489998696193708 acc=0.9403669724770642\n",
      "test: loss=0.2656501988069801 acc=0.9036697247706422\n",
      "EPOCH=702\n",
      "train: loss=0.1112712692637098 acc=0.9655963302752294\n",
      "test: loss=0.2992366762826835 acc=0.8967889908256881\n",
      "EPOCH=703\n",
      "train: loss=0.15216580402087415 acc=0.944954128440367\n",
      "test: loss=0.27375951603415966 acc=0.9036697247706422\n",
      "EPOCH=704\n",
      "train: loss=0.14217996602887958 acc=0.944954128440367\n",
      "test: loss=0.3143807118617839 acc=0.8944954128440367\n",
      "EPOCH=705\n",
      "train: loss=0.11273233958125814 acc=0.9587155963302753\n",
      "test: loss=0.2771208011451143 acc=0.9059633027522935\n",
      "EPOCH=706\n",
      "train: loss=0.1351187517829495 acc=0.9541284403669725\n",
      "test: loss=0.27188644425860226 acc=0.8990825688073395\n",
      "EPOCH=707\n",
      "train: loss=0.12525336778168644 acc=0.963302752293578\n",
      "test: loss=0.2973940678315103 acc=0.8967889908256881\n",
      "EPOCH=708\n",
      "train: loss=0.15692228754915122 acc=0.9518348623853211\n",
      "test: loss=0.30065468658709127 acc=0.8853211009174312\n",
      "EPOCH=709\n",
      "train: loss=0.18233778050511815 acc=0.9357798165137615\n",
      "test: loss=0.2557500613274389 acc=0.9059633027522935\n",
      "EPOCH=710\n",
      "train: loss=0.1140408054142894 acc=0.9610091743119266\n",
      "test: loss=0.24371365511171314 acc=0.9105504587155964\n",
      "EPOCH=711\n",
      "train: loss=0.21472695049244558 acc=0.9403669724770642\n",
      "test: loss=0.25145785487183003 acc=0.9151376146788991\n",
      "EPOCH=712\n",
      "train: loss=0.09119642125031967 acc=0.9587155963302753\n",
      "test: loss=0.33303597296527204 acc=0.8967889908256881\n",
      "EPOCH=713\n",
      "train: loss=0.06717025086085782 acc=0.9770642201834863\n",
      "test: loss=0.20381201532580903 acc=0.9220183486238532\n",
      "EPOCH=714\n",
      "train: loss=0.11502634910203377 acc=0.9564220183486238\n",
      "test: loss=0.2749800311238737 acc=0.9013761467889908\n",
      "EPOCH=715\n",
      "train: loss=0.16624627102756148 acc=0.9403669724770642\n",
      "test: loss=0.27328759390045154 acc=0.9013761467889908\n",
      "EPOCH=716\n",
      "train: loss=0.24751300648479868 acc=0.9197247706422018\n",
      "test: loss=0.2957142727562401 acc=0.9013761467889908\n",
      "EPOCH=717\n",
      "train: loss=0.17407774486458158 acc=0.9426605504587156\n",
      "test: loss=0.2709838231164892 acc=0.9128440366972477\n",
      "EPOCH=718\n",
      "train: loss=0.14910869045112568 acc=0.9472477064220184\n",
      "test: loss=0.263123855184878 acc=0.908256880733945\n",
      "EPOCH=719\n",
      "train: loss=0.15608645436986296 acc=0.9403669724770642\n",
      "test: loss=0.23995608607708194 acc=0.9128440366972477\n",
      "EPOCH=720\n",
      "train: loss=0.11083620624606806 acc=0.9678899082568807\n",
      "test: loss=0.23731570620194228 acc=0.908256880733945\n",
      "EPOCH=721\n",
      "train: loss=0.24636040376000817 acc=0.9128440366972477\n",
      "test: loss=0.22501788979511253 acc=0.9059633027522935\n",
      "EPOCH=722\n",
      "train: loss=0.07367996032879535 acc=0.9747706422018348\n",
      "test: loss=0.28766185409858874 acc=0.8990825688073395\n",
      "EPOCH=723\n",
      "train: loss=0.08997061979956568 acc=0.9610091743119266\n",
      "test: loss=0.28612255270265696 acc=0.8967889908256881\n",
      "EPOCH=724\n",
      "train: loss=0.19693535272940657 acc=0.9288990825688074\n",
      "test: loss=0.20121881671887856 acc=0.9174311926605505\n",
      "EPOCH=725\n",
      "train: loss=0.1911909727157722 acc=0.9220183486238532\n",
      "test: loss=0.24772573358346822 acc=0.9105504587155964\n",
      "EPOCH=726\n",
      "train: loss=0.1874040243410962 acc=0.9311926605504587\n",
      "test: loss=0.2962553578944441 acc=0.8990825688073395\n",
      "EPOCH=727\n",
      "train: loss=0.20548270838825564 acc=0.9220183486238532\n",
      "test: loss=0.32052505074508986 acc=0.8807339449541285\n",
      "EPOCH=728\n",
      "train: loss=0.26219093833890134 acc=0.9105504587155964\n",
      "test: loss=0.28340158636395757 acc=0.8876146788990825\n",
      "EPOCH=729\n",
      "train: loss=0.0806540191553182 acc=0.9701834862385321\n",
      "test: loss=0.2981568523459212 acc=0.8944954128440367\n",
      "EPOCH=730\n",
      "train: loss=0.20485551316772543 acc=0.9311926605504587\n",
      "test: loss=0.3111032735459392 acc=0.8876146788990825\n",
      "EPOCH=731\n",
      "train: loss=0.1381908825994618 acc=0.9426605504587156\n",
      "test: loss=0.2633031903478142 acc=0.9036697247706422\n",
      "EPOCH=732\n",
      "train: loss=0.07542216992841366 acc=0.9747706422018348\n",
      "test: loss=0.23554037165868077 acc=0.9151376146788991\n",
      "EPOCH=733\n",
      "train: loss=0.07096286331346041 acc=0.9701834862385321\n",
      "test: loss=0.2516937327597454 acc=0.9059633027522935\n",
      "EPOCH=734\n",
      "train: loss=0.13051871503820683 acc=0.9495412844036697\n",
      "test: loss=0.23430049039692555 acc=0.9197247706422018\n",
      "EPOCH=735\n",
      "train: loss=0.12593254030958487 acc=0.9564220183486238\n",
      "test: loss=0.27701513335003414 acc=0.9059633027522935\n",
      "EPOCH=736\n",
      "train: loss=0.12451610510950022 acc=0.9495412844036697\n",
      "test: loss=0.3085715194307168 acc=0.8967889908256881\n",
      "EPOCH=737\n",
      "train: loss=0.15982075765568182 acc=0.9403669724770642\n",
      "test: loss=0.28443976628266426 acc=0.9059633027522935\n",
      "EPOCH=738\n",
      "train: loss=0.15081861908065897 acc=0.9495412844036697\n",
      "test: loss=0.3122633590273829 acc=0.8967889908256881\n",
      "EPOCH=739\n",
      "train: loss=0.12480330326547708 acc=0.9564220183486238\n",
      "test: loss=0.22655302302147767 acc=0.9197247706422018\n",
      "EPOCH=740\n",
      "train: loss=0.09778215793669563 acc=0.9655963302752294\n",
      "test: loss=0.3214600873146491 acc=0.8922018348623854\n",
      "EPOCH=741\n",
      "train: loss=0.095334381909026 acc=0.9701834862385321\n",
      "test: loss=0.2530378846292209 acc=0.9036697247706422\n",
      "EPOCH=742\n",
      "train: loss=0.14343793751943648 acc=0.944954128440367\n",
      "test: loss=0.2177283189760503 acc=0.9105504587155964\n",
      "EPOCH=743\n",
      "train: loss=0.1526669748201853 acc=0.9518348623853211\n",
      "test: loss=0.3194872571654959 acc=0.8944954128440367\n",
      "EPOCH=744\n",
      "train: loss=0.17926219305192845 acc=0.9288990825688074\n",
      "test: loss=0.20630563083555745 acc=0.9220183486238532\n",
      "EPOCH=745\n",
      "train: loss=0.16290508168948115 acc=0.9495412844036697\n",
      "test: loss=0.24799924040719515 acc=0.9105504587155964\n",
      "EPOCH=746\n",
      "train: loss=0.16298268547562209 acc=0.9288990825688074\n",
      "test: loss=0.31683209800599343 acc=0.8922018348623854\n",
      "EPOCH=747\n",
      "train: loss=0.2399008154610943 acc=0.9288990825688074\n",
      "test: loss=0.2794503229191998 acc=0.908256880733945\n",
      "EPOCH=748\n",
      "train: loss=0.12872393012063468 acc=0.9518348623853211\n",
      "test: loss=0.22634744621564856 acc=0.9174311926605505\n",
      "EPOCH=749\n",
      "train: loss=0.11586394778387477 acc=0.9541284403669725\n",
      "test: loss=0.34878618749370655 acc=0.8853211009174312\n",
      "EPOCH=750\n",
      "train: loss=0.17341293259843882 acc=0.944954128440367\n",
      "test: loss=0.25030911173096715 acc=0.908256880733945\n",
      "EPOCH=751\n",
      "train: loss=0.1796072054771361 acc=0.9426605504587156\n",
      "test: loss=0.27651890104382776 acc=0.8967889908256881\n",
      "EPOCH=752\n",
      "train: loss=0.074945962544738 acc=0.9747706422018348\n",
      "test: loss=0.2936467720696082 acc=0.8967889908256881\n",
      "EPOCH=753\n",
      "train: loss=0.22097690140086895 acc=0.9311926605504587\n",
      "test: loss=0.26038719416089606 acc=0.8967889908256881\n",
      "EPOCH=754\n",
      "train: loss=0.1157297532677355 acc=0.9610091743119266\n",
      "test: loss=0.2812640483081564 acc=0.8967889908256881\n",
      "EPOCH=755\n",
      "train: loss=0.10178164864225804 acc=0.9655963302752294\n",
      "test: loss=0.3777564042499256 acc=0.8646788990825688\n",
      "EPOCH=756\n",
      "train: loss=0.24766948317388368 acc=0.9128440366972477\n",
      "test: loss=0.25416362083736227 acc=0.8990825688073395\n",
      "EPOCH=757\n",
      "train: loss=0.1449951330368004 acc=0.944954128440367\n",
      "test: loss=0.2905496506084034 acc=0.9036697247706422\n",
      "EPOCH=758\n",
      "train: loss=0.06520208474074529 acc=0.9770642201834863\n",
      "test: loss=0.319091226292714 acc=0.8853211009174312\n",
      "EPOCH=759\n",
      "train: loss=0.1965349069190123 acc=0.9311926605504587\n",
      "test: loss=0.26425945350405855 acc=0.9036697247706422\n",
      "EPOCH=760\n",
      "train: loss=0.15280325464337943 acc=0.9472477064220184\n",
      "test: loss=0.34770377063834806 acc=0.8784403669724771\n",
      "EPOCH=761\n",
      "train: loss=0.1917115538099134 acc=0.9357798165137615\n",
      "test: loss=0.19371185521631282 acc=0.926605504587156\n",
      "EPOCH=762\n",
      "train: loss=0.2789541216746169 acc=0.9151376146788991\n",
      "test: loss=0.2246332082738407 acc=0.9105504587155964\n",
      "EPOCH=763\n",
      "train: loss=0.10715140111152295 acc=0.963302752293578\n",
      "test: loss=0.25151863583325174 acc=0.9036697247706422\n",
      "EPOCH=764\n",
      "train: loss=0.14216970626364375 acc=0.944954128440367\n",
      "test: loss=0.223123844308754 acc=0.9128440366972477\n",
      "EPOCH=765\n",
      "train: loss=0.08406148839224747 acc=0.9610091743119266\n",
      "test: loss=0.24576824984056392 acc=0.9105504587155964\n",
      "EPOCH=766\n",
      "train: loss=0.17040642276164836 acc=0.9334862385321101\n",
      "test: loss=0.27317210988239604 acc=0.9128440366972477\n",
      "EPOCH=767\n",
      "train: loss=0.1376375133253424 acc=0.9472477064220184\n",
      "test: loss=0.3190799099630059 acc=0.8922018348623854\n",
      "EPOCH=768\n",
      "train: loss=0.14056047179684272 acc=0.944954128440367\n",
      "test: loss=0.3134223220584595 acc=0.9013761467889908\n",
      "EPOCH=769\n",
      "train: loss=0.17319974089920764 acc=0.9380733944954128\n",
      "test: loss=0.2592228495913356 acc=0.8990825688073395\n",
      "EPOCH=770\n",
      "train: loss=0.15644091273853164 acc=0.9426605504587156\n",
      "test: loss=0.317564280296109 acc=0.908256880733945\n",
      "EPOCH=771\n",
      "train: loss=0.18383285174813488 acc=0.9426605504587156\n",
      "test: loss=0.27144222878650515 acc=0.9151376146788991\n",
      "EPOCH=772\n",
      "train: loss=0.23290876275725783 acc=0.9288990825688074\n",
      "test: loss=0.24067319873058995 acc=0.9128440366972477\n",
      "EPOCH=773\n",
      "train: loss=0.09298794895802336 acc=0.9701834862385321\n",
      "test: loss=0.2791856254095569 acc=0.8944954128440367\n",
      "EPOCH=774\n",
      "train: loss=0.15467302930451965 acc=0.9472477064220184\n",
      "test: loss=0.25497090443813186 acc=0.908256880733945\n",
      "EPOCH=775\n",
      "train: loss=0.13481276968006492 acc=0.9541284403669725\n",
      "test: loss=0.22649121286295612 acc=0.908256880733945\n",
      "EPOCH=776\n",
      "train: loss=0.1506564504719161 acc=0.9564220183486238\n",
      "test: loss=0.26467584090571095 acc=0.9036697247706422\n",
      "EPOCH=777\n",
      "train: loss=0.20693227076489837 acc=0.926605504587156\n",
      "test: loss=0.22271630673165924 acc=0.908256880733945\n",
      "EPOCH=778\n",
      "train: loss=0.11120398555138976 acc=0.9541284403669725\n",
      "test: loss=0.31457481971472273 acc=0.8967889908256881\n",
      "EPOCH=779\n",
      "train: loss=0.17133569840897808 acc=0.944954128440367\n",
      "test: loss=0.2958079937287453 acc=0.9059633027522935\n",
      "EPOCH=780\n",
      "train: loss=0.23872250183009944 acc=0.9128440366972477\n",
      "test: loss=0.2671317808854293 acc=0.9059633027522935\n",
      "EPOCH=781\n",
      "train: loss=0.2999218756604487 acc=0.9151376146788991\n",
      "test: loss=0.2730163405219702 acc=0.8944954128440367\n",
      "EPOCH=782\n",
      "train: loss=0.19852573129371326 acc=0.926605504587156\n",
      "test: loss=0.2992867729007587 acc=0.8967889908256881\n",
      "EPOCH=783\n",
      "train: loss=0.20952233211944274 acc=0.9174311926605505\n",
      "test: loss=0.24464667565079024 acc=0.9151376146788991\n",
      "EPOCH=784\n",
      "train: loss=0.09453057821058171 acc=0.963302752293578\n",
      "test: loss=0.28173502675198664 acc=0.9036697247706422\n",
      "EPOCH=785\n",
      "train: loss=0.19484409120349896 acc=0.9220183486238532\n",
      "test: loss=0.26715702943835096 acc=0.9036697247706422\n",
      "EPOCH=786\n",
      "train: loss=0.12705071359922757 acc=0.9541284403669725\n",
      "test: loss=0.29977999485678314 acc=0.9013761467889908\n",
      "EPOCH=787\n",
      "train: loss=0.13955705171184668 acc=0.9541284403669725\n",
      "test: loss=0.2796304342921288 acc=0.9013761467889908\n",
      "EPOCH=788\n",
      "train: loss=0.17471572492961554 acc=0.9426605504587156\n",
      "test: loss=0.2764314505379331 acc=0.9013761467889908\n",
      "EPOCH=789\n",
      "train: loss=0.17467760319377512 acc=0.9426605504587156\n",
      "test: loss=0.26386591984549085 acc=0.9105504587155964\n",
      "EPOCH=790\n",
      "train: loss=0.15649017898414344 acc=0.9288990825688074\n",
      "test: loss=0.26930957649767595 acc=0.9059633027522935\n",
      "EPOCH=791\n",
      "train: loss=0.15038499161622731 acc=0.9518348623853211\n",
      "test: loss=0.2593693514349991 acc=0.9013761467889908\n",
      "EPOCH=792\n",
      "train: loss=0.10985795944182149 acc=0.9610091743119266\n",
      "test: loss=0.1907623741123213 acc=0.9243119266055045\n",
      "EPOCH=793\n",
      "train: loss=0.05469481256108525 acc=0.9747706422018348\n",
      "test: loss=0.290574495663667 acc=0.8899082568807339\n",
      "EPOCH=794\n",
      "train: loss=0.2592092520082351 acc=0.9197247706422018\n",
      "test: loss=0.22306123531970756 acc=0.9174311926605505\n",
      "EPOCH=795\n",
      "train: loss=0.10778525822985184 acc=0.9541284403669725\n",
      "test: loss=0.22567146888250578 acc=0.9105504587155964\n",
      "EPOCH=796\n",
      "train: loss=0.23254356066158083 acc=0.9403669724770642\n",
      "test: loss=0.29969563051153375 acc=0.9059633027522935\n",
      "EPOCH=797\n",
      "train: loss=0.16892216787539188 acc=0.9403669724770642\n",
      "test: loss=0.2877143658756698 acc=0.9036697247706422\n",
      "EPOCH=798\n",
      "train: loss=0.1620310418136468 acc=0.9518348623853211\n",
      "test: loss=0.32324976164300373 acc=0.8876146788990825\n",
      "EPOCH=799\n",
      "train: loss=0.17999187063565847 acc=0.9426605504587156\n",
      "test: loss=0.23177905008395047 acc=0.9151376146788991\n",
      "EPOCH=800\n",
      "train: loss=0.06370536019869602 acc=0.9770642201834863\n",
      "test: loss=0.29345527747680666 acc=0.9059633027522935\n",
      "EPOCH=801\n",
      "train: loss=0.07998489440245318 acc=0.9724770642201835\n",
      "test: loss=0.31631548201134263 acc=0.9013761467889908\n",
      "EPOCH=802\n",
      "train: loss=0.1849318867858565 acc=0.9220183486238532\n",
      "test: loss=0.22609446723705784 acc=0.9105504587155964\n",
      "EPOCH=803\n",
      "train: loss=0.19801087194441727 acc=0.9288990825688074\n",
      "test: loss=0.26380549600916536 acc=0.8990825688073395\n",
      "EPOCH=804\n",
      "train: loss=0.16312668131128055 acc=0.9334862385321101\n",
      "test: loss=0.28561887206904163 acc=0.9036697247706422\n",
      "EPOCH=805\n",
      "train: loss=0.13544241174520244 acc=0.9541284403669725\n",
      "test: loss=0.2942918388944222 acc=0.8944954128440367\n",
      "EPOCH=806\n",
      "train: loss=0.2018380121550247 acc=0.9311926605504587\n",
      "test: loss=0.2962801113160468 acc=0.8922018348623854\n",
      "EPOCH=807\n",
      "train: loss=0.12137836474812574 acc=0.9518348623853211\n",
      "test: loss=0.32172181862921023 acc=0.8876146788990825\n",
      "EPOCH=808\n",
      "train: loss=0.09117048205092151 acc=0.9701834862385321\n",
      "test: loss=0.24426377068709115 acc=0.9174311926605505\n",
      "EPOCH=809\n",
      "train: loss=0.12078076658319792 acc=0.963302752293578\n",
      "test: loss=0.27681815911127894 acc=0.8944954128440367\n",
      "EPOCH=810\n",
      "train: loss=0.1656421385937109 acc=0.9495412844036697\n",
      "test: loss=0.2426873544519 acc=0.9197247706422018\n",
      "EPOCH=811\n",
      "train: loss=0.10129920427599019 acc=0.9701834862385321\n",
      "test: loss=0.2329925754300649 acc=0.908256880733945\n",
      "EPOCH=812\n",
      "train: loss=0.11027018430125726 acc=0.9587155963302753\n",
      "test: loss=0.26749537355050285 acc=0.9128440366972477\n",
      "EPOCH=813\n",
      "train: loss=0.145016729011782 acc=0.9610091743119266\n",
      "test: loss=0.2079987822727055 acc=0.9128440366972477\n",
      "EPOCH=814\n",
      "train: loss=0.14976202749811274 acc=0.9403669724770642\n",
      "test: loss=0.26592990150808443 acc=0.9151376146788991\n",
      "EPOCH=815\n",
      "train: loss=0.13431574229373236 acc=0.9541284403669725\n",
      "test: loss=0.25523795085473816 acc=0.9174311926605505\n",
      "EPOCH=816\n",
      "train: loss=0.21744622441985925 acc=0.9197247706422018\n",
      "test: loss=0.23368052808515163 acc=0.9197247706422018\n",
      "EPOCH=817\n",
      "train: loss=0.1054819877795922 acc=0.963302752293578\n",
      "test: loss=0.2621204876677322 acc=0.9197247706422018\n",
      "EPOCH=818\n",
      "train: loss=0.06917529333641839 acc=0.9747706422018348\n",
      "test: loss=0.2815513196469358 acc=0.9197247706422018\n",
      "EPOCH=819\n",
      "train: loss=0.19463046258443614 acc=0.9380733944954128\n",
      "test: loss=0.27876258170818585 acc=0.8922018348623854\n",
      "EPOCH=820\n",
      "train: loss=0.215349587173006 acc=0.9151376146788991\n",
      "test: loss=0.27180105695106277 acc=0.9128440366972477\n",
      "EPOCH=821\n",
      "train: loss=0.17852876080368674 acc=0.9357798165137615\n",
      "test: loss=0.2605875180807049 acc=0.9105504587155964\n",
      "EPOCH=822\n",
      "train: loss=0.18801898032922493 acc=0.9495412844036697\n",
      "test: loss=0.29321800173163676 acc=0.8990825688073395\n",
      "EPOCH=823\n",
      "train: loss=0.1561689394853381 acc=0.9495412844036697\n",
      "test: loss=0.311544333774872 acc=0.8830275229357798\n",
      "EPOCH=824\n",
      "train: loss=0.18553041656535496 acc=0.9495412844036697\n",
      "test: loss=0.23089540832491875 acc=0.9128440366972477\n",
      "EPOCH=825\n",
      "train: loss=0.13002558608586698 acc=0.9426605504587156\n",
      "test: loss=0.23125219360066354 acc=0.9197247706422018\n",
      "EPOCH=826\n",
      "train: loss=0.15744117502825883 acc=0.9472477064220184\n",
      "test: loss=0.2478701452729896 acc=0.9174311926605505\n",
      "EPOCH=827\n",
      "train: loss=0.2350231074184693 acc=0.9197247706422018\n",
      "test: loss=0.23254673444130086 acc=0.908256880733945\n",
      "EPOCH=828\n",
      "train: loss=0.12347946075899029 acc=0.9587155963302753\n",
      "test: loss=0.3156019924336884 acc=0.8990825688073395\n",
      "EPOCH=829\n",
      "train: loss=0.04011221863729188 acc=0.981651376146789\n",
      "test: loss=0.30097721207890477 acc=0.9105504587155964\n",
      "EPOCH=830\n",
      "train: loss=0.14648063605738962 acc=0.9403669724770642\n",
      "test: loss=0.29422076248594803 acc=0.9105504587155964\n",
      "EPOCH=831\n",
      "train: loss=0.1541780637518557 acc=0.9472477064220184\n",
      "test: loss=0.22201815334858852 acc=0.9288990825688074\n",
      "EPOCH=832\n",
      "train: loss=0.1645055957320057 acc=0.9380733944954128\n",
      "test: loss=0.2820552817472668 acc=0.9105504587155964\n",
      "EPOCH=833\n",
      "train: loss=0.23743631381499122 acc=0.9174311926605505\n",
      "test: loss=0.24330412865237022 acc=0.9243119266055045\n",
      "EPOCH=834\n",
      "train: loss=0.2555342964002239 acc=0.9105504587155964\n",
      "test: loss=0.35533851737993366 acc=0.9036697247706422\n",
      "EPOCH=835\n",
      "train: loss=0.07145323020160316 acc=0.9724770642201835\n",
      "test: loss=0.25061213906174096 acc=0.9105504587155964\n",
      "EPOCH=836\n",
      "train: loss=0.06365410719891221 acc=0.9724770642201835\n",
      "test: loss=0.27943225987426396 acc=0.9059633027522935\n",
      "EPOCH=837\n",
      "train: loss=0.14007723901872046 acc=0.9518348623853211\n",
      "test: loss=0.24867000418361793 acc=0.9013761467889908\n",
      "EPOCH=838\n",
      "train: loss=0.19327566416930714 acc=0.926605504587156\n",
      "test: loss=0.24030403126722114 acc=0.9105504587155964\n",
      "EPOCH=839\n",
      "train: loss=0.23651794342018306 acc=0.926605504587156\n",
      "test: loss=0.280901479007852 acc=0.9036697247706422\n",
      "EPOCH=840\n",
      "train: loss=0.16205865622887253 acc=0.9380733944954128\n",
      "test: loss=0.25788017429073234 acc=0.908256880733945\n",
      "EPOCH=841\n",
      "train: loss=0.27330499767522487 acc=0.9151376146788991\n",
      "test: loss=0.32822829957969457 acc=0.9036697247706422\n",
      "EPOCH=842\n",
      "train: loss=0.057001319005904126 acc=0.981651376146789\n",
      "test: loss=0.3268191870271974 acc=0.8922018348623854\n",
      "EPOCH=843\n",
      "train: loss=0.3181351048028339 acc=0.9013761467889908\n",
      "test: loss=0.2873003448218387 acc=0.9036697247706422\n",
      "EPOCH=844\n",
      "train: loss=0.12110506536241704 acc=0.963302752293578\n",
      "test: loss=0.24963310080763698 acc=0.9220183486238532\n",
      "EPOCH=845\n",
      "train: loss=0.18065923937486958 acc=0.9403669724770642\n",
      "test: loss=0.2119190589499968 acc=0.9288990825688074\n",
      "EPOCH=846\n",
      "train: loss=0.1658517586839264 acc=0.9472477064220184\n",
      "test: loss=0.292452689205682 acc=0.8990825688073395\n",
      "EPOCH=847\n",
      "train: loss=0.08966972462684368 acc=0.9747706422018348\n",
      "test: loss=0.3216740298318306 acc=0.9013761467889908\n",
      "EPOCH=848\n",
      "train: loss=0.133864428324324 acc=0.9564220183486238\n",
      "test: loss=0.20148110127673285 acc=0.9128440366972477\n",
      "EPOCH=849\n",
      "train: loss=0.15920307590759356 acc=0.9541284403669725\n",
      "test: loss=0.2500625496325831 acc=0.9059633027522935\n",
      "EPOCH=850\n",
      "train: loss=0.21947360703725552 acc=0.9311926605504587\n",
      "test: loss=0.2659916026551398 acc=0.908256880733945\n",
      "EPOCH=851\n",
      "train: loss=0.13858992402033038 acc=0.9472477064220184\n",
      "test: loss=0.27314167432239833 acc=0.9059633027522935\n",
      "EPOCH=852\n",
      "train: loss=0.12990539443139013 acc=0.944954128440367\n",
      "test: loss=0.25125855554531784 acc=0.9128440366972477\n",
      "EPOCH=853\n",
      "train: loss=0.12771344730113768 acc=0.9564220183486238\n",
      "test: loss=0.27512756897821994 acc=0.9059633027522935\n",
      "EPOCH=854\n",
      "train: loss=0.09256119007636714 acc=0.9610091743119266\n",
      "test: loss=0.28733542462437217 acc=0.8990825688073395\n",
      "EPOCH=855\n",
      "train: loss=0.20600630022535385 acc=0.9288990825688074\n",
      "test: loss=0.2650427492679674 acc=0.8967889908256881\n",
      "EPOCH=856\n",
      "train: loss=0.14810846856238266 acc=0.944954128440367\n",
      "test: loss=0.2309294185289456 acc=0.926605504587156\n",
      "EPOCH=857\n",
      "train: loss=0.15167593276396638 acc=0.9495412844036697\n",
      "test: loss=0.24313491084525948 acc=0.8990825688073395\n",
      "EPOCH=858\n",
      "train: loss=0.19991248187020572 acc=0.9472477064220184\n",
      "test: loss=0.29804551260910717 acc=0.8899082568807339\n",
      "EPOCH=859\n",
      "train: loss=0.15492002068341548 acc=0.9334862385321101\n",
      "test: loss=0.30963298099838044 acc=0.8967889908256881\n",
      "EPOCH=860\n",
      "train: loss=0.055499073732726084 acc=0.9793577981651376\n",
      "test: loss=0.24842419757107473 acc=0.9105504587155964\n",
      "EPOCH=861\n",
      "train: loss=0.08932767843830061 acc=0.9587155963302753\n",
      "test: loss=0.2707843962560115 acc=0.9128440366972477\n",
      "EPOCH=862\n",
      "train: loss=0.1475595321555283 acc=0.944954128440367\n",
      "test: loss=0.2513021589562336 acc=0.9105504587155964\n",
      "EPOCH=863\n",
      "train: loss=0.13646287634648724 acc=0.9472477064220184\n",
      "test: loss=0.2425586557307539 acc=0.9220183486238532\n",
      "EPOCH=864\n",
      "train: loss=0.13338702256244578 acc=0.963302752293578\n",
      "test: loss=0.22918868885713894 acc=0.9128440366972477\n",
      "EPOCH=865\n",
      "train: loss=0.20204557757435485 acc=0.9518348623853211\n",
      "test: loss=0.30385305041644656 acc=0.8944954128440367\n",
      "EPOCH=866\n",
      "train: loss=0.09180054302093474 acc=0.9610091743119266\n",
      "test: loss=0.24722604572193704 acc=0.9174311926605505\n",
      "EPOCH=867\n",
      "train: loss=0.17770507628083196 acc=0.9518348623853211\n",
      "test: loss=0.3350604703788115 acc=0.8967889908256881\n",
      "EPOCH=868\n",
      "train: loss=0.08112966785609887 acc=0.9701834862385321\n",
      "test: loss=0.27315495673989026 acc=0.8990825688073395\n",
      "EPOCH=869\n",
      "train: loss=0.13444401139703555 acc=0.944954128440367\n",
      "test: loss=0.30955239684546154 acc=0.908256880733945\n",
      "EPOCH=870\n",
      "train: loss=0.19099713941179194 acc=0.9587155963302753\n",
      "test: loss=0.25511999932162904 acc=0.9059633027522935\n",
      "EPOCH=871\n",
      "train: loss=0.1633522671260895 acc=0.944954128440367\n",
      "test: loss=0.25452279467093275 acc=0.908256880733945\n",
      "EPOCH=872\n",
      "train: loss=0.1578464254612957 acc=0.9610091743119266\n",
      "test: loss=0.25500294649141186 acc=0.9174311926605505\n",
      "EPOCH=873\n",
      "train: loss=0.10412305533619856 acc=0.963302752293578\n",
      "test: loss=0.27252036598085355 acc=0.9036697247706422\n",
      "EPOCH=874\n",
      "train: loss=0.14909291378608394 acc=0.9403669724770642\n",
      "test: loss=0.2635302249711599 acc=0.9059633027522935\n",
      "EPOCH=875\n",
      "train: loss=0.1924567477342602 acc=0.9311926605504587\n",
      "test: loss=0.30998930648246614 acc=0.908256880733945\n",
      "EPOCH=876\n",
      "train: loss=0.2190645512076534 acc=0.9220183486238532\n",
      "test: loss=0.34140148621283206 acc=0.8922018348623854\n",
      "EPOCH=877\n",
      "train: loss=0.09550881530441993 acc=0.9655963302752294\n",
      "test: loss=0.2832027635827844 acc=0.9059633027522935\n",
      "EPOCH=878\n",
      "train: loss=0.08041051283261927 acc=0.9724770642201835\n",
      "test: loss=0.24846654204877033 acc=0.9105504587155964\n",
      "EPOCH=879\n",
      "train: loss=0.13939615325536991 acc=0.9495412844036697\n",
      "test: loss=0.2842757802036359 acc=0.9013761467889908\n",
      "EPOCH=880\n",
      "train: loss=0.15464227130971753 acc=0.9610091743119266\n",
      "test: loss=0.33119786888618463 acc=0.908256880733945\n",
      "EPOCH=881\n",
      "train: loss=0.15637004808962873 acc=0.9380733944954128\n",
      "test: loss=0.32237640243791255 acc=0.8967889908256881\n",
      "EPOCH=882\n",
      "train: loss=0.08663564794244598 acc=0.963302752293578\n",
      "test: loss=0.26964621006308354 acc=0.908256880733945\n",
      "EPOCH=883\n",
      "train: loss=0.15298020248205077 acc=0.9495412844036697\n",
      "test: loss=0.29778167385595433 acc=0.9036697247706422\n",
      "EPOCH=884\n",
      "train: loss=0.1665201847613406 acc=0.9518348623853211\n",
      "test: loss=0.3179450207486765 acc=0.9036697247706422\n",
      "EPOCH=885\n",
      "train: loss=0.2073876317668033 acc=0.9288990825688074\n",
      "test: loss=0.26531944271564606 acc=0.9128440366972477\n",
      "EPOCH=886\n",
      "train: loss=0.1056306772570508 acc=0.963302752293578\n",
      "test: loss=0.2482559012346022 acc=0.908256880733945\n",
      "EPOCH=887\n",
      "train: loss=0.16265634600701603 acc=0.9541284403669725\n",
      "test: loss=0.2514925592079006 acc=0.9059633027522935\n",
      "EPOCH=888\n",
      "train: loss=0.10368958635075501 acc=0.963302752293578\n",
      "test: loss=0.326418239930831 acc=0.8944954128440367\n",
      "EPOCH=889\n",
      "train: loss=0.1481509794312557 acc=0.9472477064220184\n",
      "test: loss=0.25335238398109616 acc=0.9243119266055045\n",
      "EPOCH=890\n",
      "train: loss=0.045341570329313755 acc=0.9839449541284404\n",
      "test: loss=0.25472836358147966 acc=0.9174311926605505\n",
      "EPOCH=891\n",
      "train: loss=0.07810664933008334 acc=0.9587155963302753\n",
      "test: loss=0.2586387908344287 acc=0.8967889908256881\n",
      "EPOCH=892\n",
      "train: loss=0.10262148428410327 acc=0.9655963302752294\n",
      "test: loss=0.27518775534059603 acc=0.8967889908256881\n",
      "EPOCH=893\n",
      "train: loss=0.2509573336414194 acc=0.9197247706422018\n",
      "test: loss=0.2615436321226063 acc=0.9151376146788991\n",
      "EPOCH=894\n",
      "train: loss=0.13732731538464832 acc=0.9495412844036697\n",
      "test: loss=0.26543851530466933 acc=0.8990825688073395\n",
      "EPOCH=895\n",
      "train: loss=0.22565454394443454 acc=0.9357798165137615\n",
      "test: loss=0.31964140499425986 acc=0.8967889908256881\n",
      "EPOCH=896\n",
      "train: loss=0.07136732806309386 acc=0.9839449541284404\n",
      "test: loss=0.265779329352619 acc=0.9174311926605505\n",
      "EPOCH=897\n",
      "train: loss=0.0691304683424393 acc=0.9793577981651376\n",
      "test: loss=0.2760502669038279 acc=0.9151376146788991\n",
      "EPOCH=898\n",
      "train: loss=0.19091356946575788 acc=0.9334862385321101\n",
      "test: loss=0.30853677694092063 acc=0.9013761467889908\n",
      "EPOCH=899\n",
      "train: loss=0.19778582418502122 acc=0.9357798165137615\n",
      "test: loss=0.29889967557801145 acc=0.8967889908256881\n",
      "EPOCH=900\n",
      "train: loss=0.14207583090053186 acc=0.9426605504587156\n",
      "test: loss=0.28572939257211016 acc=0.9105504587155964\n",
      "EPOCH=901\n",
      "train: loss=0.13628997923804634 acc=0.9610091743119266\n",
      "test: loss=0.23398553643400266 acc=0.9197247706422018\n",
      "EPOCH=902\n",
      "train: loss=0.09111309834430294 acc=0.9655963302752294\n",
      "test: loss=0.30151459170049955 acc=0.8922018348623854\n",
      "EPOCH=903\n",
      "train: loss=0.12814687213193 acc=0.9564220183486238\n",
      "test: loss=0.28475270399291525 acc=0.9013761467889908\n",
      "EPOCH=904\n",
      "train: loss=0.12610406420305229 acc=0.9495412844036697\n",
      "test: loss=0.3267883812860717 acc=0.908256880733945\n",
      "EPOCH=905\n",
      "train: loss=0.20573550976435137 acc=0.9334862385321101\n",
      "test: loss=0.25459586503052944 acc=0.9151376146788991\n",
      "EPOCH=906\n",
      "train: loss=0.15363167911956396 acc=0.9541284403669725\n",
      "test: loss=0.29677006159160285 acc=0.8967889908256881\n",
      "EPOCH=907\n",
      "train: loss=0.23354574359318017 acc=0.9220183486238532\n",
      "test: loss=0.2620536249830693 acc=0.8922018348623854\n",
      "EPOCH=908\n",
      "train: loss=0.06863159955403259 acc=0.9724770642201835\n",
      "test: loss=0.25248596613974505 acc=0.9197247706422018\n",
      "EPOCH=909\n",
      "train: loss=0.15666080462267507 acc=0.9334862385321101\n",
      "test: loss=0.32151861533152254 acc=0.8899082568807339\n",
      "EPOCH=910\n",
      "train: loss=0.18809811832443446 acc=0.9243119266055045\n",
      "test: loss=0.27636969316511606 acc=0.9151376146788991\n",
      "EPOCH=911\n",
      "train: loss=0.16760219339135435 acc=0.9311926605504587\n",
      "test: loss=0.30568019780158245 acc=0.9036697247706422\n",
      "EPOCH=912\n",
      "train: loss=0.07547737557307359 acc=0.981651376146789\n",
      "test: loss=0.2716179177423838 acc=0.9197247706422018\n",
      "EPOCH=913\n",
      "train: loss=0.13132041621410948 acc=0.9495412844036697\n",
      "test: loss=0.22549323000807994 acc=0.9288990825688074\n",
      "EPOCH=914\n",
      "train: loss=0.14803212862491685 acc=0.9564220183486238\n",
      "test: loss=0.28068809566797787 acc=0.9059633027522935\n",
      "EPOCH=915\n",
      "train: loss=0.18063070674016418 acc=0.9403669724770642\n",
      "test: loss=0.3168825920852419 acc=0.8990825688073395\n",
      "EPOCH=916\n",
      "train: loss=0.07508008163651067 acc=0.9655963302752294\n",
      "test: loss=0.2524542172534663 acc=0.9105504587155964\n",
      "EPOCH=917\n",
      "train: loss=0.14158927774027494 acc=0.9655963302752294\n",
      "test: loss=0.29546427012318505 acc=0.9059633027522935\n",
      "EPOCH=918\n",
      "train: loss=0.19374430039906151 acc=0.9403669724770642\n",
      "test: loss=0.3190431173366245 acc=0.8967889908256881\n",
      "EPOCH=919\n",
      "train: loss=0.1279204298004836 acc=0.9587155963302753\n",
      "test: loss=0.3025762462525182 acc=0.9128440366972477\n",
      "EPOCH=920\n",
      "train: loss=0.09302176099403452 acc=0.9610091743119266\n",
      "test: loss=0.24113650901586725 acc=0.9197247706422018\n",
      "EPOCH=921\n",
      "train: loss=0.1300227792324929 acc=0.9564220183486238\n",
      "test: loss=0.24342747924513827 acc=0.926605504587156\n",
      "EPOCH=922\n",
      "train: loss=0.0639989304246722 acc=0.9770642201834863\n",
      "test: loss=0.2776235634321086 acc=0.9036697247706422\n",
      "EPOCH=923\n",
      "train: loss=0.08942538113575998 acc=0.9678899082568807\n",
      "test: loss=0.19823447010655126 acc=0.9174311926605505\n",
      "EPOCH=924\n",
      "train: loss=0.12439564799029725 acc=0.9472477064220184\n",
      "test: loss=0.28468447622766074 acc=0.9128440366972477\n",
      "EPOCH=925\n",
      "train: loss=0.20658522260871867 acc=0.926605504587156\n",
      "test: loss=0.22211909416880568 acc=0.9243119266055045\n",
      "EPOCH=926\n",
      "train: loss=0.17738907571822135 acc=0.9541284403669725\n",
      "test: loss=0.2572870714362842 acc=0.9059633027522935\n",
      "EPOCH=927\n",
      "train: loss=0.18182755233121167 acc=0.9610091743119266\n",
      "test: loss=0.27803974741979526 acc=0.9036697247706422\n",
      "EPOCH=928\n",
      "train: loss=0.14718569012577246 acc=0.9541284403669725\n",
      "test: loss=0.23257170858058335 acc=0.9151376146788991\n",
      "EPOCH=929\n",
      "train: loss=0.09838995922608487 acc=0.9678899082568807\n",
      "test: loss=0.27317287443428095 acc=0.9220183486238532\n",
      "EPOCH=930\n",
      "train: loss=0.11505631372276484 acc=0.9541284403669725\n",
      "test: loss=0.2939155183827017 acc=0.908256880733945\n",
      "EPOCH=931\n",
      "train: loss=0.050246311166223315 acc=0.9770642201834863\n",
      "test: loss=0.27667816344194457 acc=0.9036697247706422\n",
      "EPOCH=932\n",
      "train: loss=0.0791536716633091 acc=0.9701834862385321\n",
      "test: loss=0.29796221749789525 acc=0.908256880733945\n",
      "EPOCH=933\n",
      "train: loss=0.1276257455010619 acc=0.963302752293578\n",
      "test: loss=0.2789077782798026 acc=0.9013761467889908\n",
      "EPOCH=934\n",
      "train: loss=0.1872289940655008 acc=0.9403669724770642\n",
      "test: loss=0.24592981694377464 acc=0.9128440366972477\n",
      "EPOCH=935\n",
      "train: loss=0.09196190479696875 acc=0.9724770642201835\n",
      "test: loss=0.29998595305584536 acc=0.9036697247706422\n",
      "EPOCH=936\n",
      "train: loss=0.1387960697065051 acc=0.9495412844036697\n",
      "test: loss=0.23901939757308852 acc=0.908256880733945\n",
      "EPOCH=937\n",
      "train: loss=0.13597884186918327 acc=0.9564220183486238\n",
      "test: loss=0.28358491775359357 acc=0.908256880733945\n",
      "EPOCH=938\n",
      "train: loss=0.07728438839592504 acc=0.9655963302752294\n",
      "test: loss=0.27951132642331195 acc=0.8967889908256881\n",
      "EPOCH=939\n",
      "train: loss=0.10517455460692475 acc=0.9701834862385321\n",
      "test: loss=0.2925632629610182 acc=0.908256880733945\n",
      "EPOCH=940\n",
      "train: loss=0.08617527142731189 acc=0.9678899082568807\n",
      "test: loss=0.24414244012502265 acc=0.9105504587155964\n",
      "EPOCH=941\n",
      "train: loss=0.14191668523102707 acc=0.9564220183486238\n",
      "test: loss=0.24694189322283425 acc=0.9059633027522935\n",
      "EPOCH=942\n",
      "train: loss=0.17022328720302018 acc=0.9357798165137615\n",
      "test: loss=0.25886040737755545 acc=0.9036697247706422\n",
      "EPOCH=943\n",
      "train: loss=0.180251025635183 acc=0.9357798165137615\n",
      "test: loss=0.3417696202523217 acc=0.8990825688073395\n",
      "EPOCH=944\n",
      "train: loss=0.1578241733774556 acc=0.9472477064220184\n",
      "test: loss=0.24230675334425708 acc=0.9128440366972477\n",
      "EPOCH=945\n",
      "train: loss=0.15365511806780438 acc=0.9518348623853211\n",
      "test: loss=0.32963368004640625 acc=0.8899082568807339\n",
      "EPOCH=946\n",
      "train: loss=0.1188630009746546 acc=0.9541284403669725\n",
      "test: loss=0.2911252772545664 acc=0.9036697247706422\n",
      "EPOCH=947\n",
      "train: loss=0.19516990055808045 acc=0.9403669724770642\n",
      "test: loss=0.27333567441953166 acc=0.9105504587155964\n",
      "EPOCH=948\n",
      "train: loss=0.1432468188783491 acc=0.9472477064220184\n",
      "test: loss=0.24905853719941037 acc=0.9105504587155964\n",
      "EPOCH=949\n",
      "train: loss=0.15742170727082455 acc=0.9288990825688074\n",
      "test: loss=0.3051303974399952 acc=0.9036697247706422\n",
      "EPOCH=950\n",
      "train: loss=0.26028533152126265 acc=0.9013761467889908\n",
      "test: loss=0.3359492800872829 acc=0.8922018348623854\n",
      "EPOCH=951\n",
      "train: loss=0.23779467209186186 acc=0.9288990825688074\n",
      "test: loss=0.2297591789010884 acc=0.926605504587156\n",
      "EPOCH=952\n",
      "train: loss=0.2265152560486317 acc=0.9334862385321101\n",
      "test: loss=0.2773224543759059 acc=0.908256880733945\n",
      "EPOCH=953\n",
      "train: loss=0.17655279668412954 acc=0.9357798165137615\n",
      "test: loss=0.31172307176044584 acc=0.8990825688073395\n",
      "EPOCH=954\n",
      "train: loss=0.0991285792257237 acc=0.9587155963302753\n",
      "test: loss=0.2584736756974794 acc=0.9174311926605505\n",
      "EPOCH=955\n",
      "train: loss=0.0966602277251481 acc=0.9678899082568807\n",
      "test: loss=0.2850119091105442 acc=0.9128440366972477\n",
      "EPOCH=956\n",
      "train: loss=0.18654188650881154 acc=0.9587155963302753\n",
      "test: loss=0.2652118130690046 acc=0.9059633027522935\n",
      "EPOCH=957\n",
      "train: loss=0.20307533200151884 acc=0.9334862385321101\n",
      "test: loss=0.23887421635289832 acc=0.9311926605504587\n",
      "EPOCH=958\n",
      "train: loss=0.20620647128724914 acc=0.926605504587156\n",
      "test: loss=0.23271717749515225 acc=0.908256880733945\n",
      "EPOCH=959\n",
      "train: loss=0.1563726547264335 acc=0.9403669724770642\n",
      "test: loss=0.2784895476062349 acc=0.908256880733945\n",
      "EPOCH=960\n",
      "train: loss=0.1099890168179028 acc=0.9587155963302753\n",
      "test: loss=0.19440016538973098 acc=0.9311926605504587\n",
      "EPOCH=961\n",
      "train: loss=0.09318255313863716 acc=0.9655963302752294\n",
      "test: loss=0.2906507460045918 acc=0.9013761467889908\n",
      "EPOCH=962\n",
      "train: loss=0.1262665907404512 acc=0.9587155963302753\n",
      "test: loss=0.22981432399878474 acc=0.9174311926605505\n",
      "EPOCH=963\n",
      "train: loss=0.24689827268274317 acc=0.9174311926605505\n",
      "test: loss=0.27787478416151223 acc=0.9036697247706422\n",
      "EPOCH=964\n",
      "train: loss=0.16859919363602405 acc=0.9403669724770642\n",
      "test: loss=0.2834245480307566 acc=0.9197247706422018\n",
      "EPOCH=965\n",
      "train: loss=0.2404946641467215 acc=0.926605504587156\n",
      "test: loss=0.2512998060342274 acc=0.908256880733945\n",
      "EPOCH=966\n",
      "train: loss=0.14608519769329895 acc=0.9541284403669725\n",
      "test: loss=0.22702705514268612 acc=0.9243119266055045\n",
      "EPOCH=967\n",
      "train: loss=0.05713121522247084 acc=0.981651376146789\n",
      "test: loss=0.22858089301677043 acc=0.9105504587155964\n",
      "EPOCH=968\n",
      "train: loss=0.23905544836063322 acc=0.9151376146788991\n",
      "test: loss=0.3232788433002056 acc=0.9036697247706422\n",
      "EPOCH=969\n",
      "train: loss=0.12829937569157768 acc=0.9541284403669725\n",
      "test: loss=0.22059880409706692 acc=0.9128440366972477\n",
      "EPOCH=970\n",
      "train: loss=0.26839493172097817 acc=0.9334862385321101\n",
      "test: loss=0.2629225153550162 acc=0.9059633027522935\n",
      "EPOCH=971\n",
      "train: loss=0.20610433657005134 acc=0.9288990825688074\n",
      "test: loss=0.23655087690948512 acc=0.9151376146788991\n",
      "EPOCH=972\n",
      "train: loss=0.19463575041046724 acc=0.9403669724770642\n",
      "test: loss=0.30901016003199566 acc=0.9059633027522935\n",
      "EPOCH=973\n",
      "train: loss=0.18582050053835356 acc=0.9357798165137615\n",
      "test: loss=0.22077974819250895 acc=0.9197247706422018\n",
      "EPOCH=974\n",
      "train: loss=0.16398505054315296 acc=0.9541284403669725\n",
      "test: loss=0.22728685212169927 acc=0.9105504587155964\n",
      "EPOCH=975\n",
      "train: loss=0.2228417430046618 acc=0.926605504587156\n",
      "test: loss=0.29536679092510815 acc=0.908256880733945\n",
      "EPOCH=976\n",
      "train: loss=0.23318783469099347 acc=0.9288990825688074\n",
      "test: loss=0.24800566401494745 acc=0.9243119266055045\n",
      "EPOCH=977\n",
      "train: loss=0.17349118953692844 acc=0.9380733944954128\n",
      "test: loss=0.2851888214780346 acc=0.9059633027522935\n",
      "EPOCH=978\n",
      "train: loss=0.17067225791254173 acc=0.9518348623853211\n",
      "test: loss=0.27747137971510377 acc=0.908256880733945\n",
      "EPOCH=979\n",
      "train: loss=0.1486988985545997 acc=0.9495412844036697\n",
      "test: loss=0.25989853978137795 acc=0.9220183486238532\n",
      "EPOCH=980\n",
      "train: loss=0.16236401956118743 acc=0.9403669724770642\n",
      "test: loss=0.2831684749256006 acc=0.9105504587155964\n",
      "EPOCH=981\n",
      "train: loss=0.0722131364602544 acc=0.9678899082568807\n",
      "test: loss=0.2573301188620648 acc=0.9036697247706422\n",
      "EPOCH=982\n",
      "train: loss=0.12138044322089384 acc=0.9610091743119266\n",
      "test: loss=0.22192830360853968 acc=0.9174311926605505\n",
      "EPOCH=983\n",
      "train: loss=0.14897164401078428 acc=0.9518348623853211\n",
      "test: loss=0.28065945520226904 acc=0.9105504587155964\n",
      "EPOCH=984\n",
      "train: loss=0.06441285725264013 acc=0.9793577981651376\n",
      "test: loss=0.2897712662119941 acc=0.8990825688073395\n",
      "EPOCH=985\n",
      "train: loss=0.11671177408017239 acc=0.9655963302752294\n",
      "test: loss=0.27964544773019895 acc=0.9151376146788991\n",
      "EPOCH=986\n",
      "train: loss=0.14764070862769732 acc=0.9403669724770642\n",
      "test: loss=0.2438072883307515 acc=0.9151376146788991\n",
      "EPOCH=987\n",
      "train: loss=0.23338288377687835 acc=0.9197247706422018\n",
      "test: loss=0.27007954496265213 acc=0.9105504587155964\n",
      "EPOCH=988\n",
      "train: loss=0.2292679861056568 acc=0.9174311926605505\n",
      "test: loss=0.21569595318822646 acc=0.9220183486238532\n",
      "EPOCH=989\n",
      "train: loss=0.20337656457565195 acc=0.9380733944954128\n",
      "test: loss=0.28912062005691286 acc=0.9013761467889908\n",
      "EPOCH=990\n",
      "train: loss=0.11355612337518708 acc=0.963302752293578\n",
      "test: loss=0.24691706168975544 acc=0.908256880733945\n",
      "EPOCH=991\n",
      "train: loss=0.14688744138645238 acc=0.9541284403669725\n",
      "test: loss=0.32451734051225173 acc=0.9059633027522935\n",
      "EPOCH=992\n",
      "train: loss=0.12339604231128287 acc=0.9518348623853211\n",
      "test: loss=0.3148091836642392 acc=0.8990825688073395\n",
      "EPOCH=993\n",
      "train: loss=0.1777130461134688 acc=0.9380733944954128\n",
      "test: loss=0.2420855411523528 acc=0.9105504587155964\n",
      "EPOCH=994\n",
      "train: loss=0.14128835442137708 acc=0.9518348623853211\n",
      "test: loss=0.30499610648894204 acc=0.8967889908256881\n",
      "EPOCH=995\n",
      "train: loss=0.13396560277020036 acc=0.9518348623853211\n",
      "test: loss=0.2763689513332819 acc=0.908256880733945\n",
      "EPOCH=996\n",
      "train: loss=0.09189693237284016 acc=0.9701834862385321\n",
      "test: loss=0.2561161742542378 acc=0.9105504587155964\n",
      "EPOCH=997\n",
      "train: loss=0.10355450917234084 acc=0.9655963302752294\n",
      "test: loss=0.22799745528032275 acc=0.9220183486238532\n",
      "EPOCH=998\n",
      "train: loss=0.16548329800225872 acc=0.9495412844036697\n",
      "test: loss=0.2361263207217925 acc=0.9197247706422018\n",
      "EPOCH=999\n",
      "train: loss=0.11661265084938337 acc=0.9518348623853211\n",
      "test: loss=0.35605097805440244 acc=0.8944954128440367\n",
      "EPOCH=1000\n",
      "train: loss=0.15827980538305292 acc=0.9541284403669725\n",
      "test: loss=0.2591637539523078 acc=0.9151376146788991\n",
      "EPOCH=1001\n",
      "train: loss=0.1669892366844874 acc=0.944954128440367\n",
      "test: loss=0.29575622711309124 acc=0.908256880733945\n",
      "EPOCH=1002\n",
      "train: loss=0.10606747117440767 acc=0.9655963302752294\n",
      "test: loss=0.3167136563376189 acc=0.9059633027522935\n",
      "EPOCH=1003\n",
      "train: loss=0.16475885786556335 acc=0.9495412844036697\n",
      "test: loss=0.3110282125077179 acc=0.9036697247706422\n",
      "EPOCH=1004\n",
      "train: loss=0.19324623056736137 acc=0.9334862385321101\n",
      "test: loss=0.27916218608283894 acc=0.9013761467889908\n",
      "EPOCH=1005\n",
      "train: loss=0.11408127048845153 acc=0.9541284403669725\n",
      "test: loss=0.28958859940898785 acc=0.908256880733945\n",
      "EPOCH=1006\n",
      "train: loss=0.13909327308489136 acc=0.9610091743119266\n",
      "test: loss=0.26803627101305316 acc=0.9128440366972477\n",
      "EPOCH=1007\n",
      "train: loss=0.3366123108792607 acc=0.9128440366972477\n",
      "test: loss=0.2518947087189626 acc=0.9243119266055045\n",
      "EPOCH=1008\n",
      "train: loss=0.1236602237545794 acc=0.9610091743119266\n",
      "test: loss=0.2641535644002617 acc=0.9174311926605505\n",
      "EPOCH=1009\n",
      "train: loss=0.17118120973014822 acc=0.9426605504587156\n",
      "test: loss=0.2904155124518441 acc=0.9036697247706422\n",
      "EPOCH=1010\n",
      "train: loss=0.1275905428505692 acc=0.9610091743119266\n",
      "test: loss=0.27686724754239883 acc=0.908256880733945\n",
      "EPOCH=1011\n",
      "train: loss=0.06645972192221294 acc=0.9793577981651376\n",
      "test: loss=0.3072401420731557 acc=0.9036697247706422\n",
      "EPOCH=1012\n",
      "train: loss=0.17122861465435218 acc=0.9564220183486238\n",
      "test: loss=0.2846209028065682 acc=0.9128440366972477\n",
      "EPOCH=1013\n",
      "train: loss=0.148480980101571 acc=0.944954128440367\n",
      "test: loss=0.3247244857301061 acc=0.9036697247706422\n",
      "EPOCH=1014\n",
      "train: loss=0.11476551008189687 acc=0.9541284403669725\n",
      "test: loss=0.28071322073918986 acc=0.9059633027522935\n",
      "EPOCH=1015\n",
      "train: loss=0.11148674096285065 acc=0.9587155963302753\n",
      "test: loss=0.20142321862769968 acc=0.926605504587156\n",
      "EPOCH=1016\n",
      "train: loss=0.15976934944370355 acc=0.9357798165137615\n",
      "test: loss=0.3244793915450962 acc=0.9013761467889908\n",
      "EPOCH=1017\n",
      "train: loss=0.0873936426649041 acc=0.9678899082568807\n",
      "test: loss=0.32271034721730607 acc=0.8944954128440367\n",
      "EPOCH=1018\n",
      "train: loss=0.2018654291443644 acc=0.9311926605504587\n",
      "test: loss=0.2246619040485578 acc=0.9105504587155964\n",
      "EPOCH=1019\n",
      "train: loss=0.24530670140433847 acc=0.9197247706422018\n",
      "test: loss=0.24376838556979935 acc=0.9059633027522935\n",
      "EPOCH=1020\n",
      "train: loss=0.16312083695452165 acc=0.9541284403669725\n",
      "test: loss=0.27986389700941827 acc=0.9105504587155964\n",
      "EPOCH=1021\n",
      "train: loss=0.0852307569367894 acc=0.9747706422018348\n",
      "test: loss=0.2779936384489024 acc=0.9059633027522935\n",
      "EPOCH=1022\n",
      "train: loss=0.18692762020468295 acc=0.9288990825688074\n",
      "test: loss=0.32087501075317776 acc=0.9105504587155964\n",
      "EPOCH=1023\n",
      "train: loss=0.19056258475219565 acc=0.9357798165137615\n",
      "test: loss=0.2921456042783801 acc=0.9105504587155964\n",
      "EPOCH=1024\n",
      "train: loss=0.16396037017324097 acc=0.9472477064220184\n",
      "test: loss=0.24793159138184936 acc=0.9151376146788991\n",
      "EPOCH=1025\n",
      "train: loss=0.054256710736839235 acc=0.9793577981651376\n",
      "test: loss=0.22631644904731146 acc=0.9151376146788991\n",
      "EPOCH=1026\n",
      "train: loss=0.09648339147727057 acc=0.9587155963302753\n",
      "test: loss=0.2495913518828454 acc=0.9220183486238532\n",
      "EPOCH=1027\n",
      "train: loss=0.15416899247204166 acc=0.9541284403669725\n",
      "test: loss=0.3015497460255873 acc=0.9013761467889908\n",
      "EPOCH=1028\n",
      "train: loss=0.15028147364061234 acc=0.944954128440367\n",
      "test: loss=0.24246735909366673 acc=0.9174311926605505\n",
      "EPOCH=1029\n",
      "train: loss=0.10562699410746641 acc=0.9610091743119266\n",
      "test: loss=0.2387785826017509 acc=0.8944954128440367\n",
      "EPOCH=1030\n",
      "train: loss=0.16841864390732247 acc=0.944954128440367\n",
      "test: loss=0.3204749921496706 acc=0.8990825688073395\n",
      "EPOCH=1031\n",
      "train: loss=0.11835514700695413 acc=0.9564220183486238\n",
      "test: loss=0.23254238979484962 acc=0.9174311926605505\n",
      "EPOCH=1032\n",
      "train: loss=0.11738605995899136 acc=0.963302752293578\n",
      "test: loss=0.2647631163234081 acc=0.908256880733945\n",
      "EPOCH=1033\n",
      "train: loss=0.10125155991362411 acc=0.9678899082568807\n",
      "test: loss=0.2856193119373621 acc=0.8899082568807339\n",
      "EPOCH=1034\n",
      "train: loss=0.19624888270340263 acc=0.9426605504587156\n",
      "test: loss=0.3212587889013907 acc=0.9036697247706422\n",
      "EPOCH=1035\n",
      "train: loss=0.12229299739155594 acc=0.9495412844036697\n",
      "test: loss=0.29517246836946465 acc=0.908256880733945\n",
      "EPOCH=1036\n",
      "train: loss=0.24219565328152987 acc=0.926605504587156\n",
      "test: loss=0.35944762259069957 acc=0.908256880733945\n",
      "EPOCH=1037\n",
      "train: loss=0.15065463846418767 acc=0.9610091743119266\n",
      "test: loss=0.3276084552919879 acc=0.9036697247706422\n",
      "EPOCH=1038\n",
      "train: loss=0.050412778563915225 acc=0.9747706422018348\n",
      "test: loss=0.27012914113970404 acc=0.9151376146788991\n",
      "EPOCH=1039\n",
      "train: loss=0.056989544186953324 acc=0.981651376146789\n",
      "test: loss=0.32297512811484896 acc=0.9059633027522935\n",
      "EPOCH=1040\n",
      "train: loss=0.09313217271860245 acc=0.9724770642201835\n",
      "test: loss=0.3008653045947374 acc=0.8990825688073395\n",
      "EPOCH=1041\n",
      "train: loss=0.18566636546015414 acc=0.9357798165137615\n",
      "test: loss=0.22600252980455154 acc=0.926605504587156\n",
      "EPOCH=1042\n",
      "train: loss=0.12488240707220134 acc=0.9564220183486238\n",
      "test: loss=0.2847578623703541 acc=0.9128440366972477\n",
      "EPOCH=1043\n",
      "train: loss=0.10729692466615383 acc=0.963302752293578\n",
      "test: loss=0.26716595967042805 acc=0.9197247706422018\n",
      "EPOCH=1044\n",
      "train: loss=0.0828482190610497 acc=0.9678899082568807\n",
      "test: loss=0.31555574481968424 acc=0.908256880733945\n",
      "EPOCH=1045\n",
      "train: loss=0.03611636451525536 acc=0.9862385321100917\n",
      "test: loss=0.2831112460279374 acc=0.9059633027522935\n",
      "EPOCH=1046\n",
      "train: loss=0.1475458147839611 acc=0.9587155963302753\n",
      "test: loss=0.23509927711790557 acc=0.9243119266055045\n",
      "EPOCH=1047\n",
      "train: loss=0.11929827612974131 acc=0.9610091743119266\n",
      "test: loss=0.322026592056544 acc=0.8990825688073395\n",
      "EPOCH=1048\n",
      "train: loss=0.04621004359308968 acc=0.981651376146789\n",
      "test: loss=0.3141876928158185 acc=0.9036697247706422\n",
      "EPOCH=1049\n",
      "train: loss=0.1204711780310712 acc=0.9564220183486238\n",
      "test: loss=0.25326894614566936 acc=0.9128440366972477\n",
      "EPOCH=1050\n",
      "train: loss=0.14327027033028525 acc=0.9518348623853211\n",
      "test: loss=0.26985123113155085 acc=0.9105504587155964\n",
      "EPOCH=1051\n",
      "train: loss=0.14817283348769436 acc=0.944954128440367\n",
      "test: loss=0.30464819751898115 acc=0.8922018348623854\n",
      "EPOCH=1052\n",
      "train: loss=0.13921230803100781 acc=0.9357798165137615\n",
      "test: loss=0.2745976977036896 acc=0.9151376146788991\n",
      "EPOCH=1053\n",
      "train: loss=0.19415880487125284 acc=0.9357798165137615\n",
      "test: loss=0.32959750569139595 acc=0.8990825688073395\n",
      "EPOCH=1054\n",
      "train: loss=0.23741949049626757 acc=0.9426605504587156\n",
      "test: loss=0.23570890429213895 acc=0.9105504587155964\n",
      "EPOCH=1055\n",
      "train: loss=0.14269150700641767 acc=0.9472477064220184\n",
      "test: loss=0.3393654087543188 acc=0.8990825688073395\n",
      "EPOCH=1056\n",
      "train: loss=0.15130746486674082 acc=0.963302752293578\n",
      "test: loss=0.28485843754410384 acc=0.9059633027522935\n",
      "EPOCH=1057\n",
      "train: loss=0.18894719187069534 acc=0.9403669724770642\n",
      "test: loss=0.3077972037151638 acc=0.908256880733945\n",
      "EPOCH=1058\n",
      "train: loss=0.1627483786807365 acc=0.9541284403669725\n",
      "test: loss=0.21449683328196575 acc=0.9197247706422018\n",
      "EPOCH=1059\n",
      "train: loss=0.13531379129561508 acc=0.9472477064220184\n",
      "test: loss=0.2446448835664407 acc=0.9151376146788991\n",
      "EPOCH=1060\n",
      "train: loss=0.13173172473513176 acc=0.944954128440367\n",
      "test: loss=0.25343914757656066 acc=0.9105504587155964\n",
      "EPOCH=1061\n",
      "train: loss=0.22958223575874465 acc=0.9380733944954128\n",
      "test: loss=0.3396799239530793 acc=0.8990825688073395\n",
      "EPOCH=1062\n",
      "train: loss=0.20738575268886866 acc=0.9357798165137615\n",
      "test: loss=0.3409288830259505 acc=0.9059633027522935\n",
      "EPOCH=1063\n",
      "train: loss=0.3014905138593895 acc=0.9220183486238532\n",
      "test: loss=0.27416238449965763 acc=0.9128440366972477\n",
      "EPOCH=1064\n",
      "train: loss=0.11248037773108724 acc=0.9701834862385321\n",
      "test: loss=0.23402996864586526 acc=0.9197247706422018\n",
      "EPOCH=1065\n",
      "train: loss=0.06688014829629128 acc=0.981651376146789\n",
      "test: loss=0.28941412981363307 acc=0.9174311926605505\n",
      "EPOCH=1066\n",
      "train: loss=0.05355381746370402 acc=0.9770642201834863\n",
      "test: loss=0.25547226932214184 acc=0.8990825688073395\n",
      "EPOCH=1067\n",
      "train: loss=0.09213292293295104 acc=0.9587155963302753\n",
      "test: loss=0.26323704199083714 acc=0.908256880733945\n",
      "EPOCH=1068\n",
      "train: loss=0.21027225669671676 acc=0.9403669724770642\n",
      "test: loss=0.28725784748882727 acc=0.9128440366972477\n",
      "EPOCH=1069\n",
      "train: loss=0.06868789111637101 acc=0.9770642201834863\n",
      "test: loss=0.22742967567294411 acc=0.9197247706422018\n",
      "EPOCH=1070\n",
      "train: loss=0.0988895534207998 acc=0.963302752293578\n",
      "test: loss=0.2604124404387809 acc=0.9197247706422018\n",
      "EPOCH=1071\n",
      "train: loss=0.05979667710975257 acc=0.9770642201834863\n",
      "test: loss=0.27096259846514065 acc=0.9036697247706422\n",
      "EPOCH=1072\n",
      "train: loss=0.18108131937536642 acc=0.9357798165137615\n",
      "test: loss=0.2458045712060599 acc=0.908256880733945\n",
      "EPOCH=1073\n",
      "train: loss=0.0669175144650775 acc=0.9655963302752294\n",
      "test: loss=0.2685990337921648 acc=0.9059633027522935\n",
      "EPOCH=1074\n",
      "train: loss=0.19109526442201874 acc=0.944954128440367\n",
      "test: loss=0.27118482099708713 acc=0.9174311926605505\n",
      "EPOCH=1075\n",
      "train: loss=0.08331758530321479 acc=0.9701834862385321\n",
      "test: loss=0.28267660657069665 acc=0.9128440366972477\n",
      "EPOCH=1076\n",
      "train: loss=0.20534802731458898 acc=0.9151376146788991\n",
      "test: loss=0.25108825015039565 acc=0.9059633027522935\n",
      "EPOCH=1077\n",
      "train: loss=0.10259823967930454 acc=0.9655963302752294\n",
      "test: loss=0.28409953820078954 acc=0.908256880733945\n",
      "EPOCH=1078\n",
      "train: loss=0.16858072166325422 acc=0.9472477064220184\n",
      "test: loss=0.3356160627053081 acc=0.8967889908256881\n",
      "EPOCH=1079\n",
      "train: loss=0.21240160525912327 acc=0.9311926605504587\n",
      "test: loss=0.2895559468442668 acc=0.9105504587155964\n",
      "EPOCH=1080\n",
      "train: loss=0.19878470404125384 acc=0.9311926605504587\n",
      "test: loss=0.2784474185053651 acc=0.9105504587155964\n",
      "EPOCH=1081\n",
      "train: loss=0.2366369502846977 acc=0.9105504587155964\n",
      "test: loss=0.3365157448448487 acc=0.8990825688073395\n",
      "EPOCH=1082\n",
      "train: loss=0.20487872189483827 acc=0.9403669724770642\n",
      "test: loss=0.2409455243637531 acc=0.9128440366972477\n",
      "EPOCH=1083\n",
      "train: loss=0.11277202280253422 acc=0.9564220183486238\n",
      "test: loss=0.29377479635251585 acc=0.9059633027522935\n",
      "EPOCH=1084\n",
      "train: loss=0.19409773809727285 acc=0.9403669724770642\n",
      "test: loss=0.20952007282013516 acc=0.9220183486238532\n",
      "EPOCH=1085\n",
      "train: loss=0.08139524171145048 acc=0.963302752293578\n",
      "test: loss=0.3098951200606377 acc=0.8922018348623854\n",
      "EPOCH=1086\n",
      "train: loss=0.140789160797034 acc=0.9541284403669725\n",
      "test: loss=0.3052207044468831 acc=0.8922018348623854\n",
      "EPOCH=1087\n",
      "train: loss=0.1866131742528864 acc=0.9288990825688074\n",
      "test: loss=0.30907707729122313 acc=0.9013761467889908\n",
      "EPOCH=1088\n",
      "train: loss=0.2248058430042158 acc=0.926605504587156\n",
      "test: loss=0.24698691799275102 acc=0.9197247706422018\n",
      "EPOCH=1089\n",
      "train: loss=0.07486953217707532 acc=0.9724770642201835\n",
      "test: loss=0.21775623384007217 acc=0.9128440366972477\n",
      "EPOCH=1090\n",
      "train: loss=0.15024498873950068 acc=0.9426605504587156\n",
      "test: loss=0.3077498220705602 acc=0.9151376146788991\n",
      "EPOCH=1091\n",
      "train: loss=0.1394557396188581 acc=0.9541284403669725\n",
      "test: loss=0.27717448827827423 acc=0.9128440366972477\n",
      "EPOCH=1092\n",
      "train: loss=0.1801225919462035 acc=0.9495412844036697\n",
      "test: loss=0.29890498669157006 acc=0.9151376146788991\n",
      "EPOCH=1093\n",
      "train: loss=0.16573548334959617 acc=0.9541284403669725\n",
      "test: loss=0.30787305101181517 acc=0.9013761467889908\n",
      "EPOCH=1094\n",
      "train: loss=0.22224852222866323 acc=0.9357798165137615\n",
      "test: loss=0.23887054499892957 acc=0.9128440366972477\n",
      "EPOCH=1095\n",
      "train: loss=0.14354654396721625 acc=0.9564220183486238\n",
      "test: loss=0.2499037143772383 acc=0.9174311926605505\n",
      "EPOCH=1096\n",
      "train: loss=0.16538523107248085 acc=0.9495412844036697\n",
      "test: loss=0.2445800769895618 acc=0.9151376146788991\n",
      "EPOCH=1097\n",
      "train: loss=0.24895524955754764 acc=0.9311926605504587\n",
      "test: loss=0.2905594511314907 acc=0.9105504587155964\n",
      "EPOCH=1098\n",
      "train: loss=0.15936002639253988 acc=0.9472477064220184\n",
      "test: loss=0.26874174414199437 acc=0.9036697247706422\n",
      "EPOCH=1099\n",
      "train: loss=0.13523077729339314 acc=0.9564220183486238\n",
      "test: loss=0.21675299234975764 acc=0.9311926605504587\n",
      "EPOCH=1100\n",
      "train: loss=0.18261449891003487 acc=0.9541284403669725\n",
      "test: loss=0.25889807509626006 acc=0.926605504587156\n",
      "EPOCH=1101\n",
      "train: loss=0.2128742594688497 acc=0.9357798165137615\n",
      "test: loss=0.23228933011008876 acc=0.9059633027522935\n",
      "EPOCH=1102\n",
      "train: loss=0.15975809110356515 acc=0.9564220183486238\n",
      "test: loss=0.2326652878096772 acc=0.9220183486238532\n",
      "EPOCH=1103\n",
      "train: loss=0.19672370230790354 acc=0.9380733944954128\n",
      "test: loss=0.29281884577637 acc=0.9174311926605505\n",
      "EPOCH=1104\n",
      "train: loss=0.16792027120214773 acc=0.9495412844036697\n",
      "test: loss=0.2676067106750208 acc=0.9128440366972477\n",
      "EPOCH=1105\n",
      "train: loss=0.13603717784015368 acc=0.9426605504587156\n",
      "test: loss=0.31898724061936495 acc=0.908256880733945\n",
      "EPOCH=1106\n",
      "train: loss=0.12295143197605486 acc=0.9564220183486238\n",
      "test: loss=0.32955726872260915 acc=0.9059633027522935\n",
      "EPOCH=1107\n",
      "train: loss=0.1071583255652652 acc=0.9724770642201835\n",
      "test: loss=0.2892420294988359 acc=0.8990825688073395\n",
      "EPOCH=1108\n",
      "train: loss=0.16712959234808955 acc=0.944954128440367\n",
      "test: loss=0.27452298606135295 acc=0.908256880733945\n",
      "EPOCH=1109\n",
      "train: loss=0.11693667349395982 acc=0.9610091743119266\n",
      "test: loss=0.29058541252862596 acc=0.908256880733945\n",
      "EPOCH=1110\n",
      "train: loss=0.18454996628952294 acc=0.9403669724770642\n",
      "test: loss=0.270735339295703 acc=0.9151376146788991\n",
      "EPOCH=1111\n",
      "train: loss=0.18645268409659063 acc=0.9380733944954128\n",
      "test: loss=0.29456927877552486 acc=0.908256880733945\n",
      "EPOCH=1112\n",
      "train: loss=0.23227923174611087 acc=0.9243119266055045\n",
      "test: loss=0.3138514030549993 acc=0.9059633027522935\n",
      "EPOCH=1113\n",
      "train: loss=0.046331849534932225 acc=0.9793577981651376\n",
      "test: loss=0.25758039386433024 acc=0.908256880733945\n",
      "EPOCH=1114\n",
      "train: loss=0.2168161792996716 acc=0.9288990825688074\n",
      "test: loss=0.2635412315365826 acc=0.908256880733945\n",
      "EPOCH=1115\n",
      "train: loss=0.20823882326121812 acc=0.9288990825688074\n",
      "test: loss=0.307808988362211 acc=0.908256880733945\n",
      "EPOCH=1116\n",
      "train: loss=0.193616341767531 acc=0.9380733944954128\n",
      "test: loss=0.25299153905148486 acc=0.9243119266055045\n",
      "EPOCH=1117\n",
      "train: loss=0.13693776058897955 acc=0.9587155963302753\n",
      "test: loss=0.27970444302424446 acc=0.9105504587155964\n",
      "EPOCH=1118\n",
      "train: loss=0.1575186304306709 acc=0.9426605504587156\n",
      "test: loss=0.27024564220312236 acc=0.908256880733945\n",
      "EPOCH=1119\n",
      "train: loss=0.065476120395796 acc=0.9747706422018348\n",
      "test: loss=0.333361874086233 acc=0.9013761467889908\n",
      "EPOCH=1120\n",
      "train: loss=0.07681012886399376 acc=0.9701834862385321\n",
      "test: loss=0.28981175747018917 acc=0.9151376146788991\n",
      "EPOCH=1121\n",
      "train: loss=0.04760980409052693 acc=0.981651376146789\n",
      "test: loss=0.23779220632561465 acc=0.9311926605504587\n",
      "EPOCH=1122\n",
      "train: loss=0.1270181136947215 acc=0.9564220183486238\n",
      "test: loss=0.27551865626268485 acc=0.9105504587155964\n",
      "EPOCH=1123\n",
      "train: loss=0.13303500953278952 acc=0.9587155963302753\n",
      "test: loss=0.2499442481181833 acc=0.9128440366972477\n",
      "EPOCH=1124\n",
      "train: loss=0.07883543511152452 acc=0.9793577981651376\n",
      "test: loss=0.2882652314682776 acc=0.9151376146788991\n",
      "EPOCH=1125\n",
      "train: loss=0.13999768275978158 acc=0.944954128440367\n",
      "test: loss=0.30760492777453174 acc=0.9036697247706422\n",
      "EPOCH=1126\n",
      "train: loss=0.16741991629009806 acc=0.9426605504587156\n",
      "test: loss=0.307539178471162 acc=0.9105504587155964\n",
      "EPOCH=1127\n",
      "train: loss=0.23186606823373151 acc=0.9220183486238532\n",
      "test: loss=0.27560455647085097 acc=0.9220183486238532\n",
      "EPOCH=1128\n",
      "train: loss=0.11574808509722351 acc=0.9495412844036697\n",
      "test: loss=0.2846768731611018 acc=0.9151376146788991\n",
      "EPOCH=1129\n",
      "train: loss=0.1388797392795883 acc=0.9495412844036697\n",
      "test: loss=0.27121359018192354 acc=0.9128440366972477\n",
      "EPOCH=1130\n",
      "train: loss=0.1691291898179368 acc=0.9518348623853211\n",
      "test: loss=0.2880037532233423 acc=0.908256880733945\n",
      "EPOCH=1131\n",
      "train: loss=0.1778429587344884 acc=0.9334862385321101\n",
      "test: loss=0.3345885857403592 acc=0.9059633027522935\n",
      "EPOCH=1132\n",
      "train: loss=0.1097509609261828 acc=0.963302752293578\n",
      "test: loss=0.40662526842687646 acc=0.8922018348623854\n",
      "EPOCH=1133\n",
      "train: loss=0.14115919192517112 acc=0.9380733944954128\n",
      "test: loss=0.3156067417260797 acc=0.908256880733945\n",
      "EPOCH=1134\n",
      "train: loss=0.11967672352262412 acc=0.963302752293578\n",
      "test: loss=0.3619598124364285 acc=0.8853211009174312\n",
      "EPOCH=1135\n",
      "train: loss=0.1803012285800266 acc=0.9472477064220184\n",
      "test: loss=0.3412448652412983 acc=0.9036697247706422\n",
      "EPOCH=1136\n",
      "train: loss=0.14372603187380448 acc=0.9495412844036697\n",
      "test: loss=0.31687526477047595 acc=0.9105504587155964\n",
      "EPOCH=1137\n",
      "train: loss=0.2346304188955755 acc=0.9357798165137615\n",
      "test: loss=0.277497629134643 acc=0.908256880733945\n",
      "EPOCH=1138\n",
      "train: loss=0.19636744341147408 acc=0.9426605504587156\n",
      "test: loss=0.30653504142471694 acc=0.8967889908256881\n",
      "EPOCH=1139\n",
      "train: loss=0.23642310125956273 acc=0.9334862385321101\n",
      "test: loss=0.30611396755511183 acc=0.9151376146788991\n",
      "EPOCH=1140\n",
      "train: loss=0.06616641756586387 acc=0.9770642201834863\n",
      "test: loss=0.32542175478167273 acc=0.8944954128440367\n",
      "EPOCH=1141\n",
      "train: loss=0.1433293603691677 acc=0.9518348623853211\n",
      "test: loss=0.32120869705504473 acc=0.8990825688073395\n",
      "EPOCH=1142\n",
      "train: loss=0.10316736643780348 acc=0.9564220183486238\n",
      "test: loss=0.34236862913759086 acc=0.8944954128440367\n",
      "EPOCH=1143\n",
      "train: loss=0.1111048351578109 acc=0.9541284403669725\n",
      "test: loss=0.31630926002872206 acc=0.9013761467889908\n",
      "EPOCH=1144\n",
      "train: loss=0.06274533598627875 acc=0.9770642201834863\n",
      "test: loss=0.2676778895557592 acc=0.9174311926605505\n",
      "EPOCH=1145\n",
      "train: loss=0.1518004916630008 acc=0.9426605504587156\n",
      "test: loss=0.3387088196214589 acc=0.9128440366972477\n",
      "EPOCH=1146\n",
      "train: loss=0.15748438099054088 acc=0.9472477064220184\n",
      "test: loss=0.2621460701633603 acc=0.9128440366972477\n",
      "EPOCH=1147\n",
      "train: loss=0.12222541042477747 acc=0.963302752293578\n",
      "test: loss=0.2637916215377597 acc=0.9151376146788991\n",
      "EPOCH=1148\n",
      "train: loss=0.23373009696391198 acc=0.9357798165137615\n",
      "test: loss=0.1919022947596762 acc=0.9151376146788991\n",
      "EPOCH=1149\n",
      "train: loss=0.2197268511647644 acc=0.9380733944954128\n",
      "test: loss=0.2992031063238739 acc=0.9151376146788991\n",
      "EPOCH=1150\n",
      "train: loss=0.25470540697435345 acc=0.9357798165137615\n",
      "test: loss=0.28999571333922414 acc=0.9105504587155964\n",
      "EPOCH=1151\n",
      "train: loss=0.17745518516313422 acc=0.9357798165137615\n",
      "test: loss=0.31626516387197956 acc=0.8944954128440367\n",
      "EPOCH=1152\n",
      "train: loss=0.15566885523864268 acc=0.944954128440367\n",
      "test: loss=0.3259522880710253 acc=0.9013761467889908\n",
      "EPOCH=1153\n",
      "train: loss=0.13425542227674406 acc=0.9541284403669725\n",
      "test: loss=0.29137006224620043 acc=0.8944954128440367\n",
      "EPOCH=1154\n",
      "train: loss=0.1578453667225679 acc=0.9518348623853211\n",
      "test: loss=0.33104966003102243 acc=0.9105504587155964\n",
      "EPOCH=1155\n",
      "train: loss=0.16548208876545628 acc=0.9426605504587156\n",
      "test: loss=0.2589009566328872 acc=0.9174311926605505\n",
      "EPOCH=1156\n",
      "train: loss=0.10581637413475786 acc=0.9610091743119266\n",
      "test: loss=0.24227608176798213 acc=0.9197247706422018\n",
      "EPOCH=1157\n",
      "train: loss=0.2905110553559997 acc=0.9128440366972477\n",
      "test: loss=0.2658821950332405 acc=0.908256880733945\n",
      "EPOCH=1158\n",
      "train: loss=0.0534735542661689 acc=0.9793577981651376\n",
      "test: loss=0.2574889372616872 acc=0.9174311926605505\n",
      "EPOCH=1159\n",
      "train: loss=0.1275748671757887 acc=0.9564220183486238\n",
      "test: loss=0.22824554305986486 acc=0.926605504587156\n",
      "EPOCH=1160\n",
      "train: loss=0.1806130898045188 acc=0.9426605504587156\n",
      "test: loss=0.31811309201127963 acc=0.8967889908256881\n",
      "EPOCH=1161\n",
      "train: loss=0.13460155460791506 acc=0.9518348623853211\n",
      "test: loss=0.28961075447096857 acc=0.908256880733945\n",
      "EPOCH=1162\n",
      "train: loss=0.17770223619455852 acc=0.944954128440367\n",
      "test: loss=0.3059464906038232 acc=0.9197247706422018\n",
      "EPOCH=1163\n",
      "train: loss=0.07602459965126539 acc=0.9747706422018348\n",
      "test: loss=0.2569461321026597 acc=0.9220183486238532\n",
      "EPOCH=1164\n",
      "train: loss=0.19869493666736318 acc=0.9541284403669725\n",
      "test: loss=0.2972231625521539 acc=0.9059633027522935\n",
      "EPOCH=1165\n",
      "train: loss=0.11718555817482633 acc=0.9610091743119266\n",
      "test: loss=0.28916483598614995 acc=0.9128440366972477\n",
      "EPOCH=1166\n",
      "train: loss=0.15129422122519076 acc=0.9655963302752294\n",
      "test: loss=0.2674566079064126 acc=0.9128440366972477\n",
      "EPOCH=1167\n",
      "train: loss=0.10220451851624977 acc=0.9655963302752294\n",
      "test: loss=0.29745410824656254 acc=0.908256880733945\n",
      "EPOCH=1168\n",
      "train: loss=0.1555785834799257 acc=0.9518348623853211\n",
      "test: loss=0.3326754018277172 acc=0.8876146788990825\n",
      "EPOCH=1169\n",
      "train: loss=0.12564160874968563 acc=0.9655963302752294\n",
      "test: loss=0.30411806890621274 acc=0.9105504587155964\n",
      "EPOCH=1170\n",
      "train: loss=0.1587316424652109 acc=0.944954128440367\n",
      "test: loss=0.2636856565544138 acc=0.9151376146788991\n",
      "EPOCH=1171\n",
      "train: loss=0.15611565403064692 acc=0.9541284403669725\n",
      "test: loss=0.28483559575981265 acc=0.9197247706422018\n",
      "EPOCH=1172\n",
      "train: loss=0.13351677252388153 acc=0.963302752293578\n",
      "test: loss=0.28455868941155865 acc=0.9174311926605505\n",
      "EPOCH=1173\n",
      "train: loss=0.21063458623606612 acc=0.9426605504587156\n",
      "test: loss=0.31261063082343704 acc=0.908256880733945\n",
      "EPOCH=1174\n",
      "train: loss=0.1716162265104002 acc=0.9334862385321101\n",
      "test: loss=0.2631577285171258 acc=0.9243119266055045\n",
      "EPOCH=1175\n",
      "train: loss=0.1352954121273456 acc=0.9518348623853211\n",
      "test: loss=0.27688179079799335 acc=0.9128440366972477\n",
      "EPOCH=1176\n",
      "train: loss=0.13866985206954677 acc=0.9541284403669725\n",
      "test: loss=0.3694925006334102 acc=0.9013761467889908\n",
      "EPOCH=1177\n",
      "train: loss=0.10348025027944152 acc=0.9724770642201835\n",
      "test: loss=0.3022490032184052 acc=0.9059633027522935\n",
      "EPOCH=1178\n",
      "train: loss=0.15536078841085824 acc=0.9541284403669725\n",
      "test: loss=0.2615205367166144 acc=0.9128440366972477\n",
      "EPOCH=1179\n",
      "train: loss=0.14211923361320222 acc=0.9518348623853211\n",
      "test: loss=0.2516072650941337 acc=0.9220183486238532\n",
      "EPOCH=1180\n",
      "train: loss=0.13329408622685526 acc=0.9564220183486238\n",
      "test: loss=0.3001767021227891 acc=0.9036697247706422\n",
      "EPOCH=1181\n",
      "train: loss=0.041706195108037615 acc=0.9839449541284404\n",
      "test: loss=0.30830037703969426 acc=0.9013761467889908\n",
      "EPOCH=1182\n",
      "train: loss=0.0906679059708963 acc=0.9747706422018348\n",
      "test: loss=0.2524559953382908 acc=0.9151376146788991\n",
      "EPOCH=1183\n",
      "train: loss=0.23593135467333007 acc=0.9426605504587156\n",
      "test: loss=0.28016268892299107 acc=0.9151376146788991\n",
      "EPOCH=1184\n",
      "train: loss=0.09661890059600102 acc=0.9655963302752294\n",
      "test: loss=0.28496173131076846 acc=0.9197247706422018\n",
      "EPOCH=1185\n",
      "train: loss=0.23076986995419152 acc=0.9243119266055045\n",
      "test: loss=0.2569949813955604 acc=0.9151376146788991\n",
      "EPOCH=1186\n",
      "train: loss=0.1841132971117645 acc=0.9403669724770642\n",
      "test: loss=0.26187379782231235 acc=0.9059633027522935\n",
      "EPOCH=1187\n",
      "train: loss=0.16278233680871718 acc=0.9518348623853211\n",
      "test: loss=0.28924543643537287 acc=0.9151376146788991\n",
      "EPOCH=1188\n",
      "train: loss=0.14912099820179153 acc=0.9495412844036697\n",
      "test: loss=0.3049843604447544 acc=0.908256880733945\n",
      "EPOCH=1189\n",
      "train: loss=0.21727934491589235 acc=0.9334862385321101\n",
      "test: loss=0.2602545419744999 acc=0.9220183486238532\n",
      "EPOCH=1190\n",
      "train: loss=0.16957997903191413 acc=0.9403669724770642\n",
      "test: loss=0.33113071689210133 acc=0.8990825688073395\n",
      "EPOCH=1191\n",
      "train: loss=0.08444657118556032 acc=0.9747706422018348\n",
      "test: loss=0.2825460534045239 acc=0.8990825688073395\n",
      "EPOCH=1192\n",
      "train: loss=0.08609900728520803 acc=0.9770642201834863\n",
      "test: loss=0.27320005959885324 acc=0.908256880733945\n",
      "EPOCH=1193\n",
      "train: loss=0.17677372714087153 acc=0.9495412844036697\n",
      "test: loss=0.2932686572260189 acc=0.9151376146788991\n",
      "EPOCH=1194\n",
      "train: loss=0.07913710786887596 acc=0.9701834862385321\n",
      "test: loss=0.26894131355846584 acc=0.9105504587155964\n",
      "EPOCH=1195\n",
      "train: loss=0.1478482137554047 acc=0.9564220183486238\n",
      "test: loss=0.24531492570812843 acc=0.9288990825688074\n",
      "EPOCH=1196\n",
      "train: loss=0.3458548179294461 acc=0.9105504587155964\n",
      "test: loss=0.3105701994840739 acc=0.9174311926605505\n",
      "EPOCH=1197\n",
      "train: loss=0.2009033872096544 acc=0.9380733944954128\n",
      "test: loss=0.3172079794340793 acc=0.8990825688073395\n",
      "EPOCH=1198\n",
      "train: loss=0.20975979908743808 acc=0.9311926605504587\n",
      "test: loss=0.30981021108228884 acc=0.908256880733945\n",
      "EPOCH=1199\n",
      "train: loss=0.2835184590287377 acc=0.9151376146788991\n",
      "test: loss=0.3054779099271437 acc=0.9059633027522935\n",
      "EPOCH=1200\n",
      "train: loss=0.06674680837332518 acc=0.9724770642201835\n",
      "test: loss=0.3170631017676883 acc=0.9013761467889908\n",
      "EPOCH=1201\n",
      "train: loss=0.2618047284452092 acc=0.9174311926605505\n",
      "test: loss=0.314215205157891 acc=0.9128440366972477\n",
      "EPOCH=1202\n",
      "train: loss=0.10011491832100435 acc=0.9724770642201835\n",
      "test: loss=0.3186938232717325 acc=0.9105504587155964\n",
      "EPOCH=1203\n",
      "train: loss=0.28288119005779055 acc=0.9174311926605505\n",
      "test: loss=0.30460415254456397 acc=0.9105504587155964\n",
      "EPOCH=1204\n",
      "train: loss=0.28563152930589913 acc=0.9311926605504587\n",
      "test: loss=0.2911360004366331 acc=0.9105504587155964\n",
      "EPOCH=1205\n",
      "train: loss=0.08133355864386263 acc=0.9724770642201835\n",
      "test: loss=0.3251509901466054 acc=0.9036697247706422\n",
      "EPOCH=1206\n",
      "train: loss=0.1830734696980643 acc=0.9334862385321101\n",
      "test: loss=0.24323039767219712 acc=0.9288990825688074\n",
      "EPOCH=1207\n",
      "train: loss=0.12228305155503788 acc=0.9678899082568807\n",
      "test: loss=0.28897659329354564 acc=0.9105504587155964\n",
      "EPOCH=1208\n",
      "train: loss=0.12756223557670052 acc=0.9564220183486238\n",
      "test: loss=0.2801884321330744 acc=0.9128440366972477\n",
      "EPOCH=1209\n",
      "train: loss=0.12138656552614081 acc=0.9518348623853211\n",
      "test: loss=0.304585472450347 acc=0.9036697247706422\n",
      "EPOCH=1210\n",
      "train: loss=0.20918069039469223 acc=0.9403669724770642\n",
      "test: loss=0.22096975345378048 acc=0.926605504587156\n",
      "EPOCH=1211\n",
      "train: loss=0.2308292106943059 acc=0.9357798165137615\n",
      "test: loss=0.3567720333655878 acc=0.8967889908256881\n",
      "EPOCH=1212\n",
      "train: loss=0.16252089491083696 acc=0.944954128440367\n",
      "test: loss=0.2750432763902159 acc=0.9059633027522935\n",
      "EPOCH=1213\n",
      "train: loss=0.12358093201215103 acc=0.9587155963302753\n",
      "test: loss=0.27034989778278457 acc=0.9128440366972477\n",
      "EPOCH=1214\n",
      "train: loss=0.1443903706129332 acc=0.9495412844036697\n",
      "test: loss=0.28574391102890956 acc=0.9174311926605505\n",
      "EPOCH=1215\n",
      "train: loss=0.1486250619995513 acc=0.9564220183486238\n",
      "test: loss=0.3106704502729892 acc=0.9036697247706422\n",
      "EPOCH=1216\n",
      "train: loss=0.1448915523876632 acc=0.9472477064220184\n",
      "test: loss=0.30244694886278894 acc=0.9174311926605505\n",
      "EPOCH=1217\n",
      "train: loss=0.20465487314407066 acc=0.9380733944954128\n",
      "test: loss=0.2857746961225481 acc=0.9036697247706422\n",
      "EPOCH=1218\n",
      "train: loss=0.18697244296957408 acc=0.944954128440367\n",
      "test: loss=0.28277390010745385 acc=0.9059633027522935\n",
      "EPOCH=1219\n",
      "train: loss=0.16483724053022397 acc=0.9518348623853211\n",
      "test: loss=0.3160136325845645 acc=0.9059633027522935\n",
      "EPOCH=1220\n",
      "train: loss=0.20891758580211467 acc=0.926605504587156\n",
      "test: loss=0.3551278878504653 acc=0.8990825688073395\n",
      "EPOCH=1221\n",
      "train: loss=0.061657549993003984 acc=0.9747706422018348\n",
      "test: loss=0.3275526367839657 acc=0.9013761467889908\n",
      "EPOCH=1222\n",
      "train: loss=0.19593457398164338 acc=0.9334862385321101\n",
      "test: loss=0.2948841908656551 acc=0.9128440366972477\n",
      "EPOCH=1223\n",
      "train: loss=0.17257278331449918 acc=0.9403669724770642\n",
      "test: loss=0.28255201142739667 acc=0.908256880733945\n",
      "EPOCH=1224\n",
      "train: loss=0.22288414356632824 acc=0.9288990825688074\n",
      "test: loss=0.22534282938408234 acc=0.9174311926605505\n",
      "EPOCH=1225\n",
      "train: loss=0.05851650860245824 acc=0.9724770642201835\n",
      "test: loss=0.30604189892605893 acc=0.908256880733945\n",
      "EPOCH=1226\n",
      "train: loss=0.15170663051208874 acc=0.9426605504587156\n",
      "test: loss=0.3137929264637275 acc=0.9059633027522935\n",
      "EPOCH=1227\n",
      "train: loss=0.18555631417334864 acc=0.9541284403669725\n",
      "test: loss=0.2806664092393818 acc=0.9128440366972477\n",
      "EPOCH=1228\n",
      "train: loss=0.09526189811747937 acc=0.963302752293578\n",
      "test: loss=0.30083002809805565 acc=0.908256880733945\n",
      "EPOCH=1229\n",
      "train: loss=0.13434964972441482 acc=0.9678899082568807\n",
      "test: loss=0.307212359697353 acc=0.9151376146788991\n",
      "EPOCH=1230\n",
      "train: loss=0.19623518093941927 acc=0.9380733944954128\n",
      "test: loss=0.2098881199895664 acc=0.9311926605504587\n",
      "EPOCH=1231\n",
      "train: loss=0.10529807516119338 acc=0.9564220183486238\n",
      "test: loss=0.24230527964029805 acc=0.9105504587155964\n",
      "EPOCH=1232\n",
      "train: loss=0.1260312271451536 acc=0.9610091743119266\n",
      "test: loss=0.3388610914390616 acc=0.9036697247706422\n",
      "EPOCH=1233\n",
      "train: loss=0.21216694922232102 acc=0.9334862385321101\n",
      "test: loss=0.30729865884522994 acc=0.9151376146788991\n",
      "EPOCH=1234\n",
      "train: loss=0.16152818108682312 acc=0.9472477064220184\n",
      "test: loss=0.2817735384209685 acc=0.9220183486238532\n",
      "EPOCH=1235\n",
      "train: loss=0.09182970269371242 acc=0.963302752293578\n",
      "test: loss=0.3447190518622504 acc=0.9036697247706422\n",
      "EPOCH=1236\n",
      "train: loss=0.12392793537288618 acc=0.963302752293578\n",
      "test: loss=0.31494470421323567 acc=0.9151376146788991\n",
      "EPOCH=1237\n",
      "train: loss=0.19487216237406452 acc=0.9380733944954128\n",
      "test: loss=0.30897274856879753 acc=0.9036697247706422\n",
      "EPOCH=1238\n",
      "train: loss=0.10438105160773652 acc=0.9541284403669725\n",
      "test: loss=0.24268793773575087 acc=0.9220183486238532\n",
      "EPOCH=1239\n",
      "train: loss=0.1027278082980631 acc=0.9678899082568807\n",
      "test: loss=0.3530639537819808 acc=0.8944954128440367\n",
      "EPOCH=1240\n",
      "train: loss=0.1376822452086706 acc=0.9564220183486238\n",
      "test: loss=0.2724737680481323 acc=0.9128440366972477\n",
      "EPOCH=1241\n",
      "train: loss=0.08785486162545887 acc=0.9655963302752294\n",
      "test: loss=0.23116401533107483 acc=0.9220183486238532\n",
      "EPOCH=1242\n",
      "train: loss=0.18336934789302883 acc=0.944954128440367\n",
      "test: loss=0.2641113429003378 acc=0.9311926605504587\n",
      "EPOCH=1243\n",
      "train: loss=0.0667151964485834 acc=0.9724770642201835\n",
      "test: loss=0.27674199045383824 acc=0.9105504587155964\n",
      "EPOCH=1244\n",
      "train: loss=0.04985474709873079 acc=0.9724770642201835\n",
      "test: loss=0.3195780190537311 acc=0.8944954128440367\n",
      "EPOCH=1245\n",
      "train: loss=0.08027445589221793 acc=0.9701834862385321\n",
      "test: loss=0.3404216945239817 acc=0.9036697247706422\n",
      "EPOCH=1246\n",
      "train: loss=0.08793105787983733 acc=0.9564220183486238\n",
      "test: loss=0.31989005544818544 acc=0.9059633027522935\n",
      "EPOCH=1247\n",
      "train: loss=0.19759292753849536 acc=0.9357798165137615\n",
      "test: loss=0.3187019492603315 acc=0.9197247706422018\n",
      "EPOCH=1248\n",
      "train: loss=0.25273861742775305 acc=0.9243119266055045\n",
      "test: loss=0.27938768688803195 acc=0.9105504587155964\n",
      "EPOCH=1249\n",
      "train: loss=0.16309292930154423 acc=0.9357798165137615\n",
      "test: loss=0.2940623167352711 acc=0.9151376146788991\n",
      "EPOCH=1250\n",
      "train: loss=0.07553360073443524 acc=0.9747706422018348\n",
      "test: loss=0.29614210688533477 acc=0.9105504587155964\n",
      "EPOCH=1251\n",
      "train: loss=0.15859474183629454 acc=0.9518348623853211\n",
      "test: loss=0.3142078730741184 acc=0.8990825688073395\n",
      "EPOCH=1252\n",
      "train: loss=0.13896058012723916 acc=0.9541284403669725\n",
      "test: loss=0.31610799946911683 acc=0.8990825688073395\n",
      "EPOCH=1253\n",
      "train: loss=0.17465754184431062 acc=0.9587155963302753\n",
      "test: loss=0.24970467701155905 acc=0.9128440366972477\n",
      "EPOCH=1254\n",
      "train: loss=0.206562845976956 acc=0.9426605504587156\n",
      "test: loss=0.30031709005196844 acc=0.9105504587155964\n",
      "EPOCH=1255\n",
      "train: loss=0.10558056327505773 acc=0.9678899082568807\n",
      "test: loss=0.2961422494242922 acc=0.9105504587155964\n",
      "EPOCH=1256\n",
      "train: loss=0.07306974960207559 acc=0.9701834862385321\n",
      "test: loss=0.35013729250379705 acc=0.8990825688073395\n",
      "EPOCH=1257\n",
      "train: loss=0.14773110200624354 acc=0.9472477064220184\n",
      "test: loss=0.29328439573690684 acc=0.9013761467889908\n",
      "EPOCH=1258\n",
      "train: loss=0.12259112459350975 acc=0.9770642201834863\n",
      "test: loss=0.26109196543789753 acc=0.926605504587156\n",
      "EPOCH=1259\n",
      "train: loss=0.1604076844721382 acc=0.9403669724770642\n",
      "test: loss=0.33588363734767956 acc=0.8967889908256881\n",
      "EPOCH=1260\n",
      "train: loss=0.20500328548430166 acc=0.9243119266055045\n",
      "test: loss=0.33368425171588634 acc=0.9036697247706422\n",
      "EPOCH=1261\n",
      "train: loss=0.11136730645997123 acc=0.963302752293578\n",
      "test: loss=0.29888347022141243 acc=0.9174311926605505\n",
      "EPOCH=1262\n",
      "train: loss=0.09225390013215283 acc=0.9724770642201835\n",
      "test: loss=0.2817864520356652 acc=0.9151376146788991\n",
      "EPOCH=1263\n",
      "train: loss=0.14689466060411716 acc=0.944954128440367\n",
      "test: loss=0.2769514665327408 acc=0.9174311926605505\n",
      "EPOCH=1264\n",
      "train: loss=0.25813278993099353 acc=0.9288990825688074\n",
      "test: loss=0.2870606619915794 acc=0.9151376146788991\n",
      "EPOCH=1265\n",
      "train: loss=0.18767271068016797 acc=0.9495412844036697\n",
      "test: loss=0.3010413123035032 acc=0.9174311926605505\n",
      "EPOCH=1266\n",
      "train: loss=0.11536497830470785 acc=0.963302752293578\n",
      "test: loss=0.26652896780896 acc=0.9220183486238532\n",
      "EPOCH=1267\n",
      "train: loss=0.2284815023275448 acc=0.9311926605504587\n",
      "test: loss=0.3561659433284624 acc=0.908256880733945\n",
      "EPOCH=1268\n",
      "train: loss=0.12098024907884106 acc=0.9678899082568807\n",
      "test: loss=0.3161110602158548 acc=0.8967889908256881\n",
      "EPOCH=1269\n",
      "train: loss=0.08378587574417125 acc=0.9701834862385321\n",
      "test: loss=0.2596559241196211 acc=0.9220183486238532\n",
      "EPOCH=1270\n",
      "train: loss=0.09713340059815424 acc=0.9747706422018348\n",
      "test: loss=0.3806317396428707 acc=0.9059633027522935\n",
      "EPOCH=1271\n",
      "train: loss=0.2736788158053721 acc=0.9174311926605505\n",
      "test: loss=0.3079570341903545 acc=0.9151376146788991\n",
      "EPOCH=1272\n",
      "train: loss=0.1159111079882078 acc=0.963302752293578\n",
      "test: loss=0.26959607462149593 acc=0.9220183486238532\n",
      "EPOCH=1273\n",
      "train: loss=0.26619491898116193 acc=0.926605504587156\n",
      "test: loss=0.27361948142878195 acc=0.9197247706422018\n",
      "EPOCH=1274\n",
      "train: loss=0.13851130068996562 acc=0.9587155963302753\n",
      "test: loss=0.3155884747187412 acc=0.9105504587155964\n",
      "EPOCH=1275\n",
      "train: loss=0.16426018946325213 acc=0.9495412844036697\n",
      "test: loss=0.32601570787874584 acc=0.9220183486238532\n",
      "EPOCH=1276\n",
      "train: loss=0.12041673433207199 acc=0.9655963302752294\n",
      "test: loss=0.23227691189891916 acc=0.9311926605504587\n",
      "EPOCH=1277\n",
      "train: loss=0.09325565984725735 acc=0.9655963302752294\n",
      "test: loss=0.2928898583274538 acc=0.9105504587155964\n",
      "EPOCH=1278\n",
      "train: loss=0.10678843827591586 acc=0.9610091743119266\n",
      "test: loss=0.3241698382120557 acc=0.908256880733945\n",
      "EPOCH=1279\n",
      "train: loss=0.2749735244638637 acc=0.9311926605504587\n",
      "test: loss=0.3034857687442131 acc=0.9105504587155964\n",
      "EPOCH=1280\n",
      "train: loss=0.05156928170249605 acc=0.9862385321100917\n",
      "test: loss=0.3084723164651795 acc=0.9013761467889908\n",
      "EPOCH=1281\n",
      "train: loss=0.09281075483083193 acc=0.9518348623853211\n",
      "test: loss=0.3542818217612678 acc=0.9059633027522935\n",
      "EPOCH=1282\n",
      "train: loss=0.15819973458226155 acc=0.9472477064220184\n",
      "test: loss=0.31698304938908056 acc=0.9105504587155964\n",
      "EPOCH=1283\n",
      "train: loss=0.14122031735150897 acc=0.9587155963302753\n",
      "test: loss=0.269853422463735 acc=0.9059633027522935\n",
      "EPOCH=1284\n",
      "train: loss=0.18560600530432037 acc=0.9380733944954128\n",
      "test: loss=0.2732905471759063 acc=0.9220183486238532\n",
      "EPOCH=1285\n",
      "train: loss=0.16861862623533597 acc=0.9380733944954128\n",
      "test: loss=0.2628830017308899 acc=0.9197247706422018\n",
      "EPOCH=1286\n",
      "train: loss=0.12205753230789783 acc=0.9541284403669725\n",
      "test: loss=0.2651444854924596 acc=0.9220183486238532\n",
      "EPOCH=1287\n",
      "train: loss=0.21428288880499277 acc=0.9334862385321101\n",
      "test: loss=0.3784052698696524 acc=0.8967889908256881\n",
      "EPOCH=1288\n",
      "train: loss=0.11213857507401653 acc=0.9495412844036697\n",
      "test: loss=0.3101996510141861 acc=0.8990825688073395\n",
      "EPOCH=1289\n",
      "train: loss=0.11096377564448875 acc=0.9701834862385321\n",
      "test: loss=0.31094097246196684 acc=0.9105504587155964\n",
      "EPOCH=1290\n",
      "train: loss=0.055502396025485276 acc=0.9770642201834863\n",
      "test: loss=0.25908503033758556 acc=0.908256880733945\n",
      "EPOCH=1291\n",
      "train: loss=0.13092544940882428 acc=0.9564220183486238\n",
      "test: loss=0.28429286918606195 acc=0.9174311926605505\n",
      "EPOCH=1292\n",
      "train: loss=0.18859091211910045 acc=0.9564220183486238\n",
      "test: loss=0.2671807398406067 acc=0.9059633027522935\n",
      "EPOCH=1293\n",
      "train: loss=0.1358350058784475 acc=0.9426605504587156\n",
      "test: loss=0.31415626563291266 acc=0.9174311926605505\n",
      "EPOCH=1294\n",
      "train: loss=0.0857249198274298 acc=0.9678899082568807\n",
      "test: loss=0.2533474341958615 acc=0.9311926605504587\n",
      "EPOCH=1295\n",
      "train: loss=0.2749741744463741 acc=0.926605504587156\n",
      "test: loss=0.3064976051530503 acc=0.9105504587155964\n",
      "EPOCH=1296\n",
      "train: loss=0.04801501996837893 acc=0.9747706422018348\n",
      "test: loss=0.2982302631866186 acc=0.9105504587155964\n",
      "EPOCH=1297\n",
      "train: loss=0.2662472694194208 acc=0.908256880733945\n",
      "test: loss=0.32539581981829946 acc=0.9059633027522935\n",
      "EPOCH=1298\n",
      "train: loss=0.15189741664686654 acc=0.9610091743119266\n",
      "test: loss=0.2741489440198218 acc=0.9151376146788991\n",
      "EPOCH=1299\n",
      "train: loss=0.10192828220756436 acc=0.9701834862385321\n",
      "test: loss=0.27683391698689674 acc=0.9128440366972477\n",
      "EPOCH=1300\n",
      "train: loss=0.23259873181699497 acc=0.9403669724770642\n",
      "test: loss=0.3048260459806827 acc=0.9243119266055045\n",
      "EPOCH=1301\n",
      "train: loss=0.14608267575823114 acc=0.9564220183486238\n",
      "test: loss=0.262545512207134 acc=0.9151376146788991\n",
      "EPOCH=1302\n",
      "train: loss=0.18634444117355511 acc=0.9472477064220184\n",
      "test: loss=0.2497345469127661 acc=0.9197247706422018\n",
      "EPOCH=1303\n",
      "train: loss=0.13271353066730002 acc=0.963302752293578\n",
      "test: loss=0.2878898063759306 acc=0.9174311926605505\n",
      "EPOCH=1304\n",
      "train: loss=0.07712327538769226 acc=0.9701834862385321\n",
      "test: loss=0.25085350796733125 acc=0.9334862385321101\n",
      "EPOCH=1305\n",
      "train: loss=0.22455563427242842 acc=0.9403669724770642\n",
      "test: loss=0.29562007752566755 acc=0.9174311926605505\n",
      "EPOCH=1306\n",
      "train: loss=0.11454115311054239 acc=0.9564220183486238\n",
      "test: loss=0.29834689727981856 acc=0.9220183486238532\n",
      "EPOCH=1307\n",
      "train: loss=0.15872022270029956 acc=0.9334862385321101\n",
      "test: loss=0.3309766294330072 acc=0.9036697247706422\n",
      "EPOCH=1308\n",
      "train: loss=0.13551463825894688 acc=0.9518348623853211\n",
      "test: loss=0.27988420476670295 acc=0.9174311926605505\n",
      "EPOCH=1309\n",
      "train: loss=0.1653562504450618 acc=0.944954128440367\n",
      "test: loss=0.2781046021950714 acc=0.9128440366972477\n",
      "EPOCH=1310\n",
      "train: loss=0.15979907136978178 acc=0.9495412844036697\n",
      "test: loss=0.2314984328630613 acc=0.9403669724770642\n",
      "EPOCH=1311\n",
      "train: loss=0.1497759213546606 acc=0.9495412844036697\n",
      "test: loss=0.28853232577627275 acc=0.9151376146788991\n",
      "EPOCH=1312\n",
      "train: loss=0.1476447247922345 acc=0.9564220183486238\n",
      "test: loss=0.29028745927396366 acc=0.9174311926605505\n",
      "EPOCH=1313\n",
      "train: loss=0.19259742145263406 acc=0.9288990825688074\n",
      "test: loss=0.2833843791275299 acc=0.9288990825688074\n",
      "EPOCH=1314\n",
      "train: loss=0.11411446370762447 acc=0.9701834862385321\n",
      "test: loss=0.3652086296410997 acc=0.8990825688073395\n",
      "EPOCH=1315\n",
      "train: loss=0.17328547588438298 acc=0.9495412844036697\n",
      "test: loss=0.38244833280133567 acc=0.8967889908256881\n",
      "EPOCH=1316\n",
      "train: loss=0.07842184946093853 acc=0.9747706422018348\n",
      "test: loss=0.2948244218583136 acc=0.9105504587155964\n",
      "EPOCH=1317\n",
      "train: loss=0.12176561749996678 acc=0.9564220183486238\n",
      "test: loss=0.3084327852994855 acc=0.9013761467889908\n",
      "EPOCH=1318\n",
      "train: loss=0.21274026388893866 acc=0.944954128440367\n",
      "test: loss=0.27511274907623967 acc=0.9197247706422018\n",
      "EPOCH=1319\n",
      "train: loss=0.16193032048008366 acc=0.9426605504587156\n",
      "test: loss=0.33417935480931826 acc=0.9128440366972477\n",
      "EPOCH=1320\n",
      "train: loss=0.18211352318572707 acc=0.9518348623853211\n",
      "test: loss=0.2292811577167595 acc=0.9288990825688074\n",
      "EPOCH=1321\n",
      "train: loss=0.0600491496969663 acc=0.9747706422018348\n",
      "test: loss=0.24959531445446173 acc=0.9059633027522935\n",
      "EPOCH=1322\n",
      "train: loss=0.16675753170258528 acc=0.9564220183486238\n",
      "test: loss=0.3712464210880266 acc=0.8944954128440367\n",
      "EPOCH=1323\n",
      "train: loss=0.12162926226141293 acc=0.9610091743119266\n",
      "test: loss=0.2976369915999442 acc=0.9013761467889908\n",
      "EPOCH=1324\n",
      "train: loss=0.16977204839277954 acc=0.9610091743119266\n",
      "test: loss=0.31197357889022614 acc=0.908256880733945\n",
      "EPOCH=1325\n",
      "train: loss=0.026961478963415827 acc=0.9885321100917431\n",
      "test: loss=0.24075581281860906 acc=0.9197247706422018\n",
      "EPOCH=1326\n",
      "train: loss=0.24709107905415417 acc=0.9243119266055045\n",
      "test: loss=0.2650498627253662 acc=0.9151376146788991\n",
      "EPOCH=1327\n",
      "train: loss=0.159821485130906 acc=0.9701834862385321\n",
      "test: loss=0.29901807943858894 acc=0.9036697247706422\n",
      "EPOCH=1328\n",
      "train: loss=0.07971791127732193 acc=0.9747706422018348\n",
      "test: loss=0.2564728988148439 acc=0.9197247706422018\n",
      "EPOCH=1329\n",
      "train: loss=0.12587894127724764 acc=0.9610091743119266\n",
      "test: loss=0.22636540457849383 acc=0.9174311926605505\n",
      "EPOCH=1330\n",
      "train: loss=0.1310684647850009 acc=0.963302752293578\n",
      "test: loss=0.3101093045591827 acc=0.908256880733945\n",
      "EPOCH=1331\n",
      "train: loss=0.14930502245522367 acc=0.9380733944954128\n",
      "test: loss=0.28221219008678966 acc=0.9174311926605505\n",
      "EPOCH=1332\n",
      "train: loss=0.19685307254358728 acc=0.9334862385321101\n",
      "test: loss=0.3074460218835635 acc=0.9036697247706422\n",
      "EPOCH=1333\n",
      "train: loss=0.1615327291956952 acc=0.9518348623853211\n",
      "test: loss=0.29594322010391544 acc=0.9036697247706422\n",
      "EPOCH=1334\n",
      "train: loss=0.2298885461781071 acc=0.9426605504587156\n",
      "test: loss=0.2775886675908229 acc=0.9174311926605505\n",
      "EPOCH=1335\n",
      "train: loss=0.14744346296816982 acc=0.9472477064220184\n",
      "test: loss=0.3088317488808051 acc=0.9105504587155964\n",
      "EPOCH=1336\n",
      "train: loss=0.1224063321346495 acc=0.9655963302752294\n",
      "test: loss=0.26187914046929345 acc=0.9105504587155964\n",
      "EPOCH=1337\n",
      "train: loss=0.09824399380379341 acc=0.9724770642201835\n",
      "test: loss=0.34376637465677745 acc=0.8944954128440367\n",
      "EPOCH=1338\n",
      "train: loss=0.08019491704375031 acc=0.9747706422018348\n",
      "test: loss=0.2758026034241448 acc=0.926605504587156\n",
      "EPOCH=1339\n",
      "train: loss=0.22337982812038923 acc=0.9311926605504587\n",
      "test: loss=0.3166507868601219 acc=0.9036697247706422\n",
      "EPOCH=1340\n",
      "train: loss=0.20671699653480297 acc=0.9220183486238532\n",
      "test: loss=0.34560460623480577 acc=0.8990825688073395\n",
      "EPOCH=1341\n",
      "train: loss=0.22531958975990882 acc=0.9357798165137615\n",
      "test: loss=0.27070965393919416 acc=0.9220183486238532\n",
      "EPOCH=1342\n",
      "train: loss=0.14387590388723392 acc=0.9472477064220184\n",
      "test: loss=0.30279763183582736 acc=0.9036697247706422\n",
      "EPOCH=1343\n",
      "train: loss=0.22374519660113967 acc=0.9380733944954128\n",
      "test: loss=0.2782300287842584 acc=0.9243119266055045\n",
      "EPOCH=1344\n",
      "train: loss=0.11090759013204798 acc=0.9678899082568807\n",
      "test: loss=0.2007020437489802 acc=0.9151376146788991\n",
      "EPOCH=1345\n",
      "train: loss=0.1385672281375165 acc=0.9518348623853211\n",
      "test: loss=0.31147132112822545 acc=0.908256880733945\n",
      "EPOCH=1346\n",
      "train: loss=0.21059881083654955 acc=0.9288990825688074\n",
      "test: loss=0.3350966578026543 acc=0.908256880733945\n",
      "EPOCH=1347\n",
      "train: loss=0.3089320035191605 acc=0.9288990825688074\n",
      "test: loss=0.34556884741221777 acc=0.8944954128440367\n",
      "EPOCH=1348\n",
      "train: loss=0.1651807363075874 acc=0.9472477064220184\n",
      "test: loss=0.29601312539578384 acc=0.9105504587155964\n",
      "EPOCH=1349\n",
      "train: loss=0.15966364252777093 acc=0.9495412844036697\n",
      "test: loss=0.33545897572763206 acc=0.9105504587155964\n",
      "EPOCH=1350\n",
      "train: loss=0.15162074948775314 acc=0.9587155963302753\n",
      "test: loss=0.3784501231152364 acc=0.9128440366972477\n",
      "EPOCH=1351\n",
      "train: loss=0.10541456500746395 acc=0.9724770642201835\n",
      "test: loss=0.3131319400787759 acc=0.9151376146788991\n",
      "EPOCH=1352\n",
      "train: loss=0.30553520965329806 acc=0.9311926605504587\n",
      "test: loss=0.31421181230887707 acc=0.908256880733945\n",
      "EPOCH=1353\n",
      "train: loss=0.1256972628448382 acc=0.9678899082568807\n",
      "test: loss=0.2706619289175997 acc=0.9174311926605505\n",
      "EPOCH=1354\n",
      "train: loss=0.1138801151090502 acc=0.9701834862385321\n",
      "test: loss=0.28210769441821554 acc=0.9174311926605505\n",
      "EPOCH=1355\n",
      "train: loss=0.17801908445237447 acc=0.9403669724770642\n",
      "test: loss=0.2800101256113541 acc=0.9059633027522935\n",
      "EPOCH=1356\n",
      "train: loss=0.18653727329433425 acc=0.9495412844036697\n",
      "test: loss=0.28796630346308355 acc=0.9105504587155964\n",
      "EPOCH=1357\n",
      "train: loss=0.17048256859607427 acc=0.9518348623853211\n",
      "test: loss=0.29833241543795325 acc=0.9174311926605505\n",
      "EPOCH=1358\n",
      "train: loss=0.1016205194007888 acc=0.9655963302752294\n",
      "test: loss=0.3050454400746846 acc=0.9059633027522935\n",
      "EPOCH=1359\n",
      "train: loss=0.131797062756805 acc=0.9495412844036697\n",
      "test: loss=0.2645872823811682 acc=0.9197247706422018\n",
      "EPOCH=1360\n",
      "train: loss=0.17889257290156196 acc=0.9587155963302753\n",
      "test: loss=0.2708229760879546 acc=0.9220183486238532\n",
      "EPOCH=1361\n",
      "train: loss=0.1338185490743923 acc=0.9655963302752294\n",
      "test: loss=0.27595126224871896 acc=0.9151376146788991\n",
      "EPOCH=1362\n",
      "train: loss=0.16376390592587434 acc=0.9495412844036697\n",
      "test: loss=0.26656312507265995 acc=0.9128440366972477\n",
      "EPOCH=1363\n",
      "train: loss=0.11161915010236634 acc=0.9655963302752294\n",
      "test: loss=0.2882697374317732 acc=0.9105504587155964\n",
      "EPOCH=1364\n",
      "train: loss=0.24235541118766235 acc=0.9334862385321101\n",
      "test: loss=0.27014585856324136 acc=0.9151376146788991\n",
      "EPOCH=1365\n",
      "train: loss=0.127486546267933 acc=0.9564220183486238\n",
      "test: loss=0.32255418504886263 acc=0.9174311926605505\n",
      "EPOCH=1366\n",
      "train: loss=0.27239906079881127 acc=0.9128440366972477\n",
      "test: loss=0.31954926909903264 acc=0.9174311926605505\n",
      "EPOCH=1367\n",
      "train: loss=0.1259680547940193 acc=0.9610091743119266\n",
      "test: loss=0.2667070734054553 acc=0.9151376146788991\n",
      "EPOCH=1368\n",
      "train: loss=0.11681663940597235 acc=0.9610091743119266\n",
      "test: loss=0.3055785731955169 acc=0.9197247706422018\n",
      "EPOCH=1369\n",
      "train: loss=0.06820805691477232 acc=0.9747706422018348\n",
      "test: loss=0.25724418942857585 acc=0.9243119266055045\n",
      "EPOCH=1370\n",
      "train: loss=0.29462666684809224 acc=0.9174311926605505\n",
      "test: loss=0.38797943669996016 acc=0.9013761467889908\n",
      "EPOCH=1371\n",
      "train: loss=0.054968416557829455 acc=0.9747706422018348\n",
      "test: loss=0.31549233144424627 acc=0.8990825688073395\n",
      "EPOCH=1372\n",
      "train: loss=0.06847727435814142 acc=0.981651376146789\n",
      "test: loss=0.2678121927002902 acc=0.9174311926605505\n",
      "EPOCH=1373\n",
      "train: loss=0.1910677166209729 acc=0.9518348623853211\n",
      "test: loss=0.25672223226419577 acc=0.9128440366972477\n",
      "EPOCH=1374\n",
      "train: loss=0.1815511634542371 acc=0.9472477064220184\n",
      "test: loss=0.20837489473480145 acc=0.9380733944954128\n",
      "EPOCH=1375\n",
      "train: loss=0.15232525076889342 acc=0.9587155963302753\n",
      "test: loss=0.3279991606236287 acc=0.9151376146788991\n",
      "EPOCH=1376\n",
      "train: loss=0.2152393014986183 acc=0.944954128440367\n",
      "test: loss=0.27678456117536104 acc=0.9105504587155964\n",
      "EPOCH=1377\n",
      "train: loss=0.1950019209940405 acc=0.9426605504587156\n",
      "test: loss=0.3184813064178745 acc=0.9151376146788991\n",
      "EPOCH=1378\n",
      "train: loss=0.23191110567244277 acc=0.9403669724770642\n",
      "test: loss=0.3216073984060919 acc=0.9036697247706422\n",
      "EPOCH=1379\n",
      "train: loss=0.1470387646023826 acc=0.9541284403669725\n",
      "test: loss=0.28085343611598884 acc=0.9243119266055045\n",
      "EPOCH=1380\n",
      "train: loss=0.12468298353638112 acc=0.9541284403669725\n",
      "test: loss=0.27696437407521046 acc=0.9197247706422018\n",
      "EPOCH=1381\n",
      "train: loss=0.10203007624057395 acc=0.9587155963302753\n",
      "test: loss=0.32289847212435896 acc=0.9243119266055045\n",
      "EPOCH=1382\n",
      "train: loss=0.08559201073702062 acc=0.9655963302752294\n",
      "test: loss=0.2864952840558262 acc=0.926605504587156\n",
      "EPOCH=1383\n",
      "train: loss=0.14625218801363463 acc=0.9518348623853211\n",
      "test: loss=0.220122794445824 acc=0.9288990825688074\n",
      "EPOCH=1384\n",
      "train: loss=0.17465095670310568 acc=0.9518348623853211\n",
      "test: loss=0.3079580248041285 acc=0.9174311926605505\n",
      "EPOCH=1385\n",
      "train: loss=0.12606990616817795 acc=0.963302752293578\n",
      "test: loss=0.3459321421095582 acc=0.9105504587155964\n",
      "EPOCH=1386\n",
      "train: loss=0.15615823095984602 acc=0.944954128440367\n",
      "test: loss=0.36499158139431015 acc=0.8944954128440367\n",
      "EPOCH=1387\n",
      "train: loss=0.18420505431737647 acc=0.9334862385321101\n",
      "test: loss=0.3714430643523026 acc=0.9197247706422018\n",
      "EPOCH=1388\n",
      "train: loss=0.14182709832682616 acc=0.9541284403669725\n",
      "test: loss=0.3382074667686619 acc=0.9105504587155964\n",
      "EPOCH=1389\n",
      "train: loss=0.1308322168984583 acc=0.963302752293578\n",
      "test: loss=0.34743834081855907 acc=0.908256880733945\n",
      "EPOCH=1390\n",
      "train: loss=0.05210661613845376 acc=0.9747706422018348\n",
      "test: loss=0.2454689114572279 acc=0.9243119266055045\n",
      "EPOCH=1391\n",
      "train: loss=0.09390215497865724 acc=0.9747706422018348\n",
      "test: loss=0.3053504760012265 acc=0.9151376146788991\n",
      "EPOCH=1392\n",
      "train: loss=0.05846635162340079 acc=0.9770642201834863\n",
      "test: loss=0.305960988671118 acc=0.9151376146788991\n",
      "EPOCH=1393\n",
      "train: loss=0.10643816391749336 acc=0.9541284403669725\n",
      "test: loss=0.23013811401302256 acc=0.926605504587156\n",
      "EPOCH=1394\n",
      "train: loss=0.1843310187782229 acc=0.9495412844036697\n",
      "test: loss=0.2784610061130591 acc=0.9151376146788991\n",
      "EPOCH=1395\n",
      "train: loss=0.10856918922286503 acc=0.963302752293578\n",
      "test: loss=0.28461091473367967 acc=0.9105504587155964\n",
      "EPOCH=1396\n",
      "train: loss=0.1942284310024164 acc=0.9380733944954128\n",
      "test: loss=0.32151611857008905 acc=0.9059633027522935\n",
      "EPOCH=1397\n",
      "train: loss=0.2536880493734743 acc=0.9197247706422018\n",
      "test: loss=0.2983099782585272 acc=0.9197247706422018\n",
      "EPOCH=1398\n",
      "train: loss=0.05556990512241915 acc=0.9839449541284404\n",
      "test: loss=0.251628004785414 acc=0.9220183486238532\n",
      "EPOCH=1399\n",
      "train: loss=0.09116068229425352 acc=0.9724770642201835\n",
      "test: loss=0.3409671168691865 acc=0.9036697247706422\n",
      "EPOCH=1400\n",
      "train: loss=0.08735133034475262 acc=0.9655963302752294\n",
      "test: loss=0.27715655072621936 acc=0.9128440366972477\n",
      "EPOCH=1401\n",
      "train: loss=0.1545936949700669 acc=0.9495412844036697\n",
      "test: loss=0.24692427201719083 acc=0.9151376146788991\n",
      "EPOCH=1402\n",
      "train: loss=0.15065969809606866 acc=0.9587155963302753\n",
      "test: loss=0.29036076500169544 acc=0.9059633027522935\n",
      "EPOCH=1403\n",
      "train: loss=0.1772656189448052 acc=0.9380733944954128\n",
      "test: loss=0.2494150330651273 acc=0.9311926605504587\n",
      "EPOCH=1404\n",
      "train: loss=0.19085007535044737 acc=0.9495412844036697\n",
      "test: loss=0.35373064867933274 acc=0.9059633027522935\n",
      "EPOCH=1405\n",
      "train: loss=0.2869779326621699 acc=0.9036697247706422\n",
      "test: loss=0.31672910472319965 acc=0.9059633027522935\n",
      "EPOCH=1406\n",
      "train: loss=0.17784993796341578 acc=0.9472477064220184\n",
      "test: loss=0.3207024385775263 acc=0.9059633027522935\n",
      "EPOCH=1407\n",
      "train: loss=0.23036452331702248 acc=0.9220183486238532\n",
      "test: loss=0.2987206584486006 acc=0.9197247706422018\n",
      "EPOCH=1408\n",
      "train: loss=0.11174006928826057 acc=0.963302752293578\n",
      "test: loss=0.32606315859649104 acc=0.9128440366972477\n",
      "EPOCH=1409\n",
      "train: loss=0.16367987043968235 acc=0.9587155963302753\n",
      "test: loss=0.28006303411776845 acc=0.9174311926605505\n",
      "EPOCH=1410\n",
      "train: loss=0.0750108059354917 acc=0.9747706422018348\n",
      "test: loss=0.2767234241355816 acc=0.9174311926605505\n",
      "EPOCH=1411\n",
      "train: loss=0.2775978308899803 acc=0.908256880733945\n",
      "test: loss=0.33479036925236844 acc=0.9151376146788991\n",
      "EPOCH=1412\n",
      "train: loss=0.29770829889043243 acc=0.9128440366972477\n",
      "test: loss=0.27212625985854666 acc=0.9151376146788991\n",
      "EPOCH=1413\n",
      "train: loss=0.1478590380892345 acc=0.963302752293578\n",
      "test: loss=0.2710495720082712 acc=0.9151376146788991\n",
      "EPOCH=1414\n",
      "train: loss=0.02487652249566113 acc=0.9908256880733946\n",
      "test: loss=0.2669672510643354 acc=0.9197247706422018\n",
      "EPOCH=1415\n",
      "train: loss=0.1770318885524038 acc=0.9518348623853211\n",
      "test: loss=0.3318424872235779 acc=0.9174311926605505\n",
      "EPOCH=1416\n",
      "train: loss=0.14023052275191403 acc=0.9495412844036697\n",
      "test: loss=0.24946112028708958 acc=0.9128440366972477\n",
      "EPOCH=1417\n",
      "train: loss=0.10731695958521628 acc=0.9678899082568807\n",
      "test: loss=0.2474468021051525 acc=0.926605504587156\n",
      "EPOCH=1418\n",
      "train: loss=0.2346261253232807 acc=0.9243119266055045\n",
      "test: loss=0.31836553848594495 acc=0.9105504587155964\n",
      "EPOCH=1419\n",
      "train: loss=0.11020282554135398 acc=0.963302752293578\n",
      "test: loss=0.2719579530887624 acc=0.9243119266055045\n",
      "EPOCH=1420\n",
      "train: loss=0.1382038188200622 acc=0.9564220183486238\n",
      "test: loss=0.2810387491306311 acc=0.9220183486238532\n",
      "EPOCH=1421\n",
      "train: loss=0.1186568438137262 acc=0.9724770642201835\n",
      "test: loss=0.3236774060710938 acc=0.9151376146788991\n",
      "EPOCH=1422\n",
      "train: loss=0.16753422788532482 acc=0.944954128440367\n",
      "test: loss=0.34823745019303076 acc=0.9036697247706422\n",
      "EPOCH=1423\n",
      "train: loss=0.129295129624602 acc=0.9564220183486238\n",
      "test: loss=0.22437318892736535 acc=0.9357798165137615\n",
      "EPOCH=1424\n",
      "train: loss=0.14961076628792416 acc=0.9403669724770642\n",
      "test: loss=0.27612606816931135 acc=0.9105504587155964\n",
      "EPOCH=1425\n",
      "train: loss=0.21917581171032874 acc=0.9403669724770642\n",
      "test: loss=0.3074435329799287 acc=0.9036697247706422\n",
      "EPOCH=1426\n",
      "train: loss=0.13274444300946095 acc=0.9564220183486238\n",
      "test: loss=0.337652076778552 acc=0.9105504587155964\n",
      "EPOCH=1427\n",
      "train: loss=0.154502589019288 acc=0.9587155963302753\n",
      "test: loss=0.34353413820433804 acc=0.9105504587155964\n",
      "EPOCH=1428\n",
      "train: loss=0.08394411759797814 acc=0.9678899082568807\n",
      "test: loss=0.2667916183640521 acc=0.9174311926605505\n",
      "EPOCH=1429\n",
      "train: loss=0.11844694571492004 acc=0.963302752293578\n",
      "test: loss=0.26701499421902736 acc=0.9334862385321101\n",
      "EPOCH=1430\n",
      "train: loss=0.2730831313129861 acc=0.9334862385321101\n",
      "test: loss=0.32574214153211045 acc=0.8990825688073395\n",
      "EPOCH=1431\n",
      "train: loss=0.1563920115557995 acc=0.9426605504587156\n",
      "test: loss=0.27267902407206623 acc=0.926605504587156\n",
      "EPOCH=1432\n",
      "train: loss=0.10324073996695672 acc=0.9587155963302753\n",
      "test: loss=0.32671237013337134 acc=0.9013761467889908\n",
      "EPOCH=1433\n",
      "train: loss=0.13782991637744776 acc=0.9541284403669725\n",
      "test: loss=0.31328995419542216 acc=0.908256880733945\n",
      "EPOCH=1434\n",
      "train: loss=0.22654476618629793 acc=0.9334862385321101\n",
      "test: loss=0.3159594915939864 acc=0.926605504587156\n",
      "EPOCH=1435\n",
      "train: loss=0.1058919489141928 acc=0.9541284403669725\n",
      "test: loss=0.30876505071186083 acc=0.9128440366972477\n",
      "EPOCH=1436\n",
      "train: loss=0.15073523866434665 acc=0.9426605504587156\n",
      "test: loss=0.3309244539562465 acc=0.9059633027522935\n",
      "EPOCH=1437\n",
      "train: loss=0.11422051856454227 acc=0.9587155963302753\n",
      "test: loss=0.27657144297585096 acc=0.9174311926605505\n",
      "EPOCH=1438\n",
      "train: loss=0.16412753685006845 acc=0.963302752293578\n",
      "test: loss=0.2536076501019495 acc=0.9243119266055045\n",
      "EPOCH=1439\n",
      "train: loss=0.1883576493145673 acc=0.9541284403669725\n",
      "test: loss=0.36831525992814884 acc=0.9059633027522935\n",
      "EPOCH=1440\n",
      "train: loss=0.15149577103773498 acc=0.9564220183486238\n",
      "test: loss=0.31206228121416574 acc=0.908256880733945\n",
      "EPOCH=1441\n",
      "train: loss=0.22744015669296436 acc=0.9334862385321101\n",
      "test: loss=0.27520511711505835 acc=0.908256880733945\n",
      "EPOCH=1442\n",
      "train: loss=0.2336676242781992 acc=0.9105504587155964\n",
      "test: loss=0.30235840915342277 acc=0.9128440366972477\n",
      "EPOCH=1443\n",
      "train: loss=0.033468127014092415 acc=0.9862385321100917\n",
      "test: loss=0.28187511798473586 acc=0.926605504587156\n",
      "EPOCH=1444\n",
      "train: loss=0.19858393961502535 acc=0.9380733944954128\n",
      "test: loss=0.27263018322961596 acc=0.9174311926605505\n",
      "EPOCH=1445\n",
      "train: loss=0.12653491020071395 acc=0.9564220183486238\n",
      "test: loss=0.3176472123946662 acc=0.9174311926605505\n",
      "EPOCH=1446\n",
      "train: loss=0.18623026039838916 acc=0.9472477064220184\n",
      "test: loss=0.38505964818858285 acc=0.9059633027522935\n",
      "EPOCH=1447\n",
      "train: loss=0.11088563801068584 acc=0.9701834862385321\n",
      "test: loss=0.3570995671597798 acc=0.9013761467889908\n",
      "EPOCH=1448\n",
      "train: loss=0.12839481208991876 acc=0.9541284403669725\n",
      "test: loss=0.3135868608884565 acc=0.8967889908256881\n",
      "EPOCH=1449\n",
      "train: loss=0.1430048109673747 acc=0.9655963302752294\n",
      "test: loss=0.24543445391786983 acc=0.9220183486238532\n",
      "EPOCH=1450\n",
      "train: loss=0.1527259157365132 acc=0.9587155963302753\n",
      "test: loss=0.24850787741917524 acc=0.9197247706422018\n",
      "EPOCH=1451\n",
      "train: loss=0.21656857944264868 acc=0.9472477064220184\n",
      "test: loss=0.27576727263271356 acc=0.9197247706422018\n",
      "EPOCH=1452\n",
      "train: loss=0.16138482663016124 acc=0.9426605504587156\n",
      "test: loss=0.25971638939793623 acc=0.9128440366972477\n",
      "EPOCH=1453\n",
      "train: loss=0.15752586165603144 acc=0.944954128440367\n",
      "test: loss=0.3428512205947765 acc=0.9059633027522935\n",
      "EPOCH=1454\n",
      "train: loss=0.25326425953660775 acc=0.9220183486238532\n",
      "test: loss=0.29454619100079904 acc=0.908256880733945\n",
      "EPOCH=1455\n",
      "train: loss=0.12419845804975242 acc=0.9587155963302753\n",
      "test: loss=0.35273866868826487 acc=0.9036697247706422\n",
      "EPOCH=1456\n",
      "train: loss=0.06774507920313344 acc=0.9793577981651376\n",
      "test: loss=0.26568443236703004 acc=0.9105504587155964\n",
      "EPOCH=1457\n",
      "train: loss=0.15759191389627497 acc=0.9518348623853211\n",
      "test: loss=0.25467007096508093 acc=0.9220183486238532\n",
      "EPOCH=1458\n",
      "train: loss=0.1601928817213339 acc=0.944954128440367\n",
      "test: loss=0.35073176282241925 acc=0.9013761467889908\n",
      "EPOCH=1459\n",
      "train: loss=0.29716318617257875 acc=0.9334862385321101\n",
      "test: loss=0.26694489384166736 acc=0.9105504587155964\n",
      "EPOCH=1460\n",
      "train: loss=0.11314548468690547 acc=0.9701834862385321\n",
      "test: loss=0.2574152101337106 acc=0.9197247706422018\n",
      "EPOCH=1461\n",
      "train: loss=0.15741213394147938 acc=0.944954128440367\n",
      "test: loss=0.3165133306018979 acc=0.8990825688073395\n",
      "EPOCH=1462\n",
      "train: loss=0.2672278228433816 acc=0.9288990825688074\n",
      "test: loss=0.2979806903107935 acc=0.9151376146788991\n",
      "EPOCH=1463\n",
      "train: loss=0.12113611140072407 acc=0.9541284403669725\n",
      "test: loss=0.3953799667276025 acc=0.9105504587155964\n",
      "EPOCH=1464\n",
      "train: loss=0.08787773297814247 acc=0.9701834862385321\n",
      "test: loss=0.29589377139247525 acc=0.908256880733945\n",
      "EPOCH=1465\n",
      "train: loss=0.09989271817212196 acc=0.9655963302752294\n",
      "test: loss=0.24288361787630913 acc=0.9151376146788991\n",
      "EPOCH=1466\n",
      "train: loss=0.15081746534806287 acc=0.9495412844036697\n",
      "test: loss=0.30748048573313697 acc=0.9197247706422018\n",
      "EPOCH=1467\n",
      "train: loss=0.1281072292619582 acc=0.9701834862385321\n",
      "test: loss=0.26425277639537964 acc=0.9174311926605505\n",
      "EPOCH=1468\n",
      "train: loss=0.18917187155717105 acc=0.9380733944954128\n",
      "test: loss=0.2821516993271321 acc=0.926605504587156\n",
      "EPOCH=1469\n",
      "train: loss=0.09459557909845241 acc=0.9701834862385321\n",
      "test: loss=0.3267957184232452 acc=0.9059633027522935\n",
      "EPOCH=1470\n",
      "train: loss=0.19764453194897297 acc=0.9495412844036697\n",
      "test: loss=0.2983414426544417 acc=0.908256880733945\n",
      "EPOCH=1471\n",
      "train: loss=0.11084657701424286 acc=0.9655963302752294\n",
      "test: loss=0.2971666454054636 acc=0.9197247706422018\n",
      "EPOCH=1472\n",
      "train: loss=0.23105508237978087 acc=0.9334862385321101\n",
      "test: loss=0.32056907841952137 acc=0.9036697247706422\n",
      "EPOCH=1473\n",
      "train: loss=0.13767416911968755 acc=0.9564220183486238\n",
      "test: loss=0.31456092473252023 acc=0.9128440366972477\n",
      "EPOCH=1474\n",
      "train: loss=0.1009890173914412 acc=0.963302752293578\n",
      "test: loss=0.237978299651738 acc=0.9288990825688074\n",
      "EPOCH=1475\n",
      "train: loss=0.13113836250732797 acc=0.9495412844036697\n",
      "test: loss=0.27405673733405467 acc=0.9128440366972477\n",
      "EPOCH=1476\n",
      "train: loss=0.12413130296312033 acc=0.944954128440367\n",
      "test: loss=0.24542889989645622 acc=0.926605504587156\n",
      "EPOCH=1477\n",
      "train: loss=0.24954794843267922 acc=0.9288990825688074\n",
      "test: loss=0.3614060682544326 acc=0.8990825688073395\n",
      "EPOCH=1478\n",
      "train: loss=0.14954196820291474 acc=0.9518348623853211\n",
      "test: loss=0.2537655641147286 acc=0.9288990825688074\n",
      "EPOCH=1479\n",
      "train: loss=0.2825884340204205 acc=0.9151376146788991\n",
      "test: loss=0.2844887179824401 acc=0.9105504587155964\n",
      "EPOCH=1480\n",
      "train: loss=0.16439500365548854 acc=0.9495412844036697\n",
      "test: loss=0.2961988096805645 acc=0.9197247706422018\n",
      "EPOCH=1481\n",
      "train: loss=0.14633884577111073 acc=0.9587155963302753\n",
      "test: loss=0.2608268103558655 acc=0.9197247706422018\n",
      "EPOCH=1482\n",
      "train: loss=0.22651749463918222 acc=0.9288990825688074\n",
      "test: loss=0.2931756518644851 acc=0.908256880733945\n",
      "EPOCH=1483\n",
      "train: loss=0.07167160368384597 acc=0.9747706422018348\n",
      "test: loss=0.30460072063166416 acc=0.9128440366972477\n",
      "EPOCH=1484\n",
      "train: loss=0.16129527086927656 acc=0.963302752293578\n",
      "test: loss=0.3005688212334917 acc=0.9059633027522935\n",
      "EPOCH=1485\n",
      "train: loss=0.16808277466847563 acc=0.9334862385321101\n",
      "test: loss=0.244874105107628 acc=0.926605504587156\n",
      "EPOCH=1486\n",
      "train: loss=0.18003680129179986 acc=0.9495412844036697\n",
      "test: loss=0.3129278109991537 acc=0.9128440366972477\n",
      "EPOCH=1487\n",
      "train: loss=0.16478865044263566 acc=0.9541284403669725\n",
      "test: loss=0.3111191265016368 acc=0.9059633027522935\n",
      "EPOCH=1488\n",
      "train: loss=0.18469246882948687 acc=0.9495412844036697\n",
      "test: loss=0.29584408376266086 acc=0.908256880733945\n",
      "EPOCH=1489\n",
      "train: loss=0.12422918777301399 acc=0.9655963302752294\n",
      "test: loss=0.22190384659292567 acc=0.9288990825688074\n",
      "EPOCH=1490\n",
      "train: loss=0.2745485960108428 acc=0.9288990825688074\n",
      "test: loss=0.29898149595875434 acc=0.9151376146788991\n",
      "EPOCH=1491\n",
      "train: loss=0.07523657977612186 acc=0.9724770642201835\n",
      "test: loss=0.30011470667423706 acc=0.9128440366972477\n",
      "EPOCH=1492\n",
      "train: loss=0.14169955055821723 acc=0.9610091743119266\n",
      "test: loss=0.27524191924701163 acc=0.9128440366972477\n",
      "EPOCH=1493\n",
      "train: loss=0.24952114267446127 acc=0.9334862385321101\n",
      "test: loss=0.2932866909633797 acc=0.9174311926605505\n",
      "EPOCH=1494\n",
      "train: loss=0.08427450983216402 acc=0.9655963302752294\n",
      "test: loss=0.2556700867519927 acc=0.9174311926605505\n",
      "EPOCH=1495\n",
      "train: loss=0.20896930969891395 acc=0.926605504587156\n",
      "test: loss=0.309958868173261 acc=0.9197247706422018\n",
      "EPOCH=1496\n",
      "train: loss=0.08191082367143918 acc=0.9770642201834863\n",
      "test: loss=0.2803639033737166 acc=0.9197247706422018\n",
      "EPOCH=1497\n",
      "train: loss=0.1698486677714735 acc=0.9495412844036697\n",
      "test: loss=0.2950057162572123 acc=0.9013761467889908\n",
      "EPOCH=1498\n",
      "train: loss=0.16493599282054286 acc=0.944954128440367\n",
      "test: loss=0.22037080610407495 acc=0.9243119266055045\n",
      "EPOCH=1499\n",
      "train: loss=0.1944183523259391 acc=0.9403669724770642\n",
      "test: loss=0.32337105873328553 acc=0.9151376146788991\n",
      "EPOCH=1500\n",
      "train: loss=0.17731110596255897 acc=0.9518348623853211\n",
      "test: loss=0.3056248825713028 acc=0.9197247706422018\n",
      "EPOCH=1501\n",
      "train: loss=0.07975886340790575 acc=0.9724770642201835\n",
      "test: loss=0.2688702205956394 acc=0.9174311926605505\n",
      "EPOCH=1502\n",
      "train: loss=0.12455886658445031 acc=0.9655963302752294\n",
      "test: loss=0.23088415783175514 acc=0.9174311926605505\n",
      "EPOCH=1503\n",
      "train: loss=0.0753013324861419 acc=0.9793577981651376\n",
      "test: loss=0.3417540644406838 acc=0.9105504587155964\n",
      "EPOCH=1504\n",
      "train: loss=0.1200664652544982 acc=0.9564220183486238\n",
      "test: loss=0.30256204533806474 acc=0.9174311926605505\n",
      "EPOCH=1505\n",
      "train: loss=0.05720473072554624 acc=0.9793577981651376\n",
      "test: loss=0.2870442332353434 acc=0.9243119266055045\n",
      "EPOCH=1506\n",
      "train: loss=0.10396743845060628 acc=0.9678899082568807\n",
      "test: loss=0.290282728062836 acc=0.9128440366972477\n",
      "EPOCH=1507\n",
      "train: loss=0.28470268498668444 acc=0.9334862385321101\n",
      "test: loss=0.3247219209570413 acc=0.9128440366972477\n",
      "EPOCH=1508\n",
      "train: loss=0.14609397194414625 acc=0.9564220183486238\n",
      "test: loss=0.3241673014034926 acc=0.9128440366972477\n",
      "EPOCH=1509\n",
      "train: loss=0.11776069376926733 acc=0.9541284403669725\n",
      "test: loss=0.2993884792915251 acc=0.9197247706422018\n",
      "EPOCH=1510\n",
      "train: loss=0.1565052601645411 acc=0.963302752293578\n",
      "test: loss=0.30094342511455385 acc=0.9105504587155964\n",
      "EPOCH=1511\n",
      "train: loss=0.0925867814587388 acc=0.9655963302752294\n",
      "test: loss=0.3709008583033253 acc=0.908256880733945\n",
      "EPOCH=1512\n",
      "train: loss=0.19252852313611066 acc=0.9380733944954128\n",
      "test: loss=0.34695849620276614 acc=0.8876146788990825\n",
      "EPOCH=1513\n",
      "train: loss=0.042905443386016935 acc=0.9908256880733946\n",
      "test: loss=0.3439750089924072 acc=0.9059633027522935\n",
      "EPOCH=1514\n",
      "train: loss=0.08836811870050779 acc=0.9701834862385321\n",
      "test: loss=0.3012649318295995 acc=0.908256880733945\n",
      "EPOCH=1515\n",
      "train: loss=0.10648743263405658 acc=0.9747706422018348\n",
      "test: loss=0.2689098540668344 acc=0.9174311926605505\n",
      "EPOCH=1516\n",
      "train: loss=0.14430731294966542 acc=0.9541284403669725\n",
      "test: loss=0.2602065252846654 acc=0.9220183486238532\n",
      "EPOCH=1517\n",
      "train: loss=0.11992596787389503 acc=0.963302752293578\n",
      "test: loss=0.22735393508139656 acc=0.9426605504587156\n",
      "EPOCH=1518\n",
      "train: loss=0.11971749025094774 acc=0.9587155963302753\n",
      "test: loss=0.29721240626774226 acc=0.9243119266055045\n",
      "EPOCH=1519\n",
      "train: loss=0.14398979010072563 acc=0.9518348623853211\n",
      "test: loss=0.3255703172466775 acc=0.9105504587155964\n",
      "EPOCH=1520\n",
      "train: loss=0.1738760758543842 acc=0.9495412844036697\n",
      "test: loss=0.32375640567701647 acc=0.9059633027522935\n",
      "EPOCH=1521\n",
      "train: loss=0.162078839280672 acc=0.9655963302752294\n",
      "test: loss=0.25795000950768926 acc=0.9220183486238532\n",
      "EPOCH=1522\n",
      "train: loss=0.07264979966248895 acc=0.9747706422018348\n",
      "test: loss=0.31166683896782615 acc=0.9151376146788991\n",
      "EPOCH=1523\n",
      "train: loss=0.18951283215680242 acc=0.9541284403669725\n",
      "test: loss=0.27326312687561777 acc=0.9151376146788991\n",
      "EPOCH=1524\n",
      "train: loss=0.14169300235828755 acc=0.9472477064220184\n",
      "test: loss=0.33696371045220114 acc=0.9036697247706422\n",
      "EPOCH=1525\n",
      "train: loss=0.2136408254573795 acc=0.9357798165137615\n",
      "test: loss=0.3018583028020047 acc=0.9197247706422018\n",
      "EPOCH=1526\n",
      "train: loss=0.10210552087857054 acc=0.9587155963302753\n",
      "test: loss=0.2245561259978137 acc=0.9220183486238532\n",
      "EPOCH=1527\n",
      "train: loss=0.19500824841321918 acc=0.9357798165137615\n",
      "test: loss=0.30472141749086334 acc=0.9197247706422018\n",
      "EPOCH=1528\n",
      "train: loss=0.17757384128691664 acc=0.9701834862385321\n",
      "test: loss=0.2757029621844429 acc=0.9174311926605505\n",
      "EPOCH=1529\n",
      "train: loss=0.03015375059270671 acc=0.9885321100917431\n",
      "test: loss=0.3134754171904799 acc=0.9174311926605505\n",
      "EPOCH=1530\n",
      "train: loss=0.2608956079377232 acc=0.926605504587156\n",
      "test: loss=0.3070119992429059 acc=0.9220183486238532\n",
      "EPOCH=1531\n",
      "train: loss=0.11998451087935573 acc=0.9587155963302753\n",
      "test: loss=0.2878596028278512 acc=0.9128440366972477\n",
      "EPOCH=1532\n",
      "train: loss=0.15970504577539993 acc=0.9518348623853211\n",
      "test: loss=0.28321008588658475 acc=0.9220183486238532\n",
      "EPOCH=1533\n",
      "train: loss=0.14493336700684337 acc=0.9541284403669725\n",
      "test: loss=0.31310541627610633 acc=0.9197247706422018\n",
      "EPOCH=1534\n",
      "train: loss=0.16699898357849371 acc=0.9518348623853211\n",
      "test: loss=0.34229894560479984 acc=0.8990825688073395\n",
      "EPOCH=1535\n",
      "train: loss=0.2461267303315994 acc=0.9380733944954128\n",
      "test: loss=0.410366579177269 acc=0.8944954128440367\n",
      "EPOCH=1536\n",
      "train: loss=0.11487182397836866 acc=0.9541284403669725\n",
      "test: loss=0.2545098941936265 acc=0.9243119266055045\n",
      "EPOCH=1537\n",
      "train: loss=0.11955682275772757 acc=0.9701834862385321\n",
      "test: loss=0.37681235843768623 acc=0.8967889908256881\n",
      "EPOCH=1538\n",
      "train: loss=0.18049871349014762 acc=0.9380733944954128\n",
      "test: loss=0.26961146160176497 acc=0.926605504587156\n",
      "EPOCH=1539\n",
      "train: loss=0.20454679067496556 acc=0.9495412844036697\n",
      "test: loss=0.250609878863419 acc=0.9151376146788991\n",
      "EPOCH=1540\n",
      "train: loss=0.13321145291960373 acc=0.9426605504587156\n",
      "test: loss=0.31203864673438664 acc=0.9128440366972477\n",
      "EPOCH=1541\n",
      "train: loss=0.08739427138199848 acc=0.9678899082568807\n",
      "test: loss=0.35075963461729354 acc=0.908256880733945\n",
      "EPOCH=1542\n",
      "train: loss=0.1348116694173819 acc=0.9518348623853211\n",
      "test: loss=0.2522435147083664 acc=0.926605504587156\n",
      "EPOCH=1543\n",
      "train: loss=0.1605093780084234 acc=0.9587155963302753\n",
      "test: loss=0.28583595579679655 acc=0.9174311926605505\n",
      "EPOCH=1544\n",
      "train: loss=0.1011667682420846 acc=0.9655963302752294\n",
      "test: loss=0.2578451078115039 acc=0.9220183486238532\n",
      "EPOCH=1545\n",
      "train: loss=0.1593486746397509 acc=0.9495412844036697\n",
      "test: loss=0.2683982990241501 acc=0.9151376146788991\n",
      "EPOCH=1546\n",
      "train: loss=0.1402483936003675 acc=0.9472477064220184\n",
      "test: loss=0.32147859570195547 acc=0.9128440366972477\n",
      "EPOCH=1547\n",
      "train: loss=0.16995247150393109 acc=0.9587155963302753\n",
      "test: loss=0.26152694413281347 acc=0.9311926605504587\n",
      "EPOCH=1548\n",
      "train: loss=0.11695521961307158 acc=0.9587155963302753\n",
      "test: loss=0.3335298941845441 acc=0.9220183486238532\n",
      "EPOCH=1549\n",
      "train: loss=0.2081303909615249 acc=0.9495412844036697\n",
      "test: loss=0.3440661156611985 acc=0.908256880733945\n",
      "EPOCH=1550\n",
      "train: loss=0.19837456126419786 acc=0.9357798165137615\n",
      "test: loss=0.3758079135158257 acc=0.8899082568807339\n",
      "EPOCH=1551\n",
      "train: loss=0.13504133612583663 acc=0.9541284403669725\n",
      "test: loss=0.37389101442043643 acc=0.9036697247706422\n",
      "EPOCH=1552\n",
      "train: loss=0.12557130497918845 acc=0.9564220183486238\n",
      "test: loss=0.3360442802625247 acc=0.9059633027522935\n",
      "EPOCH=1553\n",
      "train: loss=0.08012520031868917 acc=0.9701834862385321\n",
      "test: loss=0.32468353984614823 acc=0.9128440366972477\n",
      "EPOCH=1554\n",
      "train: loss=0.11125409323439268 acc=0.9701834862385321\n",
      "test: loss=0.3271745460160033 acc=0.9013761467889908\n",
      "EPOCH=1555\n",
      "train: loss=0.18527701643636454 acc=0.9357798165137615\n",
      "test: loss=0.3391590781096526 acc=0.8967889908256881\n",
      "EPOCH=1556\n",
      "train: loss=0.22577476130504462 acc=0.9288990825688074\n",
      "test: loss=0.3732527226737075 acc=0.8990825688073395\n",
      "EPOCH=1557\n",
      "train: loss=0.27770464882674173 acc=0.9288990825688074\n",
      "test: loss=0.3883951019268424 acc=0.8899082568807339\n",
      "EPOCH=1558\n",
      "train: loss=0.31170711226273107 acc=0.926605504587156\n",
      "test: loss=0.37064114957573263 acc=0.8967889908256881\n",
      "EPOCH=1559\n",
      "train: loss=0.12905368517952642 acc=0.9564220183486238\n",
      "test: loss=0.2858526168055146 acc=0.8944954128440367\n",
      "EPOCH=1560\n",
      "train: loss=0.10352693044259478 acc=0.963302752293578\n",
      "test: loss=0.27115859978092066 acc=0.9197247706422018\n",
      "EPOCH=1561\n",
      "train: loss=0.06990464428272267 acc=0.9747706422018348\n",
      "test: loss=0.31146257002212013 acc=0.9174311926605505\n",
      "EPOCH=1562\n",
      "train: loss=0.3453087953188714 acc=0.8967889908256881\n",
      "test: loss=0.3087382923311034 acc=0.926605504587156\n",
      "EPOCH=1563\n",
      "train: loss=0.1516406453425571 acc=0.9587155963302753\n",
      "test: loss=0.23969633568762777 acc=0.9311926605504587\n",
      "EPOCH=1564\n",
      "train: loss=0.15033590052173426 acc=0.9564220183486238\n",
      "test: loss=0.32441948963049894 acc=0.9151376146788991\n",
      "EPOCH=1565\n",
      "train: loss=0.24610714159677516 acc=0.9426605504587156\n",
      "test: loss=0.3377879756576666 acc=0.9151376146788991\n",
      "EPOCH=1566\n",
      "train: loss=0.09188465988286021 acc=0.9655963302752294\n",
      "test: loss=0.33632339824645374 acc=0.9036697247706422\n",
      "EPOCH=1567\n",
      "train: loss=0.17012939985520434 acc=0.9426605504587156\n",
      "test: loss=0.3239237963992833 acc=0.908256880733945\n",
      "EPOCH=1568\n",
      "train: loss=0.14081025236615816 acc=0.9564220183486238\n",
      "test: loss=0.3300204153846886 acc=0.9059633027522935\n",
      "EPOCH=1569\n",
      "train: loss=0.0977590206967183 acc=0.9701834862385321\n",
      "test: loss=0.2932296655195118 acc=0.9105504587155964\n",
      "EPOCH=1570\n",
      "train: loss=0.26807793749842057 acc=0.9197247706422018\n",
      "test: loss=0.36129611921549487 acc=0.908256880733945\n",
      "EPOCH=1571\n",
      "train: loss=0.1430016990609958 acc=0.9610091743119266\n",
      "test: loss=0.3576860081362598 acc=0.9151376146788991\n",
      "EPOCH=1572\n",
      "train: loss=0.21779428373439033 acc=0.9426605504587156\n",
      "test: loss=0.3224267143489458 acc=0.9036697247706422\n",
      "EPOCH=1573\n",
      "train: loss=0.21056998016472955 acc=0.9311926605504587\n",
      "test: loss=0.3053971421735699 acc=0.908256880733945\n",
      "EPOCH=1574\n",
      "train: loss=0.16045834967155317 acc=0.944954128440367\n",
      "test: loss=0.26313504640361035 acc=0.9174311926605505\n",
      "EPOCH=1575\n",
      "train: loss=0.07251419731301323 acc=0.9724770642201835\n",
      "test: loss=0.27826356814966374 acc=0.9174311926605505\n",
      "EPOCH=1576\n",
      "train: loss=0.22552617469454667 acc=0.9334862385321101\n",
      "test: loss=0.2409892901485134 acc=0.9220183486238532\n",
      "EPOCH=1577\n",
      "train: loss=0.2513614931337639 acc=0.9334862385321101\n",
      "test: loss=0.28945780467799487 acc=0.9197247706422018\n",
      "EPOCH=1578\n",
      "train: loss=0.10613850537037775 acc=0.9610091743119266\n",
      "test: loss=0.38207685718515266 acc=0.9105504587155964\n",
      "EPOCH=1579\n",
      "train: loss=0.3387213738490244 acc=0.9105504587155964\n",
      "test: loss=0.25247159736709546 acc=0.9128440366972477\n",
      "EPOCH=1580\n",
      "train: loss=0.18134594797733714 acc=0.9334862385321101\n",
      "test: loss=0.3548785137898157 acc=0.908256880733945\n",
      "EPOCH=1581\n",
      "train: loss=0.12277539970295562 acc=0.9518348623853211\n",
      "test: loss=0.23326059680319075 acc=0.926605504587156\n",
      "EPOCH=1582\n",
      "train: loss=0.2806426810959897 acc=0.9403669724770642\n",
      "test: loss=0.2864390212247014 acc=0.9151376146788991\n",
      "EPOCH=1583\n",
      "train: loss=0.1541833917759576 acc=0.9472477064220184\n",
      "test: loss=0.3609083703024299 acc=0.9128440366972477\n",
      "EPOCH=1584\n",
      "train: loss=0.12534889254204878 acc=0.9610091743119266\n",
      "test: loss=0.25280852156169037 acc=0.9288990825688074\n",
      "EPOCH=1585\n",
      "train: loss=0.22399658525962177 acc=0.9197247706422018\n",
      "test: loss=0.3108228346944057 acc=0.908256880733945\n",
      "EPOCH=1586\n",
      "train: loss=0.15078465646854114 acc=0.9495412844036697\n",
      "test: loss=0.3099105126584249 acc=0.908256880733945\n",
      "EPOCH=1587\n",
      "train: loss=0.20072465289224345 acc=0.944954128440367\n",
      "test: loss=0.21337459923739335 acc=0.9380733944954128\n",
      "EPOCH=1588\n",
      "train: loss=0.15523916780651292 acc=0.9403669724770642\n",
      "test: loss=0.3667368401019299 acc=0.9013761467889908\n",
      "EPOCH=1589\n",
      "train: loss=0.15564253790464755 acc=0.9403669724770642\n",
      "test: loss=0.22938071199752938 acc=0.9128440366972477\n",
      "EPOCH=1590\n",
      "train: loss=0.11833598386900887 acc=0.9587155963302753\n",
      "test: loss=0.24146804550885442 acc=0.9357798165137615\n",
      "EPOCH=1591\n",
      "train: loss=0.10514596277911567 acc=0.9495412844036697\n",
      "test: loss=0.28019103810644264 acc=0.9220183486238532\n",
      "EPOCH=1592\n",
      "train: loss=0.12669939973349803 acc=0.9587155963302753\n",
      "test: loss=0.31573748466628626 acc=0.9151376146788991\n",
      "EPOCH=1593\n",
      "train: loss=0.25455781892565243 acc=0.9357798165137615\n",
      "test: loss=0.29282704905717705 acc=0.9197247706422018\n",
      "EPOCH=1594\n",
      "train: loss=0.15767976665261332 acc=0.9426605504587156\n",
      "test: loss=0.3387348121550624 acc=0.9059633027522935\n",
      "EPOCH=1595\n",
      "train: loss=0.07095481768272736 acc=0.9793577981651376\n",
      "test: loss=0.23808192990835042 acc=0.926605504587156\n",
      "EPOCH=1596\n",
      "train: loss=0.23388222091239025 acc=0.9311926605504587\n",
      "test: loss=0.29241817138637927 acc=0.9174311926605505\n",
      "EPOCH=1597\n",
      "train: loss=0.114527975745589 acc=0.9564220183486238\n",
      "test: loss=0.331879292340581 acc=0.908256880733945\n",
      "EPOCH=1598\n",
      "train: loss=0.17340866403129707 acc=0.9541284403669725\n",
      "test: loss=0.30269882192129993 acc=0.9128440366972477\n",
      "EPOCH=1599\n",
      "train: loss=0.16180818159640564 acc=0.9495412844036697\n",
      "test: loss=0.32080396884686857 acc=0.9059633027522935\n",
      "EPOCH=1600\n",
      "train: loss=0.14586640135830745 acc=0.9655963302752294\n",
      "test: loss=0.31731001334656145 acc=0.9059633027522935\n",
      "EPOCH=1601\n",
      "train: loss=0.21624935404220436 acc=0.944954128440367\n",
      "test: loss=0.3554535261015287 acc=0.9036697247706422\n",
      "EPOCH=1602\n",
      "train: loss=0.08514344588689546 acc=0.9701834862385321\n",
      "test: loss=0.21847038868105367 acc=0.9288990825688074\n",
      "EPOCH=1603\n",
      "train: loss=0.17567418894051615 acc=0.9472477064220184\n",
      "test: loss=0.28096462755014995 acc=0.9243119266055045\n",
      "EPOCH=1604\n",
      "train: loss=0.15887380491299227 acc=0.9426605504587156\n",
      "test: loss=0.2881148391472414 acc=0.9174311926605505\n",
      "EPOCH=1605\n",
      "train: loss=0.1404245923728796 acc=0.963302752293578\n",
      "test: loss=0.27671617157926326 acc=0.9128440366972477\n",
      "EPOCH=1606\n",
      "train: loss=0.2079119339166907 acc=0.9518348623853211\n",
      "test: loss=0.36004860686111817 acc=0.9128440366972477\n",
      "EPOCH=1607\n",
      "train: loss=0.10215676874934479 acc=0.9678899082568807\n",
      "test: loss=0.2623906066280612 acc=0.926605504587156\n",
      "EPOCH=1608\n",
      "train: loss=0.10426914035094709 acc=0.9587155963302753\n",
      "test: loss=0.352276491167506 acc=0.9105504587155964\n",
      "EPOCH=1609\n",
      "train: loss=0.18697799304908883 acc=0.9564220183486238\n",
      "test: loss=0.3198079208893117 acc=0.9105504587155964\n",
      "EPOCH=1610\n",
      "train: loss=0.1421366963014357 acc=0.9610091743119266\n",
      "test: loss=0.2724240483163954 acc=0.926605504587156\n",
      "EPOCH=1611\n",
      "train: loss=0.09926659586553253 acc=0.981651376146789\n",
      "test: loss=0.28436148299080677 acc=0.9128440366972477\n",
      "EPOCH=1612\n",
      "train: loss=0.15061035709211365 acc=0.9518348623853211\n",
      "test: loss=0.3338890312044162 acc=0.9128440366972477\n",
      "EPOCH=1613\n",
      "train: loss=0.15953809077634695 acc=0.9380733944954128\n",
      "test: loss=0.31550014310994734 acc=0.9243119266055045\n",
      "EPOCH=1614\n",
      "train: loss=0.30008831110610557 acc=0.9036697247706422\n",
      "test: loss=0.33845538153769517 acc=0.9036697247706422\n",
      "EPOCH=1615\n",
      "train: loss=0.1229615466505621 acc=0.9610091743119266\n",
      "test: loss=0.32192016334263335 acc=0.9105504587155964\n",
      "EPOCH=1616\n",
      "train: loss=0.10955963860081012 acc=0.9518348623853211\n",
      "test: loss=0.27221610668027707 acc=0.9288990825688074\n",
      "EPOCH=1617\n",
      "train: loss=0.053620233421456685 acc=0.9793577981651376\n",
      "test: loss=0.30781693703842267 acc=0.9288990825688074\n",
      "EPOCH=1618\n",
      "train: loss=0.13680763097242538 acc=0.9495412844036697\n",
      "test: loss=0.2947539642961219 acc=0.9105504587155964\n",
      "EPOCH=1619\n",
      "train: loss=0.10027981472391959 acc=0.9610091743119266\n",
      "test: loss=0.33268102937134536 acc=0.9059633027522935\n",
      "EPOCH=1620\n",
      "train: loss=0.06347380764896689 acc=0.9701834862385321\n",
      "test: loss=0.266594980572385 acc=0.926605504587156\n",
      "EPOCH=1621\n",
      "train: loss=0.14534600203495085 acc=0.963302752293578\n",
      "test: loss=0.3718545808677086 acc=0.8944954128440367\n",
      "EPOCH=1622\n",
      "train: loss=0.20879297751664272 acc=0.9403669724770642\n",
      "test: loss=0.27388737959975545 acc=0.9128440366972477\n",
      "EPOCH=1623\n",
      "train: loss=0.10988055403753189 acc=0.9678899082568807\n",
      "test: loss=0.2803103063112962 acc=0.908256880733945\n",
      "EPOCH=1624\n",
      "train: loss=0.24231414087113026 acc=0.9334862385321101\n",
      "test: loss=0.3288155362045785 acc=0.908256880733945\n",
      "EPOCH=1625\n",
      "train: loss=0.12324328726104275 acc=0.9610091743119266\n",
      "test: loss=0.44427210326120176 acc=0.8830275229357798\n",
      "EPOCH=1626\n",
      "train: loss=0.038726395475240205 acc=0.9862385321100917\n",
      "test: loss=0.30882021433017276 acc=0.9174311926605505\n",
      "EPOCH=1627\n",
      "train: loss=0.2640484746327052 acc=0.9151376146788991\n",
      "test: loss=0.26842034702189715 acc=0.9197247706422018\n",
      "EPOCH=1628\n",
      "train: loss=0.09309830775281495 acc=0.9724770642201835\n",
      "test: loss=0.2789156401383104 acc=0.9197247706422018\n",
      "EPOCH=1629\n",
      "train: loss=0.2865382850994969 acc=0.9105504587155964\n",
      "test: loss=0.35732960144855735 acc=0.8990825688073395\n",
      "EPOCH=1630\n",
      "train: loss=0.23135533869111594 acc=0.9288990825688074\n",
      "test: loss=0.3299344818956306 acc=0.9151376146788991\n",
      "EPOCH=1631\n",
      "train: loss=0.1850915813825241 acc=0.9472477064220184\n",
      "test: loss=0.28101072031400254 acc=0.9059633027522935\n",
      "EPOCH=1632\n",
      "train: loss=0.2116909893066265 acc=0.9334862385321101\n",
      "test: loss=0.2671764028845651 acc=0.9197247706422018\n",
      "EPOCH=1633\n",
      "train: loss=0.0531539829085568 acc=0.981651376146789\n",
      "test: loss=0.3178312808509307 acc=0.8944954128440367\n",
      "EPOCH=1634\n",
      "train: loss=0.19577761140071975 acc=0.9311926605504587\n",
      "test: loss=0.28752343264910507 acc=0.926605504587156\n",
      "EPOCH=1635\n",
      "train: loss=0.08684846421223825 acc=0.9701834862385321\n",
      "test: loss=0.21538841538367812 acc=0.926605504587156\n",
      "EPOCH=1636\n",
      "train: loss=0.171034336729362 acc=0.963302752293578\n",
      "test: loss=0.3120518715143382 acc=0.9151376146788991\n",
      "EPOCH=1637\n",
      "train: loss=0.33425270662327594 acc=0.8990825688073395\n",
      "test: loss=0.2846850803267814 acc=0.9243119266055045\n",
      "EPOCH=1638\n",
      "train: loss=0.24152500485635728 acc=0.9243119266055045\n",
      "test: loss=0.36103690391708915 acc=0.8990825688073395\n",
      "EPOCH=1639\n",
      "train: loss=0.18107816531618198 acc=0.9495412844036697\n",
      "test: loss=0.3238149751736537 acc=0.9174311926605505\n",
      "EPOCH=1640\n",
      "train: loss=0.20002576509755074 acc=0.9426605504587156\n",
      "test: loss=0.2701394767422126 acc=0.9197247706422018\n",
      "EPOCH=1641\n",
      "train: loss=0.171602492105466 acc=0.9610091743119266\n",
      "test: loss=0.36002276838268166 acc=0.9059633027522935\n",
      "EPOCH=1642\n",
      "train: loss=0.22115470142237492 acc=0.9403669724770642\n",
      "test: loss=0.3337866039319313 acc=0.8990825688073395\n",
      "EPOCH=1643\n",
      "train: loss=0.15667858409478594 acc=0.9495412844036697\n",
      "test: loss=0.31110800497613217 acc=0.9128440366972477\n",
      "EPOCH=1644\n",
      "train: loss=0.19122390635052203 acc=0.9610091743119266\n",
      "test: loss=0.3951778239698144 acc=0.8830275229357798\n",
      "EPOCH=1645\n",
      "train: loss=0.28614873013613223 acc=0.9357798165137615\n",
      "test: loss=0.3667951823108762 acc=0.908256880733945\n",
      "EPOCH=1646\n",
      "train: loss=0.17544237844877025 acc=0.9403669724770642\n",
      "test: loss=0.43624071464772374 acc=0.8876146788990825\n",
      "EPOCH=1647\n",
      "train: loss=0.21599916024526608 acc=0.9518348623853211\n",
      "test: loss=0.2831987258016406 acc=0.908256880733945\n",
      "EPOCH=1648\n",
      "train: loss=0.1565049304762871 acc=0.9518348623853211\n",
      "test: loss=0.3639852207830093 acc=0.9105504587155964\n",
      "EPOCH=1649\n",
      "train: loss=0.22190130872295216 acc=0.9311926605504587\n",
      "test: loss=0.3691536994404947 acc=0.9036697247706422\n",
      "EPOCH=1650\n",
      "train: loss=0.19641999178283306 acc=0.9518348623853211\n",
      "test: loss=0.2503066841984987 acc=0.9243119266055045\n",
      "EPOCH=1651\n",
      "train: loss=0.1945886518841859 acc=0.9610091743119266\n",
      "test: loss=0.3744833622220574 acc=0.8944954128440367\n",
      "EPOCH=1652\n",
      "train: loss=0.06214086693697579 acc=0.981651376146789\n",
      "test: loss=0.3468533332241374 acc=0.8967889908256881\n",
      "EPOCH=1653\n",
      "train: loss=0.21158344115440933 acc=0.9311926605504587\n",
      "test: loss=0.35682066701349135 acc=0.908256880733945\n",
      "EPOCH=1654\n",
      "train: loss=0.13316355573552333 acc=0.9541284403669725\n",
      "test: loss=0.4007456851132146 acc=0.8990825688073395\n",
      "EPOCH=1655\n",
      "train: loss=0.26927083839492266 acc=0.9311926605504587\n",
      "test: loss=0.3136820914176682 acc=0.908256880733945\n",
      "EPOCH=1656\n",
      "train: loss=0.22217760975822437 acc=0.9564220183486238\n",
      "test: loss=0.29133303386382353 acc=0.9243119266055045\n",
      "EPOCH=1657\n",
      "train: loss=0.145895625469241 acc=0.9610091743119266\n",
      "test: loss=0.31880278177148136 acc=0.9174311926605505\n",
      "EPOCH=1658\n",
      "train: loss=0.29299150998756307 acc=0.9151376146788991\n",
      "test: loss=0.35278829992183003 acc=0.9013761467889908\n",
      "EPOCH=1659\n",
      "train: loss=0.24224240492730317 acc=0.9243119266055045\n",
      "test: loss=0.3036480990515542 acc=0.9059633027522935\n",
      "EPOCH=1660\n",
      "train: loss=0.15896506729782087 acc=0.9518348623853211\n",
      "test: loss=0.3267750617772866 acc=0.9059633027522935\n",
      "EPOCH=1661\n",
      "train: loss=0.20218741220240263 acc=0.9472477064220184\n",
      "test: loss=0.29363137724062716 acc=0.9128440366972477\n",
      "EPOCH=1662\n",
      "train: loss=0.16300788678875677 acc=0.9426605504587156\n",
      "test: loss=0.3130367696279246 acc=0.9059633027522935\n",
      "EPOCH=1663\n",
      "train: loss=0.20452474039523424 acc=0.9380733944954128\n",
      "test: loss=0.23617803290090125 acc=0.9243119266055045\n",
      "EPOCH=1664\n",
      "train: loss=0.2227717602703717 acc=0.944954128440367\n",
      "test: loss=0.3675734817681705 acc=0.9036697247706422\n",
      "EPOCH=1665\n",
      "train: loss=0.2917208175043807 acc=0.9174311926605505\n",
      "test: loss=0.3885565658632548 acc=0.9036697247706422\n",
      "EPOCH=1666\n",
      "train: loss=0.2806168621293693 acc=0.9288990825688074\n",
      "test: loss=0.30285212121715077 acc=0.9036697247706422\n",
      "EPOCH=1667\n",
      "train: loss=0.2401640314219629 acc=0.9243119266055045\n",
      "test: loss=0.33091288056297896 acc=0.9128440366972477\n",
      "EPOCH=1668\n",
      "train: loss=0.10571217060069751 acc=0.9678899082568807\n",
      "test: loss=0.3121086170479483 acc=0.8944954128440367\n",
      "EPOCH=1669\n",
      "train: loss=0.1350150300384118 acc=0.9472477064220184\n",
      "test: loss=0.26876456161936946 acc=0.926605504587156\n",
      "EPOCH=1670\n",
      "train: loss=0.16362784616693482 acc=0.9541284403669725\n",
      "test: loss=0.32663153140614637 acc=0.9197247706422018\n",
      "EPOCH=1671\n",
      "train: loss=0.14380358898517492 acc=0.9610091743119266\n",
      "test: loss=0.2763181102996851 acc=0.9174311926605505\n",
      "EPOCH=1672\n",
      "train: loss=0.14485427441449117 acc=0.9541284403669725\n",
      "test: loss=0.2869366169279849 acc=0.9151376146788991\n",
      "EPOCH=1673\n",
      "train: loss=0.14210686954867194 acc=0.9610091743119266\n",
      "test: loss=0.344469299257188 acc=0.908256880733945\n",
      "EPOCH=1674\n",
      "train: loss=0.23771167437089769 acc=0.9311926605504587\n",
      "test: loss=0.3092058171337967 acc=0.9128440366972477\n",
      "EPOCH=1675\n",
      "train: loss=0.2566337393013474 acc=0.9403669724770642\n",
      "test: loss=0.34431592109468423 acc=0.8922018348623854\n",
      "EPOCH=1676\n",
      "train: loss=0.2000618897875331 acc=0.9426605504587156\n",
      "test: loss=0.2971844336537784 acc=0.908256880733945\n",
      "EPOCH=1677\n",
      "train: loss=0.17123578737202222 acc=0.9472477064220184\n",
      "test: loss=0.32955166095658606 acc=0.908256880733945\n",
      "EPOCH=1678\n",
      "train: loss=0.23134255351648683 acc=0.9380733944954128\n",
      "test: loss=0.28900218792860344 acc=0.9220183486238532\n",
      "EPOCH=1679\n",
      "train: loss=0.12370881380988448 acc=0.9678899082568807\n",
      "test: loss=0.2845027280942388 acc=0.926605504587156\n",
      "EPOCH=1680\n",
      "train: loss=0.13715681827389486 acc=0.9587155963302753\n",
      "test: loss=0.38416146619981134 acc=0.8990825688073395\n",
      "EPOCH=1681\n",
      "train: loss=0.15394264147720968 acc=0.9518348623853211\n",
      "test: loss=0.3761727549691126 acc=0.8899082568807339\n",
      "EPOCH=1682\n",
      "train: loss=0.2149496049195341 acc=0.9288990825688074\n",
      "test: loss=0.3975622473548315 acc=0.8876146788990825\n",
      "EPOCH=1683\n",
      "train: loss=0.14464602070869975 acc=0.9610091743119266\n",
      "test: loss=0.40786342256965474 acc=0.8990825688073395\n",
      "EPOCH=1684\n",
      "train: loss=0.1870045098174326 acc=0.9403669724770642\n",
      "test: loss=0.4008604643642832 acc=0.908256880733945\n",
      "EPOCH=1685\n",
      "train: loss=0.417192096404956 acc=0.8944954128440367\n",
      "test: loss=0.3115778218411262 acc=0.9105504587155964\n",
      "EPOCH=1686\n",
      "train: loss=0.10940288118883233 acc=0.9610091743119266\n",
      "test: loss=0.3104770863179983 acc=0.9128440366972477\n",
      "EPOCH=1687\n",
      "train: loss=0.19388749110047174 acc=0.9403669724770642\n",
      "test: loss=0.3122248424077838 acc=0.9013761467889908\n",
      "EPOCH=1688\n",
      "train: loss=0.16716308767709664 acc=0.9495412844036697\n",
      "test: loss=0.34370711454266417 acc=0.9013761467889908\n",
      "EPOCH=1689\n",
      "train: loss=0.05744671746575487 acc=0.9839449541284404\n",
      "test: loss=0.33511747759018623 acc=0.9013761467889908\n",
      "EPOCH=1690\n",
      "train: loss=0.21562801092777562 acc=0.9288990825688074\n",
      "test: loss=0.30805770370176905 acc=0.9151376146788991\n",
      "EPOCH=1691\n",
      "train: loss=0.10251623159866184 acc=0.9701834862385321\n",
      "test: loss=0.3717872078431192 acc=0.8967889908256881\n",
      "EPOCH=1692\n",
      "train: loss=0.15171329381261792 acc=0.9495412844036697\n",
      "test: loss=0.3549641406271085 acc=0.9128440366972477\n",
      "EPOCH=1693\n",
      "train: loss=0.2997548175211316 acc=0.9151376146788991\n",
      "test: loss=0.3604056079202276 acc=0.908256880733945\n",
      "EPOCH=1694\n",
      "train: loss=0.1805153103328607 acc=0.9472477064220184\n",
      "test: loss=0.28386662832086196 acc=0.908256880733945\n",
      "EPOCH=1695\n",
      "train: loss=0.18225542638742528 acc=0.9357798165137615\n",
      "test: loss=0.3082994922863155 acc=0.9105504587155964\n",
      "EPOCH=1696\n",
      "train: loss=0.21182301373614856 acc=0.9380733944954128\n",
      "test: loss=0.3379034799679918 acc=0.908256880733945\n",
      "EPOCH=1697\n",
      "train: loss=0.19197354975289221 acc=0.944954128440367\n",
      "test: loss=0.4195469200429093 acc=0.8876146788990825\n",
      "EPOCH=1698\n",
      "train: loss=0.08476476362873962 acc=0.9678899082568807\n",
      "test: loss=0.30234345898340037 acc=0.9059633027522935\n",
      "EPOCH=1699\n",
      "train: loss=0.23671849521103644 acc=0.9334862385321101\n",
      "test: loss=0.37541219046833924 acc=0.9036697247706422\n",
      "EPOCH=1700\n",
      "train: loss=0.11374214576907885 acc=0.9724770642201835\n",
      "test: loss=0.3826882220303108 acc=0.9059633027522935\n",
      "EPOCH=1701\n",
      "train: loss=0.19157125201454012 acc=0.9495412844036697\n",
      "test: loss=0.40711147532828623 acc=0.8922018348623854\n",
      "EPOCH=1702\n",
      "train: loss=0.15860725209503623 acc=0.9587155963302753\n",
      "test: loss=0.2875987255063403 acc=0.9334862385321101\n",
      "EPOCH=1703\n",
      "train: loss=0.2402495828315622 acc=0.9380733944954128\n",
      "test: loss=0.33903363041510515 acc=0.8922018348623854\n",
      "EPOCH=1704\n",
      "train: loss=0.14233414672552278 acc=0.963302752293578\n",
      "test: loss=0.2923174291911529 acc=0.9174311926605505\n",
      "EPOCH=1705\n",
      "train: loss=0.11648276730443462 acc=0.9655963302752294\n",
      "test: loss=0.2836963531157102 acc=0.9174311926605505\n",
      "EPOCH=1706\n",
      "train: loss=0.10142701901325112 acc=0.9678899082568807\n",
      "test: loss=0.3401335042408803 acc=0.908256880733945\n",
      "EPOCH=1707\n",
      "train: loss=0.20781512680119368 acc=0.944954128440367\n",
      "test: loss=0.37103987599128524 acc=0.9105504587155964\n",
      "EPOCH=1708\n",
      "train: loss=0.16245097682659274 acc=0.9472477064220184\n",
      "test: loss=0.28201742475802244 acc=0.9151376146788991\n",
      "EPOCH=1709\n",
      "train: loss=0.1665734179119452 acc=0.9472477064220184\n",
      "test: loss=0.36760372643523265 acc=0.8990825688073395\n",
      "EPOCH=1710\n",
      "train: loss=0.1395964174329536 acc=0.9610091743119266\n",
      "test: loss=0.40156047669365447 acc=0.8922018348623854\n",
      "EPOCH=1711\n",
      "train: loss=0.31529835186226074 acc=0.9220183486238532\n",
      "test: loss=0.30970478036444826 acc=0.9174311926605505\n",
      "EPOCH=1712\n",
      "train: loss=0.265376474892242 acc=0.9151376146788991\n",
      "test: loss=0.29333984813555475 acc=0.9105504587155964\n",
      "EPOCH=1713\n",
      "train: loss=0.21971853067538605 acc=0.9472477064220184\n",
      "test: loss=0.2752460599681306 acc=0.9220183486238532\n",
      "EPOCH=1714\n",
      "train: loss=0.1663265455294331 acc=0.9426605504587156\n",
      "test: loss=0.3183034113594383 acc=0.9220183486238532\n",
      "EPOCH=1715\n",
      "train: loss=0.18465139525251228 acc=0.963302752293578\n",
      "test: loss=0.276385692084841 acc=0.9059633027522935\n",
      "EPOCH=1716\n",
      "train: loss=0.16874594806631427 acc=0.9587155963302753\n",
      "test: loss=0.29583054636115413 acc=0.9151376146788991\n",
      "EPOCH=1717\n",
      "train: loss=0.17501740137129093 acc=0.9426605504587156\n",
      "test: loss=0.43369463280966686 acc=0.8990825688073395\n",
      "EPOCH=1718\n",
      "train: loss=0.18191407603975893 acc=0.9518348623853211\n",
      "test: loss=0.4052567973568549 acc=0.8944954128440367\n",
      "EPOCH=1719\n",
      "train: loss=0.32670565711419075 acc=0.9288990825688074\n",
      "test: loss=0.35358027430124983 acc=0.9013761467889908\n",
      "EPOCH=1720\n",
      "train: loss=0.14422175294278045 acc=0.9495412844036697\n",
      "test: loss=0.30168955200908654 acc=0.9197247706422018\n",
      "EPOCH=1721\n",
      "train: loss=0.11878944539491203 acc=0.9541284403669725\n",
      "test: loss=0.43015442496853273 acc=0.8944954128440367\n",
      "EPOCH=1722\n",
      "train: loss=0.14341715394276958 acc=0.9541284403669725\n",
      "test: loss=0.4763878220075696 acc=0.9036697247706422\n",
      "EPOCH=1723\n",
      "train: loss=0.2510313515395333 acc=0.9380733944954128\n",
      "test: loss=0.4418811140484491 acc=0.8967889908256881\n",
      "EPOCH=1724\n",
      "train: loss=0.5047793109689397 acc=0.8646788990825688\n",
      "test: loss=0.415000527139054 acc=0.8922018348623854\n",
      "EPOCH=1725\n",
      "train: loss=0.24538390738907329 acc=0.926605504587156\n",
      "test: loss=0.4003111466186967 acc=0.9174311926605505\n",
      "EPOCH=1726\n",
      "train: loss=0.12334124538281287 acc=0.963302752293578\n",
      "test: loss=0.29616882657118837 acc=0.9128440366972477\n",
      "EPOCH=1727\n",
      "train: loss=0.17312435332871365 acc=0.944954128440367\n",
      "test: loss=0.3163551377327914 acc=0.9174311926605505\n",
      "EPOCH=1728\n",
      "train: loss=0.20180597697170047 acc=0.9472477064220184\n",
      "test: loss=0.34275125943910867 acc=0.9128440366972477\n",
      "EPOCH=1729\n",
      "train: loss=0.17647753211059924 acc=0.9357798165137615\n",
      "test: loss=0.311430311160718 acc=0.9174311926605505\n",
      "EPOCH=1730\n",
      "train: loss=0.10086410425939668 acc=0.9610091743119266\n",
      "test: loss=0.33110592254248444 acc=0.9128440366972477\n",
      "EPOCH=1731\n",
      "train: loss=0.15900987829169627 acc=0.9541284403669725\n",
      "test: loss=0.3286945627025202 acc=0.9151376146788991\n",
      "EPOCH=1732\n",
      "train: loss=0.10734001997112183 acc=0.9724770642201835\n",
      "test: loss=0.3135586326009744 acc=0.9220183486238532\n",
      "EPOCH=1733\n",
      "train: loss=0.21474594474314043 acc=0.9311926605504587\n",
      "test: loss=0.2502857685042687 acc=0.9220183486238532\n",
      "EPOCH=1734\n",
      "train: loss=0.19474877562969098 acc=0.9403669724770642\n",
      "test: loss=0.3085538115036833 acc=0.9151376146788991\n",
      "EPOCH=1735\n",
      "train: loss=0.0904796616282876 acc=0.9678899082568807\n",
      "test: loss=0.32388259428981425 acc=0.9151376146788991\n",
      "EPOCH=1736\n",
      "train: loss=0.1646159921070627 acc=0.9357798165137615\n",
      "test: loss=0.2605225281820171 acc=0.908256880733945\n",
      "EPOCH=1737\n",
      "train: loss=0.11843807624046306 acc=0.9587155963302753\n",
      "test: loss=0.30456665698322927 acc=0.9151376146788991\n",
      "EPOCH=1738\n",
      "train: loss=0.13960386137677064 acc=0.9564220183486238\n",
      "test: loss=0.28835210005491757 acc=0.9059633027522935\n",
      "EPOCH=1739\n",
      "train: loss=0.16969782875502354 acc=0.9472477064220184\n",
      "test: loss=0.2960201742406148 acc=0.9059633027522935\n",
      "EPOCH=1740\n",
      "train: loss=0.11239996275218328 acc=0.9541284403669725\n",
      "test: loss=0.27560410369453103 acc=0.9105504587155964\n",
      "EPOCH=1741\n",
      "train: loss=0.16198524998540131 acc=0.9495412844036697\n",
      "test: loss=0.27260714071714204 acc=0.926605504587156\n",
      "EPOCH=1742\n",
      "train: loss=0.175713413578324 acc=0.9541284403669725\n",
      "test: loss=0.2985896232064469 acc=0.908256880733945\n",
      "EPOCH=1743\n",
      "train: loss=0.15833850758579746 acc=0.9357798165137615\n",
      "test: loss=0.31296854238264465 acc=0.9036697247706422\n",
      "EPOCH=1744\n",
      "train: loss=0.22583533717673673 acc=0.9564220183486238\n",
      "test: loss=0.32668361874669716 acc=0.8990825688073395\n",
      "EPOCH=1745\n",
      "train: loss=0.1485531289166267 acc=0.9587155963302753\n",
      "test: loss=0.28853262659232837 acc=0.9197247706422018\n",
      "EPOCH=1746\n",
      "train: loss=0.18463803322226596 acc=0.9518348623853211\n",
      "test: loss=0.28157581329508174 acc=0.9334862385321101\n",
      "EPOCH=1747\n",
      "train: loss=0.13245889663289123 acc=0.9678899082568807\n",
      "test: loss=0.2718045289390997 acc=0.9151376146788991\n",
      "EPOCH=1748\n",
      "train: loss=0.09474938798243124 acc=0.9678899082568807\n",
      "test: loss=0.3014699424023559 acc=0.9059633027522935\n",
      "EPOCH=1749\n",
      "train: loss=0.09633506474970402 acc=0.9655963302752294\n",
      "test: loss=0.3393184530412744 acc=0.8967889908256881\n",
      "EPOCH=1750\n",
      "train: loss=0.28236270318183965 acc=0.9174311926605505\n",
      "test: loss=0.2817641154981506 acc=0.9197247706422018\n",
      "EPOCH=1751\n",
      "train: loss=0.2943637894380333 acc=0.9151376146788991\n",
      "test: loss=0.2695106284058915 acc=0.9197247706422018\n",
      "EPOCH=1752\n",
      "train: loss=0.2055648353973509 acc=0.9357798165137615\n",
      "test: loss=0.23661052709539995 acc=0.9174311926605505\n",
      "EPOCH=1753\n",
      "train: loss=0.2302132621856276 acc=0.9243119266055045\n",
      "test: loss=0.28690491544762203 acc=0.9059633027522935\n",
      "EPOCH=1754\n",
      "train: loss=0.20674698576720998 acc=0.9541284403669725\n",
      "test: loss=0.3216031301920822 acc=0.9036697247706422\n",
      "EPOCH=1755\n",
      "train: loss=0.223744722004225 acc=0.9380733944954128\n",
      "test: loss=0.3165509220104859 acc=0.9059633027522935\n",
      "EPOCH=1756\n",
      "train: loss=0.17582950912247763 acc=0.9541284403669725\n",
      "test: loss=0.31930487921645195 acc=0.9243119266055045\n",
      "EPOCH=1757\n",
      "train: loss=0.20061199512012606 acc=0.9426605504587156\n",
      "test: loss=0.29236081569882244 acc=0.908256880733945\n",
      "EPOCH=1758\n",
      "train: loss=0.2216984912522375 acc=0.944954128440367\n",
      "test: loss=0.38735254133664493 acc=0.9059633027522935\n",
      "EPOCH=1759\n",
      "train: loss=0.18301002896979918 acc=0.9380733944954128\n",
      "test: loss=0.21236712404730762 acc=0.9357798165137615\n",
      "EPOCH=1760\n",
      "train: loss=0.2698445941527868 acc=0.9059633027522935\n",
      "test: loss=0.3204852508519545 acc=0.8990825688073395\n",
      "EPOCH=1761\n",
      "train: loss=0.12543824793193079 acc=0.9655963302752294\n",
      "test: loss=0.34748365915383367 acc=0.9013761467889908\n",
      "EPOCH=1762\n",
      "train: loss=0.28558473146195457 acc=0.9128440366972477\n",
      "test: loss=0.22413144000679588 acc=0.9311926605504587\n",
      "EPOCH=1763\n",
      "train: loss=0.04975990250851664 acc=0.981651376146789\n",
      "test: loss=0.22329784905854783 acc=0.9288990825688074\n",
      "EPOCH=1764\n",
      "train: loss=0.24384484803475237 acc=0.9357798165137615\n",
      "test: loss=0.3202753223458255 acc=0.908256880733945\n",
      "EPOCH=1765\n",
      "train: loss=0.19694236352966962 acc=0.9472477064220184\n",
      "test: loss=0.27570352625988376 acc=0.9128440366972477\n",
      "EPOCH=1766\n",
      "train: loss=0.23894635228127384 acc=0.9357798165137615\n",
      "test: loss=0.2718019208432021 acc=0.9105504587155964\n",
      "EPOCH=1767\n",
      "train: loss=0.17395402769005106 acc=0.9472477064220184\n",
      "test: loss=0.3237852477122867 acc=0.9174311926605505\n",
      "EPOCH=1768\n",
      "train: loss=0.10273107694235709 acc=0.9701834862385321\n",
      "test: loss=0.42695170048760617 acc=0.8853211009174312\n",
      "EPOCH=1769\n",
      "train: loss=0.21539187079144023 acc=0.9243119266055045\n",
      "test: loss=0.2938461238339936 acc=0.9174311926605505\n",
      "EPOCH=1770\n",
      "train: loss=0.10658665219866523 acc=0.9678899082568807\n",
      "test: loss=0.28446462517773274 acc=0.9197247706422018\n",
      "EPOCH=1771\n",
      "train: loss=0.1117411979099457 acc=0.963302752293578\n",
      "test: loss=0.2646954643202056 acc=0.9197247706422018\n",
      "EPOCH=1772\n",
      "train: loss=0.13666929770403688 acc=0.9541284403669725\n",
      "test: loss=0.3404584863352938 acc=0.9105504587155964\n",
      "EPOCH=1773\n",
      "train: loss=0.48320500134489136 acc=0.8807339449541285\n",
      "test: loss=0.38296569281497783 acc=0.8944954128440367\n",
      "EPOCH=1774\n",
      "train: loss=0.17280056712310865 acc=0.9610091743119266\n",
      "test: loss=0.2813196663692465 acc=0.9288990825688074\n",
      "EPOCH=1775\n",
      "train: loss=0.11942434705828282 acc=0.963302752293578\n",
      "test: loss=0.32120268961278287 acc=0.9059633027522935\n",
      "EPOCH=1776\n",
      "train: loss=0.16593723709306393 acc=0.9541284403669725\n",
      "test: loss=0.2568416833313063 acc=0.9128440366972477\n",
      "EPOCH=1777\n",
      "train: loss=0.15169024161813657 acc=0.9541284403669725\n",
      "test: loss=0.28450594037419713 acc=0.9036697247706422\n",
      "EPOCH=1778\n",
      "train: loss=0.2745016000405784 acc=0.944954128440367\n",
      "test: loss=0.3075911171003185 acc=0.908256880733945\n",
      "EPOCH=1779\n",
      "train: loss=0.21773035834823262 acc=0.9311926605504587\n",
      "test: loss=0.3014704231939684 acc=0.9128440366972477\n",
      "EPOCH=1780\n",
      "train: loss=0.12728415053220538 acc=0.9495412844036697\n",
      "test: loss=0.22795318309581294 acc=0.9380733944954128\n",
      "EPOCH=1781\n",
      "train: loss=0.10130995898713162 acc=0.9701834862385321\n",
      "test: loss=0.23397007747402881 acc=0.9288990825688074\n",
      "EPOCH=1782\n",
      "train: loss=0.12852497556664919 acc=0.9564220183486238\n",
      "test: loss=0.3239433466609199 acc=0.8853211009174312\n",
      "EPOCH=1783\n",
      "train: loss=0.13392055400520203 acc=0.9610091743119266\n",
      "test: loss=0.22673304561885535 acc=0.9357798165137615\n",
      "EPOCH=1784\n",
      "train: loss=0.14257864555246136 acc=0.963302752293578\n",
      "test: loss=0.2335546839841593 acc=0.9128440366972477\n",
      "EPOCH=1785\n",
      "train: loss=0.1265392891934009 acc=0.9587155963302753\n",
      "test: loss=0.3462227871476423 acc=0.9128440366972477\n",
      "EPOCH=1786\n",
      "train: loss=0.18182246987376705 acc=0.944954128440367\n",
      "test: loss=0.2968722331624545 acc=0.9128440366972477\n",
      "EPOCH=1787\n",
      "train: loss=0.15907100919012107 acc=0.9472477064220184\n",
      "test: loss=0.2905971379903137 acc=0.9151376146788991\n",
      "EPOCH=1788\n",
      "train: loss=0.14533324192398545 acc=0.9541284403669725\n",
      "test: loss=0.24525724153374703 acc=0.9311926605504587\n",
      "EPOCH=1789\n",
      "train: loss=0.14557481053731222 acc=0.9587155963302753\n",
      "test: loss=0.29539273804033944 acc=0.9036697247706422\n",
      "EPOCH=1790\n",
      "train: loss=0.21329564625747616 acc=0.944954128440367\n",
      "test: loss=0.31996191462448603 acc=0.9013761467889908\n",
      "EPOCH=1791\n",
      "train: loss=0.20804122240232445 acc=0.9541284403669725\n",
      "test: loss=0.2959289829814739 acc=0.9128440366972477\n",
      "EPOCH=1792\n",
      "train: loss=0.07223224683655784 acc=0.963302752293578\n",
      "test: loss=0.25171579719776177 acc=0.9128440366972477\n",
      "EPOCH=1793\n",
      "train: loss=0.16309614206646042 acc=0.9472477064220184\n",
      "test: loss=0.3160333359625116 acc=0.9059633027522935\n",
      "EPOCH=1794\n",
      "train: loss=0.16393392099796514 acc=0.9587155963302753\n",
      "test: loss=0.3188220417163894 acc=0.9059633027522935\n",
      "EPOCH=1795\n",
      "train: loss=0.2738155394409273 acc=0.9311926605504587\n",
      "test: loss=0.3874890845687325 acc=0.8876146788990825\n",
      "EPOCH=1796\n",
      "train: loss=0.1605677209743223 acc=0.9495412844036697\n",
      "test: loss=0.2908052651584444 acc=0.9151376146788991\n",
      "EPOCH=1797\n",
      "train: loss=0.07840215130418245 acc=0.9678899082568807\n",
      "test: loss=0.32857550461939883 acc=0.908256880733945\n",
      "EPOCH=1798\n",
      "train: loss=0.20177139601753466 acc=0.9380733944954128\n",
      "test: loss=0.22740998414564728 acc=0.9243119266055045\n",
      "EPOCH=1799\n",
      "train: loss=0.13291609066746923 acc=0.9587155963302753\n",
      "test: loss=0.2823282716644164 acc=0.9243119266055045\n",
      "EPOCH=1800\n",
      "train: loss=0.12912864273879238 acc=0.9541284403669725\n",
      "test: loss=0.32064666639038936 acc=0.9128440366972477\n",
      "EPOCH=1801\n",
      "train: loss=0.09855707194146897 acc=0.9564220183486238\n",
      "test: loss=0.28735734672557667 acc=0.9059633027522935\n",
      "EPOCH=1802\n",
      "train: loss=0.1411146943477249 acc=0.9587155963302753\n",
      "test: loss=0.3603780672567541 acc=0.8967889908256881\n",
      "EPOCH=1803\n",
      "train: loss=0.1755106744754299 acc=0.944954128440367\n",
      "test: loss=0.2744478718806766 acc=0.9197247706422018\n",
      "EPOCH=1804\n",
      "train: loss=0.1726155907199036 acc=0.9495412844036697\n",
      "test: loss=0.327992282351678 acc=0.9059633027522935\n",
      "EPOCH=1805\n",
      "train: loss=0.05075166202668157 acc=0.9885321100917431\n",
      "test: loss=0.31498901309428207 acc=0.9059633027522935\n",
      "EPOCH=1806\n",
      "train: loss=0.2323933109493647 acc=0.9334862385321101\n",
      "test: loss=0.290715410919681 acc=0.9220183486238532\n",
      "EPOCH=1807\n",
      "train: loss=0.20434164704096566 acc=0.944954128440367\n",
      "test: loss=0.25976008785584725 acc=0.9288990825688074\n",
      "EPOCH=1808\n",
      "train: loss=0.19056861918204132 acc=0.926605504587156\n",
      "test: loss=0.3527975772286468 acc=0.908256880733945\n",
      "EPOCH=1809\n",
      "train: loss=0.13566900311346952 acc=0.9541284403669725\n",
      "test: loss=0.3545285976537867 acc=0.8967889908256881\n",
      "EPOCH=1810\n",
      "train: loss=0.25720633394827747 acc=0.9518348623853211\n",
      "test: loss=0.26695825608085794 acc=0.9174311926605505\n",
      "EPOCH=1811\n",
      "train: loss=0.20440320076022098 acc=0.9495412844036697\n",
      "test: loss=0.28044850117122666 acc=0.9059633027522935\n",
      "EPOCH=1812\n",
      "train: loss=0.15924896108939698 acc=0.9518348623853211\n",
      "test: loss=0.40110599698379035 acc=0.8990825688073395\n",
      "EPOCH=1813\n",
      "train: loss=0.1310187784512111 acc=0.9655963302752294\n",
      "test: loss=0.2767578003770628 acc=0.9128440366972477\n",
      "EPOCH=1814\n",
      "train: loss=0.11300342640954386 acc=0.963302752293578\n",
      "test: loss=0.3080996148465001 acc=0.9197247706422018\n",
      "EPOCH=1815\n",
      "train: loss=0.25452483483059574 acc=0.9357798165137615\n",
      "test: loss=0.2162116801904245 acc=0.9174311926605505\n",
      "EPOCH=1816\n",
      "train: loss=0.1027446275679637 acc=0.9564220183486238\n",
      "test: loss=0.22481900094121401 acc=0.9288990825688074\n",
      "EPOCH=1817\n",
      "train: loss=0.1401938369593971 acc=0.9587155963302753\n",
      "test: loss=0.3011063422270057 acc=0.9220183486238532\n",
      "EPOCH=1818\n",
      "train: loss=0.14225837635704783 acc=0.9495412844036697\n",
      "test: loss=0.39597473584056186 acc=0.8922018348623854\n",
      "EPOCH=1819\n",
      "train: loss=0.0927933966668746 acc=0.9747706422018348\n",
      "test: loss=0.25852426232162334 acc=0.9128440366972477\n",
      "EPOCH=1820\n",
      "train: loss=0.11170109342801227 acc=0.9655963302752294\n",
      "test: loss=0.2644480729133609 acc=0.9288990825688074\n",
      "EPOCH=1821\n",
      "train: loss=0.07897603555428297 acc=0.9701834862385321\n",
      "test: loss=0.2856518111798996 acc=0.9036697247706422\n",
      "EPOCH=1822\n",
      "train: loss=0.07582936524504996 acc=0.9701834862385321\n",
      "test: loss=0.22685210457700639 acc=0.9311926605504587\n",
      "EPOCH=1823\n",
      "train: loss=0.18083913429213166 acc=0.9403669724770642\n",
      "test: loss=0.27420052174902876 acc=0.9174311926605505\n",
      "EPOCH=1824\n",
      "train: loss=0.13296140392280412 acc=0.9655963302752294\n",
      "test: loss=0.29502810540553986 acc=0.9197247706422018\n",
      "EPOCH=1825\n",
      "train: loss=0.17976534960346274 acc=0.9472477064220184\n",
      "test: loss=0.22074416344434397 acc=0.926605504587156\n",
      "EPOCH=1826\n",
      "train: loss=0.17547001371534157 acc=0.9541284403669725\n",
      "test: loss=0.2563373672311776 acc=0.9311926605504587\n",
      "EPOCH=1827\n",
      "train: loss=0.21686283020925 acc=0.9334862385321101\n",
      "test: loss=0.32780564568489123 acc=0.9036697247706422\n",
      "EPOCH=1828\n",
      "train: loss=0.21014935194151427 acc=0.9220183486238532\n",
      "test: loss=0.2983121288694839 acc=0.9197247706422018\n",
      "EPOCH=1829\n",
      "train: loss=0.18955317529578222 acc=0.9495412844036697\n",
      "test: loss=0.24617490289153554 acc=0.926605504587156\n",
      "EPOCH=1830\n",
      "train: loss=0.1579494232995857 acc=0.963302752293578\n",
      "test: loss=0.33325764245990136 acc=0.908256880733945\n",
      "EPOCH=1831\n",
      "train: loss=0.20021417798744612 acc=0.9380733944954128\n",
      "test: loss=0.3184617520231679 acc=0.9036697247706422\n",
      "EPOCH=1832\n",
      "train: loss=0.21488871480322067 acc=0.9380733944954128\n",
      "test: loss=0.33216994385565085 acc=0.8990825688073395\n",
      "EPOCH=1833\n",
      "train: loss=0.1493786490562066 acc=0.9541284403669725\n",
      "test: loss=0.3110154152350446 acc=0.9128440366972477\n",
      "EPOCH=1834\n",
      "train: loss=0.0972598479570061 acc=0.9587155963302753\n",
      "test: loss=0.2949354165684184 acc=0.9197247706422018\n",
      "EPOCH=1835\n",
      "train: loss=0.07231218000557031 acc=0.9770642201834863\n",
      "test: loss=0.2592029494662135 acc=0.9197247706422018\n",
      "EPOCH=1836\n",
      "train: loss=0.11633698982943054 acc=0.9518348623853211\n",
      "test: loss=0.21035279383271677 acc=0.9174311926605505\n",
      "EPOCH=1837\n",
      "train: loss=0.3631330243154918 acc=0.908256880733945\n",
      "test: loss=0.21483302679453464 acc=0.9334862385321101\n",
      "EPOCH=1838\n",
      "train: loss=0.09189598120708863 acc=0.9724770642201835\n",
      "test: loss=0.3454988091043287 acc=0.8944954128440367\n",
      "EPOCH=1839\n",
      "train: loss=0.14539745942704027 acc=0.9587155963302753\n",
      "test: loss=0.34518738043809344 acc=0.9128440366972477\n",
      "EPOCH=1840\n",
      "train: loss=0.1590180186655087 acc=0.9426605504587156\n",
      "test: loss=0.34876834511902494 acc=0.9059633027522935\n",
      "EPOCH=1841\n",
      "train: loss=0.31033300646937634 acc=0.9105504587155964\n",
      "test: loss=0.26845939886887027 acc=0.9174311926605505\n",
      "EPOCH=1842\n",
      "train: loss=0.09773123074177026 acc=0.9747706422018348\n",
      "test: loss=0.3707282166917471 acc=0.8922018348623854\n",
      "EPOCH=1843\n",
      "train: loss=0.16450602506875306 acc=0.944954128440367\n",
      "test: loss=0.27973603041393513 acc=0.9151376146788991\n",
      "EPOCH=1844\n",
      "train: loss=0.1723875628273134 acc=0.9495412844036697\n",
      "test: loss=0.2423719261170266 acc=0.9243119266055045\n",
      "EPOCH=1845\n",
      "train: loss=0.16421072012610693 acc=0.9518348623853211\n",
      "test: loss=0.25835307870506524 acc=0.9105504587155964\n",
      "EPOCH=1846\n",
      "train: loss=0.17715490528692346 acc=0.944954128440367\n",
      "test: loss=0.22793891297647415 acc=0.9334862385321101\n",
      "EPOCH=1847\n",
      "train: loss=0.17514394771412 acc=0.9518348623853211\n",
      "test: loss=0.30205758408630373 acc=0.9220183486238532\n",
      "EPOCH=1848\n",
      "train: loss=0.19606316170365154 acc=0.944954128440367\n",
      "test: loss=0.29347620961084475 acc=0.9151376146788991\n",
      "EPOCH=1849\n",
      "train: loss=0.11819738799336442 acc=0.9655963302752294\n",
      "test: loss=0.2808674968570248 acc=0.9036697247706422\n",
      "EPOCH=1850\n",
      "train: loss=0.11908419321758092 acc=0.9701834862385321\n",
      "test: loss=0.20447960938528703 acc=0.9380733944954128\n",
      "EPOCH=1851\n",
      "train: loss=0.14191741073844757 acc=0.9518348623853211\n",
      "test: loss=0.24940252410723648 acc=0.9128440366972477\n",
      "EPOCH=1852\n",
      "train: loss=0.13417237050018882 acc=0.9541284403669725\n",
      "test: loss=0.2924044360263846 acc=0.9174311926605505\n",
      "EPOCH=1853\n",
      "train: loss=0.040101619381399084 acc=0.9793577981651376\n",
      "test: loss=0.24484476983403997 acc=0.9243119266055045\n",
      "EPOCH=1854\n",
      "train: loss=0.1597527844165945 acc=0.9587155963302753\n",
      "test: loss=0.2970270714632138 acc=0.9105504587155964\n",
      "EPOCH=1855\n",
      "train: loss=0.16219532030175277 acc=0.9334862385321101\n",
      "test: loss=0.3111983524592237 acc=0.9220183486238532\n",
      "EPOCH=1856\n",
      "train: loss=0.17770834224699883 acc=0.9587155963302753\n",
      "test: loss=0.30105775332128465 acc=0.9013761467889908\n",
      "EPOCH=1857\n",
      "train: loss=0.13608135250945702 acc=0.9610091743119266\n",
      "test: loss=0.2777603460559831 acc=0.9174311926605505\n",
      "EPOCH=1858\n",
      "train: loss=0.12579239700286599 acc=0.9472477064220184\n",
      "test: loss=0.3155986343817904 acc=0.8967889908256881\n",
      "EPOCH=1859\n",
      "train: loss=0.2467916454122884 acc=0.9311926605504587\n",
      "test: loss=0.33874987026620323 acc=0.9128440366972477\n",
      "EPOCH=1860\n",
      "train: loss=0.1289445739949312 acc=0.963302752293578\n",
      "test: loss=0.3055535804241986 acc=0.9128440366972477\n",
      "EPOCH=1861\n",
      "train: loss=0.13916034472419161 acc=0.9541284403669725\n",
      "test: loss=0.3285529921131173 acc=0.908256880733945\n",
      "EPOCH=1862\n",
      "train: loss=0.2356817899493083 acc=0.9403669724770642\n",
      "test: loss=0.23731772436721302 acc=0.9334862385321101\n",
      "EPOCH=1863\n",
      "train: loss=0.15411110842840864 acc=0.9518348623853211\n",
      "test: loss=0.31154551203451725 acc=0.9220183486238532\n",
      "EPOCH=1864\n",
      "train: loss=0.16251608032330886 acc=0.9518348623853211\n",
      "test: loss=0.23761677150291372 acc=0.9334862385321101\n",
      "EPOCH=1865\n",
      "train: loss=0.16219812454834348 acc=0.9403669724770642\n",
      "test: loss=0.31734088019835344 acc=0.9105504587155964\n",
      "EPOCH=1866\n",
      "train: loss=0.18167068122557722 acc=0.9426605504587156\n",
      "test: loss=0.38434461909679835 acc=0.9036697247706422\n",
      "EPOCH=1867\n",
      "train: loss=0.13030693259114817 acc=0.9518348623853211\n",
      "test: loss=0.33998900271059995 acc=0.8944954128440367\n",
      "EPOCH=1868\n",
      "train: loss=0.2388892062767862 acc=0.9288990825688074\n",
      "test: loss=0.31883100764180644 acc=0.9174311926605505\n",
      "EPOCH=1869\n",
      "train: loss=0.21166625877472978 acc=0.9426605504587156\n",
      "test: loss=0.24101004807366153 acc=0.9220183486238532\n",
      "EPOCH=1870\n",
      "train: loss=0.15005650994898803 acc=0.9610091743119266\n",
      "test: loss=0.24065493142323882 acc=0.926605504587156\n",
      "EPOCH=1871\n",
      "train: loss=0.2986805989136175 acc=0.9311926605504587\n",
      "test: loss=0.23599528921518242 acc=0.926605504587156\n",
      "EPOCH=1872\n",
      "train: loss=0.25551855437288407 acc=0.9311926605504587\n",
      "test: loss=0.3343711909115885 acc=0.9036697247706422\n",
      "EPOCH=1873\n",
      "train: loss=0.1914682208041007 acc=0.9426605504587156\n",
      "test: loss=0.2391379501792643 acc=0.9288990825688074\n",
      "EPOCH=1874\n",
      "train: loss=0.17969981120775788 acc=0.9426605504587156\n",
      "test: loss=0.33410833282782815 acc=0.9128440366972477\n",
      "EPOCH=1875\n",
      "train: loss=0.18476434594674615 acc=0.9334862385321101\n",
      "test: loss=0.2799416316400338 acc=0.9174311926605505\n",
      "EPOCH=1876\n",
      "train: loss=0.26779877453355033 acc=0.9174311926605505\n",
      "test: loss=0.2472068794746177 acc=0.9128440366972477\n",
      "EPOCH=1877\n",
      "train: loss=0.1395466995875693 acc=0.9564220183486238\n",
      "test: loss=0.39778695133214376 acc=0.8899082568807339\n",
      "EPOCH=1878\n",
      "train: loss=0.09427487833256505 acc=0.9610091743119266\n",
      "test: loss=0.2269859031047217 acc=0.9357798165137615\n",
      "EPOCH=1879\n",
      "train: loss=0.09714132644643657 acc=0.9587155963302753\n",
      "test: loss=0.323679755595173 acc=0.9036697247706422\n",
      "EPOCH=1880\n",
      "train: loss=0.15162576135191705 acc=0.9495412844036697\n",
      "test: loss=0.30449682723281124 acc=0.8967889908256881\n",
      "EPOCH=1881\n",
      "train: loss=0.23128259248232297 acc=0.9564220183486238\n",
      "test: loss=0.3003506167034271 acc=0.9128440366972477\n",
      "EPOCH=1882\n",
      "train: loss=0.08221467323349842 acc=0.963302752293578\n",
      "test: loss=0.2680957908739091 acc=0.9036697247706422\n",
      "EPOCH=1883\n",
      "train: loss=0.10941866063331393 acc=0.9587155963302753\n",
      "test: loss=0.276629018308885 acc=0.9197247706422018\n",
      "EPOCH=1884\n",
      "train: loss=0.1678258681524905 acc=0.9403669724770642\n",
      "test: loss=0.3475876534307141 acc=0.9128440366972477\n",
      "EPOCH=1885\n",
      "train: loss=0.11977542998865834 acc=0.9724770642201835\n",
      "test: loss=0.2962883355575274 acc=0.9105504587155964\n",
      "EPOCH=1886\n",
      "train: loss=0.16281378060061047 acc=0.9564220183486238\n",
      "test: loss=0.3323353139737374 acc=0.9151376146788991\n",
      "EPOCH=1887\n",
      "train: loss=0.29953405525793275 acc=0.9311926605504587\n",
      "test: loss=0.3314631259798164 acc=0.9151376146788991\n",
      "EPOCH=1888\n",
      "train: loss=0.17034580297725146 acc=0.9564220183486238\n",
      "test: loss=0.3039958994763159 acc=0.9036697247706422\n",
      "EPOCH=1889\n",
      "train: loss=0.06384516641798103 acc=0.9770642201834863\n",
      "test: loss=0.3566728739320083 acc=0.9036697247706422\n",
      "EPOCH=1890\n",
      "train: loss=0.2469977080184901 acc=0.9403669724770642\n",
      "test: loss=0.2303757977784436 acc=0.9334862385321101\n",
      "EPOCH=1891\n",
      "train: loss=0.15175393228711873 acc=0.9610091743119266\n",
      "test: loss=0.3817850637157736 acc=0.9105504587155964\n",
      "EPOCH=1892\n",
      "train: loss=0.20303180078232574 acc=0.9564220183486238\n",
      "test: loss=0.29690918540571937 acc=0.9151376146788991\n",
      "EPOCH=1893\n",
      "train: loss=0.1772247692565831 acc=0.944954128440367\n",
      "test: loss=0.33530750727891195 acc=0.8967889908256881\n",
      "EPOCH=1894\n",
      "train: loss=0.12937656364869057 acc=0.9587155963302753\n",
      "test: loss=0.29949521063034285 acc=0.9243119266055045\n",
      "EPOCH=1895\n",
      "train: loss=0.2082855948518062 acc=0.9311926605504587\n",
      "test: loss=0.2728702674750521 acc=0.9174311926605505\n",
      "EPOCH=1896\n",
      "train: loss=0.10317059402652687 acc=0.9747706422018348\n",
      "test: loss=0.2564972985125288 acc=0.9243119266055045\n",
      "EPOCH=1897\n",
      "train: loss=0.20154743595085559 acc=0.9564220183486238\n",
      "test: loss=0.23871975540869658 acc=0.9220183486238532\n",
      "EPOCH=1898\n",
      "train: loss=0.1343859237501227 acc=0.9518348623853211\n",
      "test: loss=0.2907180775026272 acc=0.9174311926605505\n",
      "EPOCH=1899\n",
      "train: loss=0.09456788460007545 acc=0.963302752293578\n",
      "test: loss=0.2995424286028681 acc=0.9151376146788991\n",
      "EPOCH=1900\n",
      "train: loss=0.23749135456675485 acc=0.9311926605504587\n",
      "test: loss=0.3777051632312752 acc=0.9059633027522935\n",
      "EPOCH=1901\n",
      "train: loss=0.1999035855185617 acc=0.9495412844036697\n",
      "test: loss=0.29181716619161835 acc=0.9243119266055045\n",
      "EPOCH=1902\n",
      "train: loss=0.10416509910352437 acc=0.9610091743119266\n",
      "test: loss=0.3051595580295949 acc=0.9151376146788991\n",
      "EPOCH=1903\n",
      "train: loss=0.1709670916924362 acc=0.9541284403669725\n",
      "test: loss=0.2352938796829892 acc=0.926605504587156\n",
      "EPOCH=1904\n",
      "train: loss=0.24024755462262348 acc=0.9311926605504587\n",
      "test: loss=0.32882168200000017 acc=0.9013761467889908\n",
      "EPOCH=1905\n",
      "train: loss=0.227580961467288 acc=0.9357798165137615\n",
      "test: loss=0.2954816187380725 acc=0.9059633027522935\n",
      "EPOCH=1906\n",
      "train: loss=0.22046571864033496 acc=0.9403669724770642\n",
      "test: loss=0.37663835411073243 acc=0.8967889908256881\n",
      "EPOCH=1907\n",
      "train: loss=0.2268574450839509 acc=0.9334862385321101\n",
      "test: loss=0.29398908351796665 acc=0.9220183486238532\n",
      "EPOCH=1908\n",
      "train: loss=0.21681806887368107 acc=0.9380733944954128\n",
      "test: loss=0.26277977139738684 acc=0.9174311926605505\n",
      "EPOCH=1909\n",
      "train: loss=0.24941240188472297 acc=0.9426605504587156\n",
      "test: loss=0.34900968757206957 acc=0.9059633027522935\n",
      "EPOCH=1910\n",
      "train: loss=0.17271897918093834 acc=0.9564220183486238\n",
      "test: loss=0.3813669135331696 acc=0.8990825688073395\n",
      "EPOCH=1911\n",
      "train: loss=0.15935788752386926 acc=0.9518348623853211\n",
      "test: loss=0.29367493748967244 acc=0.9151376146788991\n",
      "EPOCH=1912\n",
      "train: loss=0.22067663405947255 acc=0.9426605504587156\n",
      "test: loss=0.2783302198906805 acc=0.9243119266055045\n",
      "EPOCH=1913\n",
      "train: loss=0.13421356127998899 acc=0.9472477064220184\n",
      "test: loss=0.3254392885906858 acc=0.9243119266055045\n",
      "EPOCH=1914\n",
      "train: loss=0.05606701094853341 acc=0.981651376146789\n",
      "test: loss=0.23037541173981918 acc=0.926605504587156\n",
      "EPOCH=1915\n",
      "train: loss=0.15258863964274233 acc=0.9495412844036697\n",
      "test: loss=0.3051463551676793 acc=0.9013761467889908\n",
      "EPOCH=1916\n",
      "train: loss=0.10078683538524755 acc=0.963302752293578\n",
      "test: loss=0.30406739319616355 acc=0.9013761467889908\n",
      "EPOCH=1917\n",
      "train: loss=0.1658051667725036 acc=0.9610091743119266\n",
      "test: loss=0.2762044801435381 acc=0.926605504587156\n",
      "EPOCH=1918\n",
      "train: loss=0.20517828673761362 acc=0.9472477064220184\n",
      "test: loss=0.23811914082569455 acc=0.9151376146788991\n",
      "EPOCH=1919\n",
      "train: loss=0.196356709898013 acc=0.944954128440367\n",
      "test: loss=0.20493877512432104 acc=0.9311926605504587\n",
      "EPOCH=1920\n",
      "train: loss=0.12347508580457092 acc=0.9564220183486238\n",
      "test: loss=0.3634121489193517 acc=0.8922018348623854\n",
      "EPOCH=1921\n",
      "train: loss=0.1280453652098255 acc=0.9747706422018348\n",
      "test: loss=0.32182584675836984 acc=0.9128440366972477\n",
      "EPOCH=1922\n",
      "train: loss=0.22234028082153678 acc=0.9220183486238532\n",
      "test: loss=0.29827950495831196 acc=0.9059633027522935\n",
      "EPOCH=1923\n",
      "train: loss=0.060969960744445634 acc=0.9839449541284404\n",
      "test: loss=0.3224148841712251 acc=0.9128440366972477\n",
      "EPOCH=1924\n",
      "train: loss=0.17910307837938205 acc=0.944954128440367\n",
      "test: loss=0.3349913967654424 acc=0.9151376146788991\n",
      "EPOCH=1925\n",
      "train: loss=0.1791640294014192 acc=0.9403669724770642\n",
      "test: loss=0.24474264463959802 acc=0.9105504587155964\n",
      "EPOCH=1926\n",
      "train: loss=0.20644155412096435 acc=0.9357798165137615\n",
      "test: loss=0.3655508143834848 acc=0.9059633027522935\n",
      "EPOCH=1927\n",
      "train: loss=0.2705110013614251 acc=0.9288990825688074\n",
      "test: loss=0.2951215763930932 acc=0.9197247706422018\n",
      "EPOCH=1928\n",
      "train: loss=0.15255275949023206 acc=0.9541284403669725\n",
      "test: loss=0.31014069978453995 acc=0.908256880733945\n",
      "EPOCH=1929\n",
      "train: loss=0.05754971162974605 acc=0.9724770642201835\n",
      "test: loss=0.2362003347249219 acc=0.9357798165137615\n",
      "EPOCH=1930\n",
      "train: loss=0.1978972780087288 acc=0.9518348623853211\n",
      "test: loss=0.2507512684562063 acc=0.9174311926605505\n",
      "EPOCH=1931\n",
      "train: loss=0.18113022850320867 acc=0.9426605504587156\n",
      "test: loss=0.34232379755263515 acc=0.8990825688073395\n",
      "EPOCH=1932\n",
      "train: loss=0.1799557205100143 acc=0.9495412844036697\n",
      "test: loss=0.2837823850550854 acc=0.9220183486238532\n",
      "EPOCH=1933\n",
      "train: loss=0.1992813234330216 acc=0.9288990825688074\n",
      "test: loss=0.37965821817198075 acc=0.9059633027522935\n",
      "EPOCH=1934\n",
      "train: loss=0.1457823463521507 acc=0.9518348623853211\n",
      "test: loss=0.328884018176213 acc=0.908256880733945\n",
      "EPOCH=1935\n",
      "train: loss=0.10812056178403925 acc=0.9655963302752294\n",
      "test: loss=0.34954237863227405 acc=0.8967889908256881\n",
      "EPOCH=1936\n",
      "train: loss=0.11684377492086194 acc=0.9655963302752294\n",
      "test: loss=0.2442636911971535 acc=0.9151376146788991\n",
      "EPOCH=1937\n",
      "train: loss=0.11982256813974537 acc=0.9655963302752294\n",
      "test: loss=0.39428649899085105 acc=0.8876146788990825\n",
      "EPOCH=1938\n",
      "train: loss=0.11232379647771243 acc=0.9610091743119266\n",
      "test: loss=0.2892278642609991 acc=0.9151376146788991\n",
      "EPOCH=1939\n",
      "train: loss=0.08656837937493465 acc=0.9724770642201835\n",
      "test: loss=0.3264305729905428 acc=0.908256880733945\n",
      "EPOCH=1940\n",
      "train: loss=0.16963353463053113 acc=0.9380733944954128\n",
      "test: loss=0.3067654113867099 acc=0.9036697247706422\n",
      "EPOCH=1941\n",
      "train: loss=0.11644746625606123 acc=0.9701834862385321\n",
      "test: loss=0.36024735878876135 acc=0.9036697247706422\n",
      "EPOCH=1942\n",
      "train: loss=0.2365812838600289 acc=0.9334862385321101\n",
      "test: loss=0.32341457916965943 acc=0.9174311926605505\n",
      "EPOCH=1943\n",
      "train: loss=0.17716861975444073 acc=0.9311926605504587\n",
      "test: loss=0.2232237102497209 acc=0.9288990825688074\n",
      "EPOCH=1944\n",
      "train: loss=0.2661625000717848 acc=0.9334862385321101\n",
      "test: loss=0.33709107098003815 acc=0.9013761467889908\n",
      "EPOCH=1945\n",
      "train: loss=0.1481869109715619 acc=0.9587155963302753\n",
      "test: loss=0.32494654043921845 acc=0.9151376146788991\n",
      "EPOCH=1946\n",
      "train: loss=0.11660259388283926 acc=0.9564220183486238\n",
      "test: loss=0.2715617127486529 acc=0.9105504587155964\n",
      "EPOCH=1947\n",
      "train: loss=0.01171547619492918 acc=0.9977064220183486\n",
      "test: loss=0.34556994705361627 acc=0.9013761467889908\n",
      "EPOCH=1948\n",
      "train: loss=0.2034955962141265 acc=0.9334862385321101\n",
      "test: loss=0.32700544265321185 acc=0.8876146788990825\n",
      "EPOCH=1949\n",
      "train: loss=0.1286155831845957 acc=0.9610091743119266\n",
      "test: loss=0.27004521946032517 acc=0.9288990825688074\n",
      "EPOCH=1950\n",
      "train: loss=0.14598322415558934 acc=0.9541284403669725\n",
      "test: loss=0.3320839278669584 acc=0.9013761467889908\n",
      "EPOCH=1951\n",
      "train: loss=0.08376539695803156 acc=0.9724770642201835\n",
      "test: loss=0.2576497481356857 acc=0.926605504587156\n",
      "EPOCH=1952\n",
      "train: loss=0.21547222624455145 acc=0.9288990825688074\n",
      "test: loss=0.2807410432579824 acc=0.9243119266055045\n",
      "EPOCH=1953\n",
      "train: loss=0.22294044487878326 acc=0.9311926605504587\n",
      "test: loss=0.25079343292334316 acc=0.926605504587156\n",
      "EPOCH=1954\n",
      "train: loss=0.1273861264472466 acc=0.9587155963302753\n",
      "test: loss=0.3579172729598528 acc=0.9059633027522935\n",
      "EPOCH=1955\n",
      "train: loss=0.1646949189871838 acc=0.944954128440367\n",
      "test: loss=0.34214074985034426 acc=0.9013761467889908\n",
      "EPOCH=1956\n",
      "train: loss=0.1789686378587139 acc=0.9541284403669725\n",
      "test: loss=0.25208337372533846 acc=0.9151376146788991\n",
      "EPOCH=1957\n",
      "train: loss=0.16037938617822606 acc=0.9403669724770642\n",
      "test: loss=0.2560719460886165 acc=0.926605504587156\n",
      "EPOCH=1958\n",
      "train: loss=0.22914219475732867 acc=0.9220183486238532\n",
      "test: loss=0.22271343337365665 acc=0.9174311926605505\n",
      "EPOCH=1959\n",
      "train: loss=0.15929186926840896 acc=0.9587155963302753\n",
      "test: loss=0.26640891396268307 acc=0.9311926605504587\n",
      "EPOCH=1960\n",
      "train: loss=0.063048340250965 acc=0.9862385321100917\n",
      "test: loss=0.25259590651563013 acc=0.9197247706422018\n",
      "EPOCH=1961\n",
      "train: loss=0.14243252092933034 acc=0.9564220183486238\n",
      "test: loss=0.34536491884895415 acc=0.9174311926605505\n",
      "EPOCH=1962\n",
      "train: loss=0.1559832450783956 acc=0.9587155963302753\n",
      "test: loss=0.28148153304497203 acc=0.9151376146788991\n",
      "EPOCH=1963\n",
      "train: loss=0.15831502718736137 acc=0.9472477064220184\n",
      "test: loss=0.31275365795203003 acc=0.9013761467889908\n",
      "EPOCH=1964\n",
      "train: loss=0.2128615212797877 acc=0.9426605504587156\n",
      "test: loss=0.3383362394588249 acc=0.8967889908256881\n",
      "EPOCH=1965\n",
      "train: loss=0.0734336462533687 acc=0.9793577981651376\n",
      "test: loss=0.3473257487320351 acc=0.9128440366972477\n",
      "EPOCH=1966\n",
      "train: loss=0.21681153398633737 acc=0.9426605504587156\n",
      "test: loss=0.3288510023780312 acc=0.9174311926605505\n",
      "EPOCH=1967\n",
      "train: loss=0.2249443821558916 acc=0.9357798165137615\n",
      "test: loss=0.3154434835198943 acc=0.9013761467889908\n",
      "EPOCH=1968\n",
      "train: loss=0.14984758434861054 acc=0.9587155963302753\n",
      "test: loss=0.263527929001554 acc=0.9174311926605505\n",
      "EPOCH=1969\n",
      "train: loss=0.06854587440843056 acc=0.9701834862385321\n",
      "test: loss=0.2624837017992922 acc=0.9288990825688074\n",
      "EPOCH=1970\n",
      "train: loss=0.21358501765328325 acc=0.9495412844036697\n",
      "test: loss=0.21147896122099002 acc=0.9174311926605505\n",
      "EPOCH=1971\n",
      "train: loss=0.1449925718538687 acc=0.9495412844036697\n",
      "test: loss=0.32437165781962274 acc=0.908256880733945\n",
      "EPOCH=1972\n",
      "train: loss=0.054339900008207244 acc=0.9839449541284404\n",
      "test: loss=0.31093281277256046 acc=0.9174311926605505\n",
      "EPOCH=1973\n",
      "train: loss=0.18693223480557658 acc=0.944954128440367\n",
      "test: loss=0.3161823074930655 acc=0.9059633027522935\n",
      "EPOCH=1974\n",
      "train: loss=0.054177847951980114 acc=0.9770642201834863\n",
      "test: loss=0.28387805247799414 acc=0.908256880733945\n",
      "EPOCH=1975\n",
      "train: loss=0.060761902194038375 acc=0.9747706422018348\n",
      "test: loss=0.27661330286976127 acc=0.9243119266055045\n",
      "EPOCH=1976\n",
      "train: loss=0.1848182051873397 acc=0.9472477064220184\n",
      "test: loss=0.3164390600644672 acc=0.9128440366972477\n",
      "EPOCH=1977\n",
      "train: loss=0.08109767619340749 acc=0.9655963302752294\n",
      "test: loss=0.30501866208275147 acc=0.9128440366972477\n",
      "EPOCH=1978\n",
      "train: loss=0.1636046633732232 acc=0.9518348623853211\n",
      "test: loss=0.25643843078976614 acc=0.9151376146788991\n",
      "EPOCH=1979\n",
      "train: loss=0.22898576454600192 acc=0.9288990825688074\n",
      "test: loss=0.2508188633535971 acc=0.9220183486238532\n",
      "EPOCH=1980\n",
      "train: loss=0.20718547920462305 acc=0.9403669724770642\n",
      "test: loss=0.34126698142821427 acc=0.8967889908256881\n",
      "EPOCH=1981\n",
      "train: loss=0.15889760038898673 acc=0.9587155963302753\n",
      "test: loss=0.2716701842254035 acc=0.908256880733945\n",
      "EPOCH=1982\n",
      "train: loss=0.1838552125415131 acc=0.944954128440367\n",
      "test: loss=0.2911156599862926 acc=0.9197247706422018\n",
      "EPOCH=1983\n",
      "train: loss=0.07477880775299471 acc=0.9793577981651376\n",
      "test: loss=0.340649790245204 acc=0.9105504587155964\n",
      "EPOCH=1984\n",
      "train: loss=0.1674342183849795 acc=0.9610091743119266\n",
      "test: loss=0.30523134189857126 acc=0.9059633027522935\n",
      "EPOCH=1985\n",
      "train: loss=0.35384913862495937 acc=0.9013761467889908\n",
      "test: loss=0.26760349030915687 acc=0.9128440366972477\n",
      "EPOCH=1986\n",
      "train: loss=0.057382644383316986 acc=0.9724770642201835\n",
      "test: loss=0.2883800534510669 acc=0.9220183486238532\n",
      "EPOCH=1987\n",
      "train: loss=0.1823572092156323 acc=0.9587155963302753\n",
      "test: loss=0.343813050909625 acc=0.9059633027522935\n",
      "EPOCH=1988\n",
      "train: loss=0.13926333243183497 acc=0.9655963302752294\n",
      "test: loss=0.31277956934835943 acc=0.908256880733945\n",
      "EPOCH=1989\n",
      "train: loss=0.1343318164243717 acc=0.963302752293578\n",
      "test: loss=0.25943203449833174 acc=0.9311926605504587\n",
      "EPOCH=1990\n",
      "train: loss=0.13802600079770233 acc=0.9587155963302753\n",
      "test: loss=0.3113365932168897 acc=0.8944954128440367\n",
      "EPOCH=1991\n",
      "train: loss=0.22480551546049105 acc=0.9403669724770642\n",
      "test: loss=0.38191139540209734 acc=0.9105504587155964\n",
      "EPOCH=1992\n",
      "train: loss=0.15362704539336874 acc=0.9380733944954128\n",
      "test: loss=0.3095493996590322 acc=0.9174311926605505\n",
      "EPOCH=1993\n",
      "train: loss=0.2510127948680196 acc=0.9243119266055045\n",
      "test: loss=0.25649313231347415 acc=0.9243119266055045\n",
      "EPOCH=1994\n",
      "train: loss=0.2283275216040178 acc=0.9426605504587156\n",
      "test: loss=0.2931966581880834 acc=0.9151376146788991\n",
      "EPOCH=1995\n",
      "train: loss=0.22943643276609918 acc=0.9357798165137615\n",
      "test: loss=0.2934289725345449 acc=0.9128440366972477\n",
      "EPOCH=1996\n",
      "train: loss=0.38017397232490424 acc=0.8967889908256881\n",
      "test: loss=0.37259610860967585 acc=0.9151376146788991\n",
      "EPOCH=1997\n",
      "train: loss=0.11157796874140916 acc=0.963302752293578\n",
      "test: loss=0.3450191693729563 acc=0.9151376146788991\n",
      "EPOCH=1998\n",
      "train: loss=0.12173294462732032 acc=0.9495412844036697\n",
      "test: loss=0.2956899346074022 acc=0.9059633027522935\n",
      "EPOCH=1999\n",
      "train: loss=0.26821866299168146 acc=0.9220183486238532\n",
      "test: loss=0.35721544029269464 acc=0.8967889908256881\n",
      "EPOCH=2000\n",
      "train: loss=0.15717646824979628 acc=0.963302752293578\n",
      "test: loss=0.24306858032731982 acc=0.9288990825688074\n",
      "EPOCH=2001\n",
      "train: loss=0.25740091321776254 acc=0.9403669724770642\n",
      "test: loss=0.2520132540847736 acc=0.9288990825688074\n",
      "EPOCH=2002\n",
      "train: loss=0.19921804451229327 acc=0.9495412844036697\n",
      "test: loss=0.2546500901251863 acc=0.9243119266055045\n",
      "EPOCH=2003\n",
      "train: loss=0.1772659656010413 acc=0.9380733944954128\n",
      "test: loss=0.3052095894091178 acc=0.9197247706422018\n",
      "EPOCH=2004\n",
      "train: loss=0.21824255879258703 acc=0.9311926605504587\n",
      "test: loss=0.26027381118643667 acc=0.9243119266055045\n",
      "EPOCH=2005\n",
      "train: loss=0.09807970150741493 acc=0.9724770642201835\n",
      "test: loss=0.21193086004050496 acc=0.9334862385321101\n",
      "EPOCH=2006\n",
      "train: loss=0.20790770666605857 acc=0.9403669724770642\n",
      "test: loss=0.31343406072169333 acc=0.9105504587155964\n",
      "EPOCH=2007\n",
      "train: loss=0.17957998088286253 acc=0.9518348623853211\n",
      "test: loss=0.2919080089936386 acc=0.9197247706422018\n",
      "EPOCH=2008\n",
      "train: loss=0.18360831586079004 acc=0.9403669724770642\n",
      "test: loss=0.2815836378529059 acc=0.9105504587155964\n",
      "EPOCH=2009\n",
      "train: loss=0.17972880524958373 acc=0.9380733944954128\n",
      "test: loss=0.223765282984089 acc=0.9288990825688074\n",
      "EPOCH=2010\n",
      "train: loss=0.1712266134833597 acc=0.944954128440367\n",
      "test: loss=0.3405827932458376 acc=0.908256880733945\n",
      "EPOCH=2011\n",
      "train: loss=0.138836086961322 acc=0.9518348623853211\n",
      "test: loss=0.2540813782728006 acc=0.9105504587155964\n",
      "EPOCH=2012\n",
      "train: loss=0.2590252804663348 acc=0.9288990825688074\n",
      "test: loss=0.28286841643298954 acc=0.9105504587155964\n",
      "EPOCH=2013\n",
      "train: loss=0.11408658517846536 acc=0.963302752293578\n",
      "test: loss=0.2977084841111794 acc=0.9128440366972477\n",
      "EPOCH=2014\n",
      "train: loss=0.20113187314580197 acc=0.9197247706422018\n",
      "test: loss=0.24177213290743627 acc=0.9243119266055045\n",
      "EPOCH=2015\n",
      "train: loss=0.14441948201716814 acc=0.944954128440367\n",
      "test: loss=0.30611669129472646 acc=0.9128440366972477\n",
      "EPOCH=2016\n",
      "train: loss=0.1647214963680656 acc=0.9403669724770642\n",
      "test: loss=0.2867684359283195 acc=0.9220183486238532\n",
      "EPOCH=2017\n",
      "train: loss=0.2684764789976795 acc=0.9357798165137615\n",
      "test: loss=0.2529620190436867 acc=0.9151376146788991\n",
      "EPOCH=2018\n",
      "train: loss=0.052402171108757445 acc=0.9793577981651376\n",
      "test: loss=0.180351711023836 acc=0.9311926605504587\n",
      "EPOCH=2019\n",
      "train: loss=0.3176501378118047 acc=0.9105504587155964\n",
      "test: loss=0.2598512796885319 acc=0.9174311926605505\n",
      "EPOCH=2020\n",
      "train: loss=0.2272062260240506 acc=0.9357798165137615\n",
      "test: loss=0.2642400306615947 acc=0.9105504587155964\n",
      "EPOCH=2021\n",
      "train: loss=0.18595433972803496 acc=0.9495412844036697\n",
      "test: loss=0.2619306208542359 acc=0.926605504587156\n",
      "EPOCH=2022\n",
      "train: loss=0.13961327111341842 acc=0.9495412844036697\n",
      "test: loss=0.2871089363071112 acc=0.9174311926605505\n",
      "EPOCH=2023\n",
      "train: loss=0.32827698475251016 acc=0.908256880733945\n",
      "test: loss=0.3421622885186104 acc=0.8990825688073395\n",
      "EPOCH=2024\n",
      "train: loss=0.22096855187382927 acc=0.926605504587156\n",
      "test: loss=0.2791604117797392 acc=0.9128440366972477\n",
      "EPOCH=2025\n",
      "train: loss=0.2713020168286012 acc=0.9288990825688074\n",
      "test: loss=0.3020102057412599 acc=0.9036697247706422\n",
      "EPOCH=2026\n",
      "train: loss=0.2146307613927094 acc=0.9518348623853211\n",
      "test: loss=0.3107961154368084 acc=0.9151376146788991\n",
      "EPOCH=2027\n",
      "train: loss=0.3623558426640131 acc=0.9036697247706422\n",
      "test: loss=0.27121782382961535 acc=0.9151376146788991\n",
      "EPOCH=2028\n",
      "train: loss=0.11168031329129066 acc=0.9610091743119266\n",
      "test: loss=0.22264095976013254 acc=0.9380733944954128\n",
      "EPOCH=2029\n",
      "train: loss=0.1433020693759392 acc=0.9587155963302753\n",
      "test: loss=0.2905779188253212 acc=0.9174311926605505\n",
      "EPOCH=2030\n",
      "train: loss=0.1657931023090111 acc=0.9403669724770642\n",
      "test: loss=0.24598426456244266 acc=0.9151376146788991\n",
      "EPOCH=2031\n",
      "train: loss=0.2579812844084968 acc=0.9357798165137615\n",
      "test: loss=0.3193267255258804 acc=0.9013761467889908\n",
      "EPOCH=2032\n",
      "train: loss=0.15611721889507635 acc=0.9472477064220184\n",
      "test: loss=0.33353452476169926 acc=0.8967889908256881\n",
      "EPOCH=2033\n",
      "train: loss=0.13053048856486496 acc=0.963302752293578\n",
      "test: loss=0.32615573153928185 acc=0.9036697247706422\n",
      "EPOCH=2034\n",
      "train: loss=0.14449791055340216 acc=0.944954128440367\n",
      "test: loss=0.23819267484007683 acc=0.9151376146788991\n",
      "EPOCH=2035\n",
      "train: loss=0.17547436848550102 acc=0.944954128440367\n",
      "test: loss=0.23697851127918287 acc=0.908256880733945\n",
      "EPOCH=2036\n",
      "train: loss=0.13850432783880606 acc=0.9564220183486238\n",
      "test: loss=0.30644241043878845 acc=0.908256880733945\n",
      "EPOCH=2037\n",
      "train: loss=0.3861075786750698 acc=0.8990825688073395\n",
      "test: loss=0.2452014187440124 acc=0.9174311926605505\n",
      "EPOCH=2038\n",
      "train: loss=0.24058665759697292 acc=0.9472477064220184\n",
      "test: loss=0.27178295559471893 acc=0.9059633027522935\n",
      "EPOCH=2039\n",
      "train: loss=0.1448167335072345 acc=0.9472477064220184\n",
      "test: loss=0.3441638869747457 acc=0.9036697247706422\n",
      "EPOCH=2040\n",
      "train: loss=0.10716832988441335 acc=0.9495412844036697\n",
      "test: loss=0.32549833032325254 acc=0.908256880733945\n",
      "EPOCH=2041\n",
      "train: loss=0.17484367364372727 acc=0.9380733944954128\n",
      "test: loss=0.2783467801675495 acc=0.9197247706422018\n",
      "EPOCH=2042\n",
      "train: loss=0.05072842483191299 acc=0.9793577981651376\n",
      "test: loss=0.33715384242246704 acc=0.9059633027522935\n",
      "EPOCH=2043\n",
      "train: loss=0.1106769952733808 acc=0.9564220183486238\n",
      "test: loss=0.35862372250368973 acc=0.9013761467889908\n",
      "EPOCH=2044\n",
      "train: loss=0.20706608466894558 acc=0.9518348623853211\n",
      "test: loss=0.20958721293426383 acc=0.9288990825688074\n",
      "EPOCH=2045\n",
      "train: loss=0.07273653980385396 acc=0.9678899082568807\n",
      "test: loss=0.2653866520776676 acc=0.926605504587156\n",
      "EPOCH=2046\n",
      "train: loss=0.08327436383363031 acc=0.9610091743119266\n",
      "test: loss=0.2851115059539316 acc=0.9059633027522935\n",
      "EPOCH=2047\n",
      "train: loss=0.0650194555850573 acc=0.981651376146789\n",
      "test: loss=0.28708942435852125 acc=0.9105504587155964\n",
      "EPOCH=2048\n",
      "train: loss=0.05763976042160075 acc=0.9770642201834863\n",
      "test: loss=0.252961714104627 acc=0.9174311926605505\n",
      "EPOCH=2049\n",
      "train: loss=0.179286356501693 acc=0.9472477064220184\n",
      "test: loss=0.24743698454521207 acc=0.9197247706422018\n",
      "EPOCH=2050\n",
      "train: loss=0.36476447444524124 acc=0.8876146788990825\n",
      "test: loss=0.29340493665066514 acc=0.9174311926605505\n",
      "EPOCH=2051\n",
      "train: loss=0.04912715782703165 acc=0.9747706422018348\n",
      "test: loss=0.2763719621749017 acc=0.908256880733945\n",
      "EPOCH=2052\n",
      "train: loss=0.17792625659976177 acc=0.9472477064220184\n",
      "test: loss=0.26257343214213735 acc=0.926605504587156\n",
      "EPOCH=2053\n",
      "train: loss=0.11670517785911162 acc=0.9655963302752294\n",
      "test: loss=0.3532337337541979 acc=0.9013761467889908\n",
      "EPOCH=2054\n",
      "train: loss=0.11063969285671918 acc=0.963302752293578\n",
      "test: loss=0.3236632878749321 acc=0.9151376146788991\n",
      "EPOCH=2055\n",
      "train: loss=0.07385936070940993 acc=0.981651376146789\n",
      "test: loss=0.26836829200540063 acc=0.9174311926605505\n",
      "EPOCH=2056\n",
      "train: loss=0.16391633727294178 acc=0.9587155963302753\n",
      "test: loss=0.34004095545086166 acc=0.8990825688073395\n",
      "EPOCH=2057\n",
      "train: loss=0.1453674153826752 acc=0.9541284403669725\n",
      "test: loss=0.2678180715529196 acc=0.9334862385321101\n",
      "EPOCH=2058\n",
      "train: loss=0.13221126780031095 acc=0.9518348623853211\n",
      "test: loss=0.33572717417621556 acc=0.9105504587155964\n",
      "EPOCH=2059\n",
      "train: loss=0.1514204443487483 acc=0.9518348623853211\n",
      "test: loss=0.2406912557100239 acc=0.926605504587156\n",
      "EPOCH=2060\n",
      "train: loss=0.12692728536001918 acc=0.9610091743119266\n",
      "test: loss=0.2737841623090692 acc=0.9059633027522935\n",
      "EPOCH=2061\n",
      "train: loss=0.14234005233277622 acc=0.9541284403669725\n",
      "test: loss=0.2242440365947426 acc=0.926605504587156\n",
      "EPOCH=2062\n",
      "train: loss=0.23626250061755946 acc=0.9311926605504587\n",
      "test: loss=0.2864564517357712 acc=0.9220183486238532\n",
      "EPOCH=2063\n",
      "train: loss=0.14862815925185735 acc=0.9541284403669725\n",
      "test: loss=0.2902764097051993 acc=0.9036697247706422\n",
      "EPOCH=2064\n",
      "train: loss=0.1916654878684202 acc=0.9426605504587156\n",
      "test: loss=0.37347784382018656 acc=0.8967889908256881\n",
      "EPOCH=2065\n",
      "train: loss=0.1527793775252267 acc=0.9587155963302753\n",
      "test: loss=0.3254274609382597 acc=0.908256880733945\n",
      "EPOCH=2066\n",
      "train: loss=0.21210544601778963 acc=0.9403669724770642\n",
      "test: loss=0.22244971655040013 acc=0.9243119266055045\n",
      "EPOCH=2067\n",
      "train: loss=0.20242231677683642 acc=0.9564220183486238\n",
      "test: loss=0.3034924994571434 acc=0.908256880733945\n",
      "EPOCH=2068\n",
      "train: loss=0.2391797321042454 acc=0.926605504587156\n",
      "test: loss=0.3146982351834372 acc=0.9128440366972477\n",
      "EPOCH=2069\n",
      "train: loss=0.14481413360304865 acc=0.9564220183486238\n",
      "test: loss=0.25450987248468454 acc=0.9288990825688074\n",
      "EPOCH=2070\n",
      "train: loss=0.1561262710127117 acc=0.9655963302752294\n",
      "test: loss=0.32279570481565 acc=0.9036697247706422\n",
      "EPOCH=2071\n",
      "train: loss=0.16744796671790776 acc=0.9564220183486238\n",
      "test: loss=0.2882518496540564 acc=0.9128440366972477\n",
      "EPOCH=2072\n",
      "train: loss=0.3902148577788793 acc=0.8853211009174312\n",
      "test: loss=0.3985802710211389 acc=0.9059633027522935\n",
      "EPOCH=2073\n",
      "train: loss=0.10839031423178601 acc=0.9655963302752294\n",
      "test: loss=0.3498534089658018 acc=0.9013761467889908\n",
      "EPOCH=2074\n",
      "train: loss=0.14704855170767758 acc=0.944954128440367\n",
      "test: loss=0.3313914419777768 acc=0.908256880733945\n",
      "EPOCH=2075\n",
      "train: loss=0.280770453621472 acc=0.9220183486238532\n",
      "test: loss=0.36341404859454074 acc=0.8876146788990825\n",
      "EPOCH=2076\n",
      "train: loss=0.05025130209630437 acc=0.9862385321100917\n",
      "test: loss=0.21738339341787782 acc=0.926605504587156\n",
      "EPOCH=2077\n",
      "train: loss=0.06992223203688394 acc=0.9747706422018348\n",
      "test: loss=0.34321388056430363 acc=0.9059633027522935\n",
      "EPOCH=2078\n",
      "train: loss=0.1677068096154709 acc=0.9495412844036697\n",
      "test: loss=0.21058177458526442 acc=0.9403669724770642\n",
      "EPOCH=2079\n",
      "train: loss=0.11702686646229582 acc=0.963302752293578\n",
      "test: loss=0.2984235199863798 acc=0.9128440366972477\n",
      "EPOCH=2080\n",
      "train: loss=0.08117666484962498 acc=0.9724770642201835\n",
      "test: loss=0.28025854250347343 acc=0.9220183486238532\n",
      "EPOCH=2081\n",
      "train: loss=0.1709047606343618 acc=0.9472477064220184\n",
      "test: loss=0.2960005362699258 acc=0.9128440366972477\n",
      "EPOCH=2082\n",
      "train: loss=0.15539429831985113 acc=0.9518348623853211\n",
      "test: loss=0.25067920378316483 acc=0.9311926605504587\n",
      "EPOCH=2083\n",
      "train: loss=0.1594007634956947 acc=0.9541284403669725\n",
      "test: loss=0.3297410010732478 acc=0.908256880733945\n",
      "EPOCH=2084\n",
      "train: loss=0.07903405988316392 acc=0.9770642201834863\n",
      "test: loss=0.3158014217341814 acc=0.9151376146788991\n",
      "EPOCH=2085\n",
      "train: loss=0.20533505533952798 acc=0.9357798165137615\n",
      "test: loss=0.3098716168203757 acc=0.9036697247706422\n",
      "EPOCH=2086\n",
      "train: loss=0.07060892226455794 acc=0.9678899082568807\n",
      "test: loss=0.2485980970915067 acc=0.9220183486238532\n",
      "EPOCH=2087\n",
      "train: loss=0.12163411116279578 acc=0.9587155963302753\n",
      "test: loss=0.3370705273605732 acc=0.8990825688073395\n",
      "EPOCH=2088\n",
      "train: loss=0.1539857969949595 acc=0.9518348623853211\n",
      "test: loss=0.30400091631429405 acc=0.9128440366972477\n",
      "EPOCH=2089\n",
      "train: loss=0.20446804278196998 acc=0.9380733944954128\n",
      "test: loss=0.2308807354963787 acc=0.9220183486238532\n",
      "EPOCH=2090\n",
      "train: loss=0.10764793044135189 acc=0.9724770642201835\n",
      "test: loss=0.29290739055456627 acc=0.9174311926605505\n",
      "EPOCH=2091\n",
      "train: loss=0.07893994981748305 acc=0.9770642201834863\n",
      "test: loss=0.2562881438530796 acc=0.9220183486238532\n",
      "EPOCH=2092\n",
      "train: loss=0.13930824555724428 acc=0.9655963302752294\n",
      "test: loss=0.26496406659347727 acc=0.9220183486238532\n",
      "EPOCH=2093\n",
      "train: loss=0.20764738631938373 acc=0.9357798165137615\n",
      "test: loss=0.3304132722648955 acc=0.8990825688073395\n",
      "EPOCH=2094\n",
      "train: loss=0.09589683823337579 acc=0.9701834862385321\n",
      "test: loss=0.3392571842525875 acc=0.908256880733945\n",
      "EPOCH=2095\n",
      "train: loss=0.14322115293101786 acc=0.944954128440367\n",
      "test: loss=0.2580469001517442 acc=0.9220183486238532\n",
      "EPOCH=2096\n",
      "train: loss=0.14639935869916618 acc=0.9541284403669725\n",
      "test: loss=0.28747802252270416 acc=0.9151376146788991\n",
      "EPOCH=2097\n",
      "train: loss=0.06823751854444858 acc=0.9724770642201835\n",
      "test: loss=0.2705435941680265 acc=0.9174311926605505\n",
      "EPOCH=2098\n",
      "train: loss=0.08530213954741471 acc=0.963302752293578\n",
      "test: loss=0.28036915268735757 acc=0.9197247706422018\n",
      "EPOCH=2099\n",
      "train: loss=0.13465555524315104 acc=0.963302752293578\n",
      "test: loss=0.2151960793620736 acc=0.9220183486238532\n",
      "EPOCH=2100\n",
      "train: loss=0.10724202110209188 acc=0.9655963302752294\n",
      "test: loss=0.2837275034898046 acc=0.9151376146788991\n",
      "EPOCH=2101\n",
      "train: loss=0.026720908631462478 acc=0.9908256880733946\n",
      "test: loss=0.2942245216194942 acc=0.9243119266055045\n",
      "EPOCH=2102\n",
      "train: loss=0.12919554703549177 acc=0.9564220183486238\n",
      "test: loss=0.2531539162274846 acc=0.9197247706422018\n",
      "EPOCH=2103\n",
      "train: loss=0.1267317356748405 acc=0.9564220183486238\n",
      "test: loss=0.2831652785603862 acc=0.9220183486238532\n",
      "EPOCH=2104\n",
      "train: loss=0.1823424941217142 acc=0.9564220183486238\n",
      "test: loss=0.25263717322216633 acc=0.926605504587156\n",
      "EPOCH=2105\n",
      "train: loss=0.22947824646945394 acc=0.9357798165137615\n",
      "test: loss=0.3761638663981807 acc=0.8899082568807339\n",
      "EPOCH=2106\n",
      "train: loss=0.14271987781982937 acc=0.9403669724770642\n",
      "test: loss=0.22032263393964843 acc=0.926605504587156\n",
      "EPOCH=2107\n",
      "train: loss=0.08212343419006285 acc=0.9770642201834863\n",
      "test: loss=0.2890333488388215 acc=0.9174311926605505\n",
      "EPOCH=2108\n",
      "train: loss=0.18379983383505155 acc=0.9495412844036697\n",
      "test: loss=0.2922015521543697 acc=0.9174311926605505\n",
      "EPOCH=2109\n",
      "train: loss=0.28667178877716515 acc=0.9151376146788991\n",
      "test: loss=0.25562567896094446 acc=0.9220183486238532\n",
      "EPOCH=2110\n",
      "train: loss=0.18812722032341567 acc=0.9403669724770642\n",
      "test: loss=0.3186459097883851 acc=0.8990825688073395\n",
      "EPOCH=2111\n",
      "train: loss=0.18484156620457942 acc=0.9495412844036697\n",
      "test: loss=0.2641551219460023 acc=0.9174311926605505\n",
      "EPOCH=2112\n",
      "train: loss=0.2430127553402908 acc=0.9311926605504587\n",
      "test: loss=0.24268706470548984 acc=0.9197247706422018\n",
      "EPOCH=2113\n",
      "train: loss=0.2694746968555716 acc=0.9380733944954128\n",
      "test: loss=0.317308650015645 acc=0.908256880733945\n",
      "EPOCH=2114\n",
      "train: loss=0.10141486497239047 acc=0.9655963302752294\n",
      "test: loss=0.23856414928611272 acc=0.9311926605504587\n",
      "EPOCH=2115\n",
      "train: loss=0.23441098150602352 acc=0.9426605504587156\n",
      "test: loss=0.21060339779670967 acc=0.9243119266055045\n",
      "EPOCH=2116\n",
      "train: loss=0.14722008664511987 acc=0.9518348623853211\n",
      "test: loss=0.265280541946706 acc=0.9151376146788991\n",
      "EPOCH=2117\n",
      "train: loss=0.11329446941684848 acc=0.9655963302752294\n",
      "test: loss=0.18104658426214656 acc=0.9380733944954128\n",
      "EPOCH=2118\n",
      "train: loss=0.24002289623255535 acc=0.9426605504587156\n",
      "test: loss=0.31145002860078064 acc=0.8944954128440367\n",
      "EPOCH=2119\n",
      "train: loss=0.3107928821234087 acc=0.8967889908256881\n",
      "test: loss=0.25250165110860195 acc=0.9197247706422018\n",
      "EPOCH=2120\n",
      "train: loss=0.12615148517552446 acc=0.9770642201834863\n",
      "test: loss=0.24861340939217938 acc=0.9220183486238532\n",
      "EPOCH=2121\n",
      "train: loss=0.08694421718925838 acc=0.9655963302752294\n",
      "test: loss=0.27763685570600405 acc=0.9174311926605505\n",
      "EPOCH=2122\n",
      "train: loss=0.09249139195813699 acc=0.9747706422018348\n",
      "test: loss=0.28283788207372823 acc=0.9059633027522935\n",
      "EPOCH=2123\n",
      "train: loss=0.2446838562044769 acc=0.9334862385321101\n",
      "test: loss=0.2871410246196508 acc=0.9036697247706422\n",
      "EPOCH=2124\n",
      "train: loss=0.13133866492527757 acc=0.9495412844036697\n",
      "test: loss=0.3454024016096814 acc=0.9128440366972477\n",
      "EPOCH=2125\n",
      "train: loss=0.10959369099755502 acc=0.9564220183486238\n",
      "test: loss=0.3070407140447652 acc=0.9105504587155964\n",
      "EPOCH=2126\n",
      "train: loss=0.19559284475396518 acc=0.9495412844036697\n",
      "test: loss=0.2559877765430078 acc=0.9311926605504587\n",
      "EPOCH=2127\n",
      "train: loss=0.31508853671323545 acc=0.926605504587156\n",
      "test: loss=0.2907649405704012 acc=0.9174311926605505\n",
      "EPOCH=2128\n",
      "train: loss=0.10450221945420067 acc=0.9724770642201835\n",
      "test: loss=0.2600260632766245 acc=0.926605504587156\n",
      "EPOCH=2129\n",
      "train: loss=0.14591481399305156 acc=0.944954128440367\n",
      "test: loss=0.29932742670452506 acc=0.9288990825688074\n",
      "EPOCH=2130\n",
      "train: loss=0.0728726419108528 acc=0.963302752293578\n",
      "test: loss=0.33398922525005337 acc=0.9151376146788991\n",
      "EPOCH=2131\n",
      "train: loss=0.10486604996490344 acc=0.9587155963302753\n",
      "test: loss=0.24739759399241973 acc=0.9174311926605505\n",
      "EPOCH=2132\n",
      "train: loss=0.2361671713608415 acc=0.9380733944954128\n",
      "test: loss=0.2944967771162051 acc=0.908256880733945\n",
      "EPOCH=2133\n",
      "train: loss=0.17223829073598465 acc=0.9495412844036697\n",
      "test: loss=0.2909466542947507 acc=0.9174311926605505\n",
      "EPOCH=2134\n",
      "train: loss=0.19881479747279646 acc=0.9334862385321101\n",
      "test: loss=0.27381007508106153 acc=0.9243119266055045\n",
      "EPOCH=2135\n",
      "train: loss=0.22569745910025044 acc=0.9357798165137615\n",
      "test: loss=0.2742180370455879 acc=0.9288990825688074\n",
      "EPOCH=2136\n",
      "train: loss=0.23787586049016765 acc=0.9403669724770642\n",
      "test: loss=0.3026402208416028 acc=0.9174311926605505\n",
      "EPOCH=2137\n",
      "train: loss=0.2577445184958269 acc=0.9243119266055045\n",
      "test: loss=0.24518481309215495 acc=0.9197247706422018\n",
      "EPOCH=2138\n",
      "train: loss=0.15194793042540883 acc=0.9587155963302753\n",
      "test: loss=0.2743868096686518 acc=0.9151376146788991\n",
      "EPOCH=2139\n",
      "train: loss=0.2052298663928448 acc=0.9380733944954128\n",
      "test: loss=0.25998347728956633 acc=0.9105504587155964\n",
      "EPOCH=2140\n",
      "train: loss=0.15186285609768502 acc=0.9403669724770642\n",
      "test: loss=0.27871861738431436 acc=0.9174311926605505\n",
      "EPOCH=2141\n",
      "train: loss=0.15988036376830939 acc=0.9357798165137615\n",
      "test: loss=0.2210093176526966 acc=0.9220183486238532\n",
      "EPOCH=2142\n",
      "train: loss=0.0768329841258596 acc=0.9747706422018348\n",
      "test: loss=0.26214002067805364 acc=0.9288990825688074\n",
      "EPOCH=2143\n",
      "train: loss=0.14335619328007798 acc=0.9495412844036697\n",
      "test: loss=0.24230604875277298 acc=0.9220183486238532\n",
      "EPOCH=2144\n",
      "train: loss=0.170086594435817 acc=0.9541284403669725\n",
      "test: loss=0.2473385663882933 acc=0.9311926605504587\n",
      "EPOCH=2145\n",
      "train: loss=0.16128957608390349 acc=0.9495412844036697\n",
      "test: loss=0.22238682534539114 acc=0.926605504587156\n",
      "EPOCH=2146\n",
      "train: loss=0.3048738556550218 acc=0.9380733944954128\n",
      "test: loss=0.3147044582794374 acc=0.9128440366972477\n",
      "EPOCH=2147\n",
      "train: loss=0.23603974591226198 acc=0.9541284403669725\n",
      "test: loss=0.3213891481793218 acc=0.908256880733945\n",
      "EPOCH=2148\n",
      "train: loss=0.20494068063085275 acc=0.9403669724770642\n",
      "test: loss=0.2752896922292486 acc=0.9243119266055045\n",
      "EPOCH=2149\n",
      "train: loss=0.07751138707327708 acc=0.9655963302752294\n",
      "test: loss=0.32538288098437185 acc=0.9105504587155964\n",
      "EPOCH=2150\n",
      "train: loss=0.30576464739344444 acc=0.9059633027522935\n",
      "test: loss=0.3331962543950171 acc=0.8990825688073395\n",
      "EPOCH=2151\n",
      "train: loss=0.1716776734264693 acc=0.9426605504587156\n",
      "test: loss=0.31396244406060075 acc=0.9197247706422018\n",
      "EPOCH=2152\n",
      "train: loss=0.09510038690872158 acc=0.9747706422018348\n",
      "test: loss=0.310578284850833 acc=0.9197247706422018\n",
      "EPOCH=2153\n",
      "train: loss=0.1325264444160029 acc=0.9472477064220184\n",
      "test: loss=0.27998573986786246 acc=0.9197247706422018\n",
      "EPOCH=2154\n",
      "train: loss=0.20996439141282755 acc=0.9426605504587156\n",
      "test: loss=0.29670111612344346 acc=0.9105504587155964\n",
      "EPOCH=2155\n",
      "train: loss=0.20959171307674654 acc=0.9288990825688074\n",
      "test: loss=0.1898596599838187 acc=0.9243119266055045\n",
      "EPOCH=2156\n",
      "train: loss=0.23886788499168457 acc=0.926605504587156\n",
      "test: loss=0.26636296751619926 acc=0.8990825688073395\n",
      "EPOCH=2157\n",
      "train: loss=0.1880384893928398 acc=0.9495412844036697\n",
      "test: loss=0.3151942769431828 acc=0.9059633027522935\n",
      "EPOCH=2158\n",
      "train: loss=0.32854156572017407 acc=0.9036697247706422\n",
      "test: loss=0.34130009755118373 acc=0.9151376146788991\n",
      "EPOCH=2159\n",
      "train: loss=0.067678016379428 acc=0.9770642201834863\n",
      "test: loss=0.28877166818091543 acc=0.908256880733945\n",
      "EPOCH=2160\n",
      "train: loss=0.1644656927692611 acc=0.9403669724770642\n",
      "test: loss=0.30934876950194223 acc=0.9220183486238532\n",
      "EPOCH=2161\n",
      "train: loss=0.16299190480335873 acc=0.9334862385321101\n",
      "test: loss=0.23502120392775425 acc=0.9243119266055045\n",
      "EPOCH=2162\n",
      "train: loss=0.3440470531941678 acc=0.8967889908256881\n",
      "test: loss=0.33804466786544846 acc=0.9013761467889908\n",
      "EPOCH=2163\n",
      "train: loss=0.15601820319511397 acc=0.9564220183486238\n",
      "test: loss=0.27455905630407784 acc=0.908256880733945\n",
      "EPOCH=2164\n",
      "train: loss=0.1009123556896636 acc=0.9747706422018348\n",
      "test: loss=0.3331876087059902 acc=0.908256880733945\n",
      "EPOCH=2165\n",
      "train: loss=0.20163674649624833 acc=0.9403669724770642\n",
      "test: loss=0.2725575652908462 acc=0.9151376146788991\n",
      "EPOCH=2166\n",
      "train: loss=0.26863325016542916 acc=0.9243119266055045\n",
      "test: loss=0.3028161725510447 acc=0.908256880733945\n",
      "EPOCH=2167\n",
      "train: loss=0.16907180920308737 acc=0.9357798165137615\n",
      "test: loss=0.20694352756390508 acc=0.9426605504587156\n",
      "EPOCH=2168\n",
      "train: loss=0.2685612028785112 acc=0.9220183486238532\n",
      "test: loss=0.38158421943018433 acc=0.9036697247706422\n",
      "EPOCH=2169\n",
      "train: loss=0.22092891553616964 acc=0.9357798165137615\n",
      "test: loss=0.30862571663591987 acc=0.9128440366972477\n",
      "EPOCH=2170\n",
      "train: loss=0.2195317960233557 acc=0.9220183486238532\n",
      "test: loss=0.27449861909107737 acc=0.9174311926605505\n",
      "EPOCH=2171\n",
      "train: loss=0.19280632236883213 acc=0.9311926605504587\n",
      "test: loss=0.30010297301531424 acc=0.908256880733945\n",
      "EPOCH=2172\n",
      "train: loss=0.1587808258925753 acc=0.9518348623853211\n",
      "test: loss=0.27867564907836334 acc=0.9151376146788991\n",
      "EPOCH=2173\n",
      "train: loss=0.0747925282916333 acc=0.9770642201834863\n",
      "test: loss=0.39221717834652803 acc=0.8967889908256881\n",
      "EPOCH=2174\n",
      "train: loss=0.12465161917630446 acc=0.9564220183486238\n",
      "test: loss=0.26976184177352963 acc=0.908256880733945\n",
      "EPOCH=2175\n",
      "train: loss=0.27760048265139653 acc=0.9036697247706422\n",
      "test: loss=0.26375205270585816 acc=0.9220183486238532\n",
      "EPOCH=2176\n",
      "train: loss=0.14002702820210977 acc=0.9541284403669725\n",
      "test: loss=0.2965187970621995 acc=0.9220183486238532\n",
      "EPOCH=2177\n",
      "train: loss=0.23419869425580994 acc=0.9541284403669725\n",
      "test: loss=0.3087901520629398 acc=0.9128440366972477\n",
      "EPOCH=2178\n",
      "train: loss=0.1298124342383583 acc=0.963302752293578\n",
      "test: loss=0.21360216483472402 acc=0.9357798165137615\n",
      "EPOCH=2179\n",
      "train: loss=0.21020884095612802 acc=0.9403669724770642\n",
      "test: loss=0.3011911474027396 acc=0.908256880733945\n",
      "EPOCH=2180\n",
      "train: loss=0.12427689832738484 acc=0.9564220183486238\n",
      "test: loss=0.24407248242150273 acc=0.9036697247706422\n",
      "EPOCH=2181\n",
      "train: loss=0.15494277047342148 acc=0.9426605504587156\n",
      "test: loss=0.33590620246525216 acc=0.926605504587156\n",
      "EPOCH=2182\n",
      "train: loss=0.15117753523547992 acc=0.9518348623853211\n",
      "test: loss=0.1649822582234235 acc=0.9518348623853211\n",
      "EPOCH=2183\n",
      "train: loss=0.22609770476302352 acc=0.9426605504587156\n",
      "test: loss=0.2523837560730925 acc=0.9151376146788991\n",
      "EPOCH=2184\n",
      "train: loss=0.1988387258551958 acc=0.9472477064220184\n",
      "test: loss=0.1853929233841913 acc=0.9380733944954128\n",
      "EPOCH=2185\n",
      "train: loss=0.14809954988327895 acc=0.9564220183486238\n",
      "test: loss=0.26822178025285853 acc=0.9013761467889908\n",
      "EPOCH=2186\n",
      "train: loss=0.14866821050955425 acc=0.9541284403669725\n",
      "test: loss=0.3043685913332139 acc=0.9197247706422018\n",
      "EPOCH=2187\n",
      "train: loss=0.13169105624050928 acc=0.963302752293578\n",
      "test: loss=0.34771800893431604 acc=0.8990825688073395\n",
      "EPOCH=2188\n",
      "train: loss=0.047671786117140576 acc=0.9839449541284404\n",
      "test: loss=0.3258903930630287 acc=0.9036697247706422\n",
      "EPOCH=2189\n",
      "train: loss=0.11490480371932779 acc=0.9610091743119266\n",
      "test: loss=0.325337252017881 acc=0.908256880733945\n",
      "EPOCH=2190\n",
      "train: loss=0.08088135620461913 acc=0.9655963302752294\n",
      "test: loss=0.30979634860852723 acc=0.9013761467889908\n",
      "EPOCH=2191\n",
      "train: loss=0.30387232824268706 acc=0.9128440366972477\n",
      "test: loss=0.2318004124356531 acc=0.9334862385321101\n",
      "EPOCH=2192\n",
      "train: loss=0.1769295824531887 acc=0.9403669724770642\n",
      "test: loss=0.3793938722967571 acc=0.8990825688073395\n",
      "EPOCH=2193\n",
      "train: loss=0.16089863555249004 acc=0.9472477064220184\n",
      "test: loss=0.17559757631480813 acc=0.9495412844036697\n",
      "EPOCH=2194\n",
      "train: loss=0.14671890696165707 acc=0.9541284403669725\n",
      "test: loss=0.2329518768708564 acc=0.9220183486238532\n",
      "EPOCH=2195\n",
      "train: loss=0.09197583480435814 acc=0.9793577981651376\n",
      "test: loss=0.31899844670620975 acc=0.9036697247706422\n",
      "EPOCH=2196\n",
      "train: loss=0.13540218159393075 acc=0.9655963302752294\n",
      "test: loss=0.29545760229101264 acc=0.9174311926605505\n",
      "EPOCH=2197\n",
      "train: loss=0.1503718304283166 acc=0.944954128440367\n",
      "test: loss=0.2780250635605133 acc=0.9128440366972477\n",
      "EPOCH=2198\n",
      "train: loss=0.12691661893089076 acc=0.9655963302752294\n",
      "test: loss=0.3579750548774228 acc=0.908256880733945\n",
      "EPOCH=2199\n",
      "train: loss=0.195156204315707 acc=0.9357798165137615\n",
      "test: loss=0.33298588031818643 acc=0.908256880733945\n",
      "EPOCH=2200\n",
      "train: loss=0.16602648183817473 acc=0.9518348623853211\n",
      "test: loss=0.23619710082045545 acc=0.9334862385321101\n",
      "EPOCH=2201\n",
      "train: loss=0.14953632811781264 acc=0.9610091743119266\n",
      "test: loss=0.2553046917919231 acc=0.9243119266055045\n",
      "EPOCH=2202\n",
      "train: loss=0.16258285371761286 acc=0.9380733944954128\n",
      "test: loss=0.2734475206896401 acc=0.9311926605504587\n",
      "EPOCH=2203\n",
      "train: loss=0.16389353352773012 acc=0.9426605504587156\n",
      "test: loss=0.3248548307167318 acc=0.9105504587155964\n",
      "EPOCH=2204\n",
      "train: loss=0.1284893138557416 acc=0.9495412844036697\n",
      "test: loss=0.26965432008582785 acc=0.9174311926605505\n",
      "EPOCH=2205\n",
      "train: loss=0.2059985172189194 acc=0.9587155963302753\n",
      "test: loss=0.2970228410083074 acc=0.9105504587155964\n",
      "EPOCH=2206\n",
      "train: loss=0.09431541002530712 acc=0.9518348623853211\n",
      "test: loss=0.32133298615652267 acc=0.908256880733945\n",
      "EPOCH=2207\n",
      "train: loss=0.19028476028277738 acc=0.9701834862385321\n",
      "test: loss=0.26967994933401856 acc=0.9151376146788991\n",
      "EPOCH=2208\n",
      "train: loss=0.18946712259852422 acc=0.9495412844036697\n",
      "test: loss=0.2411907792213352 acc=0.9151376146788991\n",
      "EPOCH=2209\n",
      "train: loss=0.2046188116122314 acc=0.9380733944954128\n",
      "test: loss=0.27536441364249736 acc=0.9151376146788991\n",
      "EPOCH=2210\n",
      "train: loss=0.19602861322973514 acc=0.9518348623853211\n",
      "test: loss=0.2819250224260826 acc=0.9151376146788991\n",
      "EPOCH=2211\n",
      "train: loss=0.3661931071619574 acc=0.9220183486238532\n",
      "test: loss=0.2607823235381754 acc=0.908256880733945\n",
      "EPOCH=2212\n",
      "train: loss=0.19798588288632427 acc=0.944954128440367\n",
      "test: loss=0.3149941404774539 acc=0.9105504587155964\n",
      "EPOCH=2213\n",
      "train: loss=0.08208101296572214 acc=0.9770642201834863\n",
      "test: loss=0.309792086169683 acc=0.9197247706422018\n",
      "EPOCH=2214\n",
      "train: loss=0.05114634748928223 acc=0.9839449541284404\n",
      "test: loss=0.30480693528778835 acc=0.9128440366972477\n",
      "EPOCH=2215\n",
      "train: loss=0.24266856801987774 acc=0.9403669724770642\n",
      "test: loss=0.3141299371225764 acc=0.9036697247706422\n",
      "EPOCH=2216\n",
      "train: loss=0.2329525428059067 acc=0.9288990825688074\n",
      "test: loss=0.26326887509804625 acc=0.9197247706422018\n",
      "EPOCH=2217\n",
      "train: loss=0.09480870965224467 acc=0.9610091743119266\n",
      "test: loss=0.3319030810087923 acc=0.9128440366972477\n",
      "EPOCH=2218\n",
      "train: loss=0.3211436322646206 acc=0.9288990825688074\n",
      "test: loss=0.23884986824740811 acc=0.926605504587156\n",
      "EPOCH=2219\n",
      "train: loss=0.143959647539632 acc=0.9564220183486238\n",
      "test: loss=0.2390880106737108 acc=0.9197247706422018\n",
      "EPOCH=2220\n",
      "train: loss=0.2157114034170225 acc=0.9357798165137615\n",
      "test: loss=0.31557733877928074 acc=0.9128440366972477\n",
      "EPOCH=2221\n",
      "train: loss=0.16743749046602668 acc=0.9472477064220184\n",
      "test: loss=0.2187756184806329 acc=0.926605504587156\n",
      "EPOCH=2222\n",
      "train: loss=0.17178702732644363 acc=0.9403669724770642\n",
      "test: loss=0.27212860506166314 acc=0.9197247706422018\n",
      "EPOCH=2223\n",
      "train: loss=0.1505678102391608 acc=0.9495412844036697\n",
      "test: loss=0.2855131162826874 acc=0.9059633027522935\n",
      "EPOCH=2224\n",
      "train: loss=0.1866760011126735 acc=0.9380733944954128\n",
      "test: loss=0.3334375176519915 acc=0.9151376146788991\n",
      "EPOCH=2225\n",
      "train: loss=0.16674247979668788 acc=0.9564220183486238\n",
      "test: loss=0.2803645054114928 acc=0.9059633027522935\n",
      "EPOCH=2226\n",
      "train: loss=0.09295615377234073 acc=0.9655963302752294\n",
      "test: loss=0.20644395397440762 acc=0.9151376146788991\n",
      "EPOCH=2227\n",
      "train: loss=0.17929825667417662 acc=0.9403669724770642\n",
      "test: loss=0.24989132680299755 acc=0.908256880733945\n",
      "EPOCH=2228\n",
      "train: loss=0.14748856749064657 acc=0.9610091743119266\n",
      "test: loss=0.33022846828303737 acc=0.9128440366972477\n",
      "EPOCH=2229\n",
      "train: loss=0.3503319997489303 acc=0.9059633027522935\n",
      "test: loss=0.29243901018635643 acc=0.9311926605504587\n",
      "EPOCH=2230\n",
      "train: loss=0.1413930160517937 acc=0.9564220183486238\n",
      "test: loss=0.2521448524218983 acc=0.926605504587156\n",
      "EPOCH=2231\n",
      "train: loss=0.21941363319796617 acc=0.9380733944954128\n",
      "test: loss=0.30947256728522804 acc=0.908256880733945\n",
      "EPOCH=2232\n",
      "train: loss=0.14658394795473054 acc=0.944954128440367\n",
      "test: loss=0.29884477920079977 acc=0.9128440366972477\n",
      "EPOCH=2233\n",
      "train: loss=0.11786894321271549 acc=0.9770642201834863\n",
      "test: loss=0.20922746527349023 acc=0.9243119266055045\n",
      "EPOCH=2234\n",
      "train: loss=0.1596387259225031 acc=0.9610091743119266\n",
      "test: loss=0.3398013337247426 acc=0.9036697247706422\n",
      "EPOCH=2235\n",
      "train: loss=0.2102976094777926 acc=0.944954128440367\n",
      "test: loss=0.2295627968314819 acc=0.9243119266055045\n",
      "EPOCH=2236\n",
      "train: loss=0.20697535630588396 acc=0.9403669724770642\n",
      "test: loss=0.2873471222004516 acc=0.9151376146788991\n",
      "EPOCH=2237\n",
      "train: loss=0.28804366498518064 acc=0.9288990825688074\n",
      "test: loss=0.22142259428290925 acc=0.9311926605504587\n",
      "EPOCH=2238\n",
      "train: loss=0.20238281442668918 acc=0.9495412844036697\n",
      "test: loss=0.28637929158420816 acc=0.9105504587155964\n",
      "EPOCH=2239\n",
      "train: loss=0.08262502624067068 acc=0.9678899082568807\n",
      "test: loss=0.2829796518994548 acc=0.9174311926605505\n",
      "EPOCH=2240\n",
      "train: loss=0.12551584837327406 acc=0.9610091743119266\n",
      "test: loss=0.28648425315645915 acc=0.9059633027522935\n",
      "EPOCH=2241\n",
      "train: loss=0.14361755517069624 acc=0.9541284403669725\n",
      "test: loss=0.2683054198217868 acc=0.9128440366972477\n",
      "EPOCH=2242\n",
      "train: loss=0.21469199922475807 acc=0.9311926605504587\n",
      "test: loss=0.3050704856347988 acc=0.9036697247706422\n",
      "EPOCH=2243\n",
      "train: loss=0.1379326582694895 acc=0.944954128440367\n",
      "test: loss=0.3598798055030056 acc=0.9128440366972477\n",
      "EPOCH=2244\n",
      "train: loss=0.192103800979097 acc=0.9288990825688074\n",
      "test: loss=0.29904649681967316 acc=0.9105504587155964\n",
      "EPOCH=2245\n",
      "train: loss=0.3058175573328045 acc=0.9220183486238532\n",
      "test: loss=0.2447208396638986 acc=0.9357798165137615\n",
      "EPOCH=2246\n",
      "train: loss=0.0625054024158879 acc=0.9747706422018348\n",
      "test: loss=0.3642174017782029 acc=0.8899082568807339\n",
      "EPOCH=2247\n",
      "train: loss=0.2799830326217958 acc=0.9334862385321101\n",
      "test: loss=0.2521555497972343 acc=0.9220183486238532\n",
      "EPOCH=2248\n",
      "train: loss=0.23991271462454192 acc=0.926605504587156\n",
      "test: loss=0.25773804282030266 acc=0.9311926605504587\n",
      "EPOCH=2249\n",
      "train: loss=0.11715653189119313 acc=0.9587155963302753\n",
      "test: loss=0.23834331976941656 acc=0.9128440366972477\n",
      "EPOCH=2250\n",
      "train: loss=0.0930006578812149 acc=0.9678899082568807\n",
      "test: loss=0.2649512929691274 acc=0.9151376146788991\n",
      "EPOCH=2251\n",
      "train: loss=0.10575379952765951 acc=0.9678899082568807\n",
      "test: loss=0.3600342477548966 acc=0.8853211009174312\n",
      "EPOCH=2252\n",
      "train: loss=0.12015653863765433 acc=0.9541284403669725\n",
      "test: loss=0.307244167902929 acc=0.908256880733945\n",
      "EPOCH=2253\n",
      "train: loss=0.09832157598394063 acc=0.9678899082568807\n",
      "test: loss=0.3446403010432463 acc=0.9036697247706422\n",
      "EPOCH=2254\n",
      "train: loss=0.14992371094832244 acc=0.9564220183486238\n",
      "test: loss=0.24961394415996774 acc=0.9220183486238532\n",
      "EPOCH=2255\n",
      "train: loss=0.11553183727117551 acc=0.9587155963302753\n",
      "test: loss=0.2711851949699009 acc=0.908256880733945\n",
      "EPOCH=2256\n",
      "train: loss=0.22049875777159475 acc=0.9541284403669725\n",
      "test: loss=0.2855490962727145 acc=0.9288990825688074\n",
      "EPOCH=2257\n",
      "train: loss=0.22505685877665013 acc=0.9380733944954128\n",
      "test: loss=0.2817517932985637 acc=0.908256880733945\n",
      "EPOCH=2258\n",
      "train: loss=0.2764384397741791 acc=0.9288990825688074\n",
      "test: loss=0.28290235110419887 acc=0.9197247706422018\n",
      "EPOCH=2259\n",
      "train: loss=0.08304615542799194 acc=0.9587155963302753\n",
      "test: loss=0.2793428966291105 acc=0.926605504587156\n",
      "EPOCH=2260\n",
      "train: loss=0.1473191231476773 acc=0.963302752293578\n",
      "test: loss=0.28118687978250234 acc=0.9174311926605505\n",
      "EPOCH=2261\n",
      "train: loss=0.19027043998537638 acc=0.9403669724770642\n",
      "test: loss=0.29648180728865486 acc=0.908256880733945\n",
      "EPOCH=2262\n",
      "train: loss=0.17325677932581782 acc=0.9426605504587156\n",
      "test: loss=0.2746277365772751 acc=0.9128440366972477\n",
      "EPOCH=2263\n",
      "train: loss=0.2567023781942559 acc=0.9288990825688074\n",
      "test: loss=0.29361425923339063 acc=0.9197247706422018\n",
      "EPOCH=2264\n",
      "train: loss=0.09313724799805446 acc=0.9655963302752294\n",
      "test: loss=0.32079044750214036 acc=0.9105504587155964\n",
      "EPOCH=2265\n",
      "train: loss=0.13027475532844332 acc=0.9472477064220184\n",
      "test: loss=0.3037883496695015 acc=0.9105504587155964\n",
      "EPOCH=2266\n",
      "train: loss=0.16190734180337474 acc=0.9518348623853211\n",
      "test: loss=0.2720227697239909 acc=0.9311926605504587\n",
      "EPOCH=2267\n",
      "train: loss=0.1371824103711508 acc=0.9701834862385321\n",
      "test: loss=0.20245416719799267 acc=0.9311926605504587\n",
      "EPOCH=2268\n",
      "train: loss=0.1665095888608 acc=0.9357798165137615\n",
      "test: loss=0.2882815029711462 acc=0.9128440366972477\n",
      "EPOCH=2269\n",
      "train: loss=0.1656931010096151 acc=0.9403669724770642\n",
      "test: loss=0.31041644709359967 acc=0.9197247706422018\n",
      "EPOCH=2270\n",
      "train: loss=0.25275497598778285 acc=0.9288990825688074\n",
      "test: loss=0.32038537969290976 acc=0.908256880733945\n",
      "EPOCH=2271\n",
      "train: loss=0.17494363251552172 acc=0.944954128440367\n",
      "test: loss=0.3509805890550894 acc=0.908256880733945\n",
      "EPOCH=2272\n",
      "train: loss=0.24722171465509857 acc=0.926605504587156\n",
      "test: loss=0.29180521893182176 acc=0.9311926605504587\n",
      "EPOCH=2273\n",
      "train: loss=0.25655474236722636 acc=0.9334862385321101\n",
      "test: loss=0.2419771493839056 acc=0.9220183486238532\n",
      "EPOCH=2274\n",
      "train: loss=0.15506796294974903 acc=0.9334862385321101\n",
      "test: loss=0.2539477990957615 acc=0.908256880733945\n",
      "EPOCH=2275\n",
      "train: loss=0.17197142573043175 acc=0.9426605504587156\n",
      "test: loss=0.28111454546094705 acc=0.9197247706422018\n",
      "EPOCH=2276\n",
      "train: loss=0.21920024912026934 acc=0.9334862385321101\n",
      "test: loss=0.3178661503566285 acc=0.9174311926605505\n",
      "EPOCH=2277\n",
      "train: loss=0.13190805511892198 acc=0.9610091743119266\n",
      "test: loss=0.22126088780807238 acc=0.9220183486238532\n",
      "EPOCH=2278\n",
      "train: loss=0.12745638797333553 acc=0.9724770642201835\n",
      "test: loss=0.25463417972738905 acc=0.9128440366972477\n",
      "EPOCH=2279\n",
      "train: loss=0.16203967736255684 acc=0.9587155963302753\n",
      "test: loss=0.28704058788357584 acc=0.9128440366972477\n",
      "EPOCH=2280\n",
      "train: loss=0.09786999226617903 acc=0.9678899082568807\n",
      "test: loss=0.3545713976093614 acc=0.9013761467889908\n",
      "EPOCH=2281\n",
      "train: loss=0.15321714426490846 acc=0.9655963302752294\n",
      "test: loss=0.2576739444973214 acc=0.9174311926605505\n",
      "EPOCH=2282\n",
      "train: loss=0.14010923163461952 acc=0.9541284403669725\n",
      "test: loss=0.2703157713809736 acc=0.9243119266055045\n",
      "EPOCH=2283\n",
      "train: loss=0.14821687099037764 acc=0.9495412844036697\n",
      "test: loss=0.2565117317460136 acc=0.9151376146788991\n",
      "EPOCH=2284\n",
      "train: loss=0.22182854060837986 acc=0.9288990825688074\n",
      "test: loss=0.26508997887539304 acc=0.9243119266055045\n",
      "EPOCH=2285\n",
      "train: loss=0.3036992348096186 acc=0.9334862385321101\n",
      "test: loss=0.26585479206756435 acc=0.926605504587156\n",
      "EPOCH=2286\n",
      "train: loss=0.30727421844577474 acc=0.9288990825688074\n",
      "test: loss=0.25454753883746156 acc=0.9288990825688074\n",
      "EPOCH=2287\n",
      "train: loss=0.1559256972028199 acc=0.9587155963302753\n",
      "test: loss=0.32616379967034625 acc=0.9151376146788991\n",
      "EPOCH=2288\n",
      "train: loss=0.13837273580646145 acc=0.9587155963302753\n",
      "test: loss=0.19508820160424284 acc=0.9334862385321101\n",
      "EPOCH=2289\n",
      "train: loss=0.1652687482734884 acc=0.9495412844036697\n",
      "test: loss=0.36090346310574595 acc=0.9013761467889908\n",
      "EPOCH=2290\n",
      "train: loss=0.14100856175783635 acc=0.9357798165137615\n",
      "test: loss=0.23775358730604804 acc=0.9197247706422018\n",
      "EPOCH=2291\n",
      "train: loss=0.11914524844139217 acc=0.963302752293578\n",
      "test: loss=0.29550988310680854 acc=0.9059633027522935\n",
      "EPOCH=2292\n",
      "train: loss=0.04986496394156543 acc=0.9885321100917431\n",
      "test: loss=0.2409389999839166 acc=0.9243119266055045\n",
      "EPOCH=2293\n",
      "train: loss=0.19652139701954835 acc=0.944954128440367\n",
      "test: loss=0.25823001349769586 acc=0.926605504587156\n",
      "EPOCH=2294\n",
      "train: loss=0.21497992232757546 acc=0.9541284403669725\n",
      "test: loss=0.3278831757077298 acc=0.9059633027522935\n",
      "EPOCH=2295\n",
      "train: loss=0.16965181950110683 acc=0.9472477064220184\n",
      "test: loss=0.27898016803939313 acc=0.9151376146788991\n",
      "EPOCH=2296\n",
      "train: loss=0.16996042960738675 acc=0.9564220183486238\n",
      "test: loss=0.2900217530189773 acc=0.9128440366972477\n",
      "EPOCH=2297\n",
      "train: loss=0.23046501089588284 acc=0.926605504587156\n",
      "test: loss=0.39101863712513946 acc=0.9036697247706422\n",
      "EPOCH=2298\n",
      "train: loss=0.16788778546421895 acc=0.9472477064220184\n",
      "test: loss=0.34656326259302606 acc=0.9197247706422018\n",
      "EPOCH=2299\n",
      "train: loss=0.2920570859692818 acc=0.9197247706422018\n",
      "test: loss=0.25267279686280414 acc=0.9288990825688074\n",
      "EPOCH=2300\n",
      "train: loss=0.15517437436263817 acc=0.9472477064220184\n",
      "test: loss=0.26215218023505193 acc=0.9174311926605505\n",
      "EPOCH=2301\n",
      "train: loss=0.17799654231369827 acc=0.9426605504587156\n",
      "test: loss=0.2866536351052756 acc=0.9243119266055045\n",
      "EPOCH=2302\n",
      "train: loss=0.11214158672437796 acc=0.9518348623853211\n",
      "test: loss=0.2779840757322345 acc=0.9334862385321101\n",
      "EPOCH=2303\n",
      "train: loss=0.08011885154679634 acc=0.9747706422018348\n",
      "test: loss=0.2375326406050011 acc=0.9288990825688074\n",
      "EPOCH=2304\n",
      "train: loss=0.21631199282545374 acc=0.9288990825688074\n",
      "test: loss=0.2818029115918874 acc=0.9105504587155964\n",
      "EPOCH=2305\n",
      "train: loss=0.21318972687535964 acc=0.9403669724770642\n",
      "test: loss=0.2716190383740154 acc=0.9151376146788991\n",
      "EPOCH=2306\n",
      "train: loss=0.12745275713269014 acc=0.9701834862385321\n",
      "test: loss=0.29003647878006433 acc=0.9151376146788991\n",
      "EPOCH=2307\n",
      "train: loss=0.1429408851356086 acc=0.9495412844036697\n",
      "test: loss=0.32852803863894015 acc=0.8967889908256881\n",
      "EPOCH=2308\n",
      "train: loss=0.16461823739000989 acc=0.9472477064220184\n",
      "test: loss=0.2355098639843075 acc=0.9197247706422018\n",
      "EPOCH=2309\n",
      "train: loss=0.11671878288816953 acc=0.9495412844036697\n",
      "test: loss=0.35314842541097125 acc=0.8967889908256881\n",
      "EPOCH=2310\n",
      "train: loss=0.23795561702673548 acc=0.9403669724770642\n",
      "test: loss=0.2832599268277255 acc=0.9174311926605505\n",
      "EPOCH=2311\n",
      "train: loss=0.09008797416788841 acc=0.9747706422018348\n",
      "test: loss=0.2937256503306307 acc=0.9288990825688074\n",
      "EPOCH=2312\n",
      "train: loss=0.14054301905435773 acc=0.963302752293578\n",
      "test: loss=0.3256762057214618 acc=0.8967889908256881\n",
      "EPOCH=2313\n",
      "train: loss=0.23020048852482286 acc=0.9334862385321101\n",
      "test: loss=0.24351877786208953 acc=0.9197247706422018\n",
      "EPOCH=2314\n",
      "train: loss=0.14730657573922037 acc=0.9587155963302753\n",
      "test: loss=0.2534532917883252 acc=0.9197247706422018\n",
      "EPOCH=2315\n",
      "train: loss=0.12940445093570624 acc=0.9655963302752294\n",
      "test: loss=0.27723912938529965 acc=0.9174311926605505\n",
      "EPOCH=2316\n",
      "train: loss=0.056856704033613266 acc=0.9655963302752294\n",
      "test: loss=0.3043764043994078 acc=0.9174311926605505\n",
      "EPOCH=2317\n",
      "train: loss=0.2163785308909514 acc=0.926605504587156\n",
      "test: loss=0.28076299703905366 acc=0.9197247706422018\n",
      "EPOCH=2318\n",
      "train: loss=0.03795840165792888 acc=0.9908256880733946\n",
      "test: loss=0.26685435598011314 acc=0.926605504587156\n",
      "EPOCH=2319\n",
      "train: loss=0.30592246999651546 acc=0.9220183486238532\n",
      "test: loss=0.3040865780951192 acc=0.908256880733945\n",
      "EPOCH=2320\n",
      "train: loss=0.21015516918457627 acc=0.9403669724770642\n",
      "test: loss=0.26910037654684815 acc=0.926605504587156\n",
      "EPOCH=2321\n",
      "train: loss=0.13759158525114662 acc=0.9587155963302753\n",
      "test: loss=0.2999642224058458 acc=0.9174311926605505\n",
      "EPOCH=2322\n",
      "train: loss=0.17019556787337722 acc=0.9495412844036697\n",
      "test: loss=0.2425672872646405 acc=0.9380733944954128\n",
      "EPOCH=2323\n",
      "train: loss=0.2739066172152161 acc=0.9380733944954128\n",
      "test: loss=0.27552515955200263 acc=0.908256880733945\n",
      "EPOCH=2324\n",
      "train: loss=0.2376080359992478 acc=0.9380733944954128\n",
      "test: loss=0.3624549443481146 acc=0.8944954128440367\n",
      "EPOCH=2325\n",
      "train: loss=0.06236082095934699 acc=0.9724770642201835\n",
      "test: loss=0.3050894907609599 acc=0.9128440366972477\n",
      "EPOCH=2326\n",
      "train: loss=0.184985336853797 acc=0.9472477064220184\n",
      "test: loss=0.23740215372044898 acc=0.926605504587156\n",
      "EPOCH=2327\n",
      "train: loss=0.06792842633773293 acc=0.9770642201834863\n",
      "test: loss=0.3197927203231652 acc=0.908256880733945\n",
      "EPOCH=2328\n",
      "train: loss=0.2256751349494784 acc=0.9403669724770642\n",
      "test: loss=0.2794374581560715 acc=0.908256880733945\n",
      "EPOCH=2329\n",
      "train: loss=0.07926868906929539 acc=0.9747706422018348\n",
      "test: loss=0.32328331501793445 acc=0.9036697247706422\n",
      "EPOCH=2330\n",
      "train: loss=0.1040885277237259 acc=0.963302752293578\n",
      "test: loss=0.24893921838334823 acc=0.9288990825688074\n",
      "EPOCH=2331\n",
      "train: loss=0.02516892868766962 acc=0.9931192660550459\n",
      "test: loss=0.34021248639924734 acc=0.9059633027522935\n",
      "EPOCH=2332\n",
      "train: loss=0.13539518309771198 acc=0.9564220183486238\n",
      "test: loss=0.35772478715774986 acc=0.8944954128440367\n",
      "EPOCH=2333\n",
      "train: loss=0.14292556963851946 acc=0.9564220183486238\n",
      "test: loss=0.34327818273593746 acc=0.908256880733945\n",
      "EPOCH=2334\n",
      "train: loss=0.23032665112874393 acc=0.9472477064220184\n",
      "test: loss=0.37518281501391143 acc=0.9105504587155964\n",
      "EPOCH=2335\n",
      "train: loss=0.11940972738285983 acc=0.963302752293578\n",
      "test: loss=0.2544715645266115 acc=0.9128440366972477\n",
      "EPOCH=2336\n",
      "train: loss=0.13066032232668678 acc=0.963302752293578\n",
      "test: loss=0.3284586916498367 acc=0.9174311926605505\n",
      "EPOCH=2337\n",
      "train: loss=0.2248708335001707 acc=0.9357798165137615\n",
      "test: loss=0.25586938766750905 acc=0.9174311926605505\n",
      "EPOCH=2338\n",
      "train: loss=0.12340300402295373 acc=0.9564220183486238\n",
      "test: loss=0.37942482019328805 acc=0.8967889908256881\n",
      "EPOCH=2339\n",
      "train: loss=0.1280072178994156 acc=0.9564220183486238\n",
      "test: loss=0.3033459005097091 acc=0.9220183486238532\n",
      "EPOCH=2340\n",
      "train: loss=0.16908223626148286 acc=0.963302752293578\n",
      "test: loss=0.18969462563357 acc=0.9472477064220184\n",
      "EPOCH=2341\n",
      "train: loss=0.19014680405676318 acc=0.9472477064220184\n",
      "test: loss=0.3436419394933169 acc=0.8967889908256881\n",
      "EPOCH=2342\n",
      "train: loss=0.18734756216776846 acc=0.9426605504587156\n",
      "test: loss=0.24613148368462748 acc=0.9288990825688074\n",
      "EPOCH=2343\n",
      "train: loss=0.15675986576168224 acc=0.9472477064220184\n",
      "test: loss=0.24155642670703717 acc=0.9197247706422018\n",
      "EPOCH=2344\n",
      "train: loss=0.14687359288607107 acc=0.9564220183486238\n",
      "test: loss=0.2744757865679658 acc=0.9174311926605505\n",
      "EPOCH=2345\n",
      "train: loss=0.2134862072724556 acc=0.9472477064220184\n",
      "test: loss=0.23955115344374758 acc=0.926605504587156\n",
      "EPOCH=2346\n",
      "train: loss=0.1252132123396182 acc=0.9587155963302753\n",
      "test: loss=0.2867755916430115 acc=0.9105504587155964\n",
      "EPOCH=2347\n",
      "train: loss=0.22275123086804272 acc=0.9380733944954128\n",
      "test: loss=0.3696863660742132 acc=0.9128440366972477\n",
      "EPOCH=2348\n",
      "train: loss=0.16141098760310396 acc=0.9495412844036697\n",
      "test: loss=0.3384529562262897 acc=0.9197247706422018\n",
      "EPOCH=2349\n",
      "train: loss=0.1394480994775482 acc=0.963302752293578\n",
      "test: loss=0.2945005436075797 acc=0.9128440366972477\n",
      "EPOCH=2350\n",
      "train: loss=0.08636901565903399 acc=0.9655963302752294\n",
      "test: loss=0.2767894733858451 acc=0.9174311926605505\n",
      "EPOCH=2351\n",
      "train: loss=0.18525236703920026 acc=0.9403669724770642\n",
      "test: loss=0.32400924446778295 acc=0.9197247706422018\n",
      "EPOCH=2352\n",
      "train: loss=0.17602019581762582 acc=0.9495412844036697\n",
      "test: loss=0.2902196815887252 acc=0.9151376146788991\n",
      "EPOCH=2353\n",
      "train: loss=0.2617440190045764 acc=0.9059633027522935\n",
      "test: loss=0.27025660380712374 acc=0.9128440366972477\n",
      "EPOCH=2354\n",
      "train: loss=0.21827558638019665 acc=0.9288990825688074\n",
      "test: loss=0.2484527734090485 acc=0.9128440366972477\n",
      "EPOCH=2355\n",
      "train: loss=0.2131518734489746 acc=0.9587155963302753\n",
      "test: loss=0.2300963196967096 acc=0.926605504587156\n",
      "EPOCH=2356\n",
      "train: loss=0.19089499492159046 acc=0.9403669724770642\n",
      "test: loss=0.35882630331646903 acc=0.9059633027522935\n",
      "EPOCH=2357\n",
      "train: loss=0.2265258373460868 acc=0.944954128440367\n",
      "test: loss=0.27951622076460253 acc=0.9128440366972477\n",
      "EPOCH=2358\n",
      "train: loss=0.18375947859159142 acc=0.9426605504587156\n",
      "test: loss=0.20292850462976386 acc=0.9334862385321101\n",
      "EPOCH=2359\n",
      "train: loss=0.180585462036437 acc=0.9403669724770642\n",
      "test: loss=0.28621689501049064 acc=0.908256880733945\n",
      "EPOCH=2360\n",
      "train: loss=0.21153121309179918 acc=0.944954128440367\n",
      "test: loss=0.2679712843141482 acc=0.9197247706422018\n",
      "EPOCH=2361\n",
      "train: loss=0.10313152803812173 acc=0.9610091743119266\n",
      "test: loss=0.2411754822723119 acc=0.926605504587156\n",
      "EPOCH=2362\n",
      "train: loss=0.12504251301781222 acc=0.9564220183486238\n",
      "test: loss=0.3179825756987838 acc=0.9059633027522935\n",
      "EPOCH=2363\n",
      "train: loss=0.0740933838611673 acc=0.9701834862385321\n",
      "test: loss=0.33703825038315716 acc=0.9036697247706422\n",
      "EPOCH=2364\n",
      "train: loss=0.16228250879964212 acc=0.9495412844036697\n",
      "test: loss=0.26060214534556 acc=0.9151376146788991\n",
      "EPOCH=2365\n",
      "train: loss=0.05835021354985338 acc=0.9747706422018348\n",
      "test: loss=0.3732749453449275 acc=0.9105504587155964\n",
      "EPOCH=2366\n",
      "train: loss=0.2673561549345415 acc=0.926605504587156\n",
      "test: loss=0.33562134289547874 acc=0.9105504587155964\n",
      "EPOCH=2367\n",
      "train: loss=0.1968962759933143 acc=0.9541284403669725\n",
      "test: loss=0.367245997764137 acc=0.908256880733945\n",
      "EPOCH=2368\n",
      "train: loss=0.3672951681818687 acc=0.8784403669724771\n",
      "test: loss=0.29099961410995495 acc=0.9288990825688074\n",
      "EPOCH=2369\n",
      "train: loss=0.17694685558358042 acc=0.9403669724770642\n",
      "test: loss=0.2551498528148036 acc=0.9311926605504587\n",
      "EPOCH=2370\n",
      "train: loss=0.18376292145833287 acc=0.9426605504587156\n",
      "test: loss=0.2969123019255905 acc=0.908256880733945\n",
      "EPOCH=2371\n",
      "train: loss=0.13872017980976734 acc=0.9564220183486238\n",
      "test: loss=0.23960297168539282 acc=0.9334862385321101\n",
      "EPOCH=2372\n",
      "train: loss=0.16806058113847785 acc=0.9541284403669725\n",
      "test: loss=0.29061347137928345 acc=0.9197247706422018\n",
      "EPOCH=2373\n",
      "train: loss=0.2637434224552718 acc=0.9380733944954128\n",
      "test: loss=0.24639234205467095 acc=0.9220183486238532\n",
      "EPOCH=2374\n",
      "train: loss=0.0993211646322745 acc=0.9610091743119266\n",
      "test: loss=0.34227799841530093 acc=0.9036697247706422\n",
      "EPOCH=2375\n",
      "train: loss=0.21195715068820187 acc=0.9380733944954128\n",
      "test: loss=0.37683495572373926 acc=0.9059633027522935\n",
      "EPOCH=2376\n",
      "train: loss=0.23408875324407857 acc=0.926605504587156\n",
      "test: loss=0.27756517389572505 acc=0.9174311926605505\n",
      "EPOCH=2377\n",
      "train: loss=0.1393963891329448 acc=0.9564220183486238\n",
      "test: loss=0.2519263189710988 acc=0.9174311926605505\n",
      "EPOCH=2378\n",
      "train: loss=0.23722356486067792 acc=0.9334862385321101\n",
      "test: loss=0.31055164815754666 acc=0.9151376146788991\n",
      "EPOCH=2379\n",
      "train: loss=0.18895661085460472 acc=0.9495412844036697\n",
      "test: loss=0.3139105117206415 acc=0.9013761467889908\n",
      "EPOCH=2380\n",
      "train: loss=0.1889154489162561 acc=0.9564220183486238\n",
      "test: loss=0.31098906335857934 acc=0.908256880733945\n",
      "EPOCH=2381\n",
      "train: loss=0.12030192310029153 acc=0.9610091743119266\n",
      "test: loss=0.28277754518149983 acc=0.9174311926605505\n",
      "EPOCH=2382\n",
      "train: loss=0.08107852770976402 acc=0.963302752293578\n",
      "test: loss=0.34045476499990784 acc=0.9059633027522935\n",
      "EPOCH=2383\n",
      "train: loss=0.2222594154860081 acc=0.9288990825688074\n",
      "test: loss=0.3798806311223814 acc=0.9105504587155964\n",
      "EPOCH=2384\n",
      "train: loss=0.17060570090938287 acc=0.9518348623853211\n",
      "test: loss=0.2634988414205848 acc=0.926605504587156\n",
      "EPOCH=2385\n",
      "train: loss=0.2583450803647554 acc=0.9128440366972477\n",
      "test: loss=0.27150389621325255 acc=0.9174311926605505\n",
      "EPOCH=2386\n",
      "train: loss=0.08932442861661671 acc=0.9701834862385321\n",
      "test: loss=0.22459582716965132 acc=0.9220183486238532\n",
      "EPOCH=2387\n",
      "train: loss=0.18026594034841717 acc=0.944954128440367\n",
      "test: loss=0.39742107540049 acc=0.8944954128440367\n",
      "EPOCH=2388\n",
      "train: loss=0.12371330509528355 acc=0.963302752293578\n",
      "test: loss=0.2235871346403002 acc=0.9220183486238532\n",
      "EPOCH=2389\n",
      "train: loss=0.21895923261658465 acc=0.9357798165137615\n",
      "test: loss=0.31893465211556893 acc=0.908256880733945\n",
      "EPOCH=2390\n",
      "train: loss=0.13853476550647298 acc=0.9610091743119266\n",
      "test: loss=0.24554600768621504 acc=0.9288990825688074\n",
      "EPOCH=2391\n",
      "train: loss=0.07270346983168499 acc=0.9770642201834863\n",
      "test: loss=0.34223575623210956 acc=0.9013761467889908\n",
      "EPOCH=2392\n",
      "train: loss=0.25723816559063856 acc=0.926605504587156\n",
      "test: loss=0.24759383033789772 acc=0.926605504587156\n",
      "EPOCH=2393\n",
      "train: loss=0.11460737431258514 acc=0.9655963302752294\n",
      "test: loss=0.31473353007612404 acc=0.9220183486238532\n",
      "EPOCH=2394\n",
      "train: loss=0.11453616834213333 acc=0.963302752293578\n",
      "test: loss=0.30727161593352315 acc=0.9174311926605505\n",
      "EPOCH=2395\n",
      "train: loss=0.10344868686760154 acc=0.9610091743119266\n",
      "test: loss=0.25620254110727503 acc=0.9243119266055045\n",
      "EPOCH=2396\n",
      "train: loss=0.18558153244337672 acc=0.9334862385321101\n",
      "test: loss=0.23643665679467993 acc=0.9288990825688074\n",
      "EPOCH=2397\n",
      "train: loss=0.08366572652315973 acc=0.9724770642201835\n",
      "test: loss=0.29600335835518693 acc=0.9197247706422018\n",
      "EPOCH=2398\n",
      "train: loss=0.21545024403046606 acc=0.9564220183486238\n",
      "test: loss=0.3393741812718667 acc=0.908256880733945\n",
      "EPOCH=2399\n",
      "train: loss=0.39420949212897877 acc=0.908256880733945\n",
      "test: loss=0.34088678581391496 acc=0.9013761467889908\n",
      "EPOCH=2400\n",
      "train: loss=0.1317494301047664 acc=0.9610091743119266\n",
      "test: loss=0.333116317232241 acc=0.9059633027522935\n",
      "EPOCH=2401\n",
      "train: loss=0.16063267967130201 acc=0.9564220183486238\n",
      "test: loss=0.2947746854769664 acc=0.9151376146788991\n",
      "EPOCH=2402\n",
      "train: loss=0.09333903843899992 acc=0.9678899082568807\n",
      "test: loss=0.3552132040005782 acc=0.9036697247706422\n",
      "EPOCH=2403\n",
      "train: loss=0.2029564910695522 acc=0.9472477064220184\n",
      "test: loss=0.3530870616878145 acc=0.9059633027522935\n",
      "EPOCH=2404\n",
      "train: loss=0.13889156620172813 acc=0.9426605504587156\n",
      "test: loss=0.3078011811338471 acc=0.8944954128440367\n",
      "EPOCH=2405\n",
      "train: loss=0.14654588400364685 acc=0.9426605504587156\n",
      "test: loss=0.3056031867670486 acc=0.908256880733945\n",
      "EPOCH=2406\n",
      "train: loss=0.18284577285333123 acc=0.944954128440367\n",
      "test: loss=0.26415389940609324 acc=0.9197247706422018\n",
      "EPOCH=2407\n",
      "train: loss=0.20877642703355387 acc=0.9311926605504587\n",
      "test: loss=0.2806436575088495 acc=0.9243119266055045\n",
      "EPOCH=2408\n",
      "train: loss=0.13503535688913756 acc=0.9518348623853211\n",
      "test: loss=0.35591410041283084 acc=0.8990825688073395\n",
      "EPOCH=2409\n",
      "train: loss=0.16756434687727897 acc=0.9288990825688074\n",
      "test: loss=0.3035402453445154 acc=0.9174311926605505\n",
      "EPOCH=2410\n",
      "train: loss=0.05099721088312626 acc=0.9770642201834863\n",
      "test: loss=0.34225536285431174 acc=0.9151376146788991\n",
      "EPOCH=2411\n",
      "train: loss=0.07150712095438447 acc=0.9655963302752294\n",
      "test: loss=0.37707055402169826 acc=0.8967889908256881\n",
      "EPOCH=2412\n",
      "train: loss=0.21450428594911267 acc=0.9357798165137615\n",
      "test: loss=0.3051132549459099 acc=0.908256880733945\n",
      "EPOCH=2413\n",
      "train: loss=0.0892843554798888 acc=0.9678899082568807\n",
      "test: loss=0.31627948806566114 acc=0.9174311926605505\n",
      "EPOCH=2414\n",
      "train: loss=0.17325412894590622 acc=0.9610091743119266\n",
      "test: loss=0.34838711576686704 acc=0.9059633027522935\n",
      "EPOCH=2415\n",
      "train: loss=0.2915067669731742 acc=0.9288990825688074\n",
      "test: loss=0.26241488975380395 acc=0.926605504587156\n",
      "EPOCH=2416\n",
      "train: loss=0.22667990694720716 acc=0.9472477064220184\n",
      "test: loss=0.2854900834218231 acc=0.9128440366972477\n",
      "EPOCH=2417\n",
      "train: loss=0.21816494544422033 acc=0.9380733944954128\n",
      "test: loss=0.25732492271268653 acc=0.9220183486238532\n",
      "EPOCH=2418\n",
      "train: loss=0.14165991987706966 acc=0.9610091743119266\n",
      "test: loss=0.23556524279227006 acc=0.9220183486238532\n",
      "EPOCH=2419\n",
      "train: loss=0.10090461075616199 acc=0.9655963302752294\n",
      "test: loss=0.32503285688598516 acc=0.9220183486238532\n",
      "EPOCH=2420\n",
      "train: loss=0.21911748178972273 acc=0.9403669724770642\n",
      "test: loss=0.24319028164479262 acc=0.9334862385321101\n",
      "EPOCH=2421\n",
      "train: loss=0.09137252293702743 acc=0.9610091743119266\n",
      "test: loss=0.20828942402613151 acc=0.9174311926605505\n",
      "EPOCH=2422\n",
      "train: loss=0.1950042121891031 acc=0.9472477064220184\n",
      "test: loss=0.25248081275114626 acc=0.9220183486238532\n",
      "EPOCH=2423\n",
      "train: loss=0.21242791871294006 acc=0.9334862385321101\n",
      "test: loss=0.28814129134368555 acc=0.9151376146788991\n",
      "EPOCH=2424\n",
      "train: loss=0.15406854871122405 acc=0.9495412844036697\n",
      "test: loss=0.314789603338236 acc=0.9197247706422018\n",
      "EPOCH=2425\n",
      "train: loss=0.1932829394798358 acc=0.9426605504587156\n",
      "test: loss=0.2531527372668139 acc=0.9220183486238532\n",
      "EPOCH=2426\n",
      "train: loss=0.21194929000765586 acc=0.9518348623853211\n",
      "test: loss=0.2531353425177066 acc=0.9197247706422018\n",
      "EPOCH=2427\n",
      "train: loss=0.2048026723100684 acc=0.9426605504587156\n",
      "test: loss=0.28985987159364013 acc=0.9197247706422018\n",
      "EPOCH=2428\n",
      "train: loss=0.3823793701241542 acc=0.9036697247706422\n",
      "test: loss=0.2560802535801177 acc=0.9243119266055045\n",
      "EPOCH=2429\n",
      "train: loss=0.17311142418285055 acc=0.9311926605504587\n",
      "test: loss=0.30147050132369685 acc=0.9105504587155964\n",
      "EPOCH=2430\n",
      "train: loss=0.14602638443965182 acc=0.9587155963302753\n",
      "test: loss=0.2598343100737788 acc=0.9220183486238532\n",
      "EPOCH=2431\n",
      "train: loss=0.14889161560186168 acc=0.963302752293578\n",
      "test: loss=0.35047887429139596 acc=0.908256880733945\n",
      "EPOCH=2432\n",
      "train: loss=0.24137310686111016 acc=0.9220183486238532\n",
      "test: loss=0.32777271713417705 acc=0.9151376146788991\n",
      "EPOCH=2433\n",
      "train: loss=0.11020036527638628 acc=0.963302752293578\n",
      "test: loss=0.33724097086456534 acc=0.9013761467889908\n",
      "EPOCH=2434\n",
      "train: loss=0.11417163547550058 acc=0.963302752293578\n",
      "test: loss=0.312899885615434 acc=0.9197247706422018\n",
      "EPOCH=2435\n",
      "train: loss=0.07454442829497035 acc=0.9678899082568807\n",
      "test: loss=0.37150882678464264 acc=0.9128440366972477\n",
      "EPOCH=2436\n",
      "train: loss=0.09625924959435174 acc=0.963302752293578\n",
      "test: loss=0.31086437429872005 acc=0.9013761467889908\n",
      "EPOCH=2437\n",
      "train: loss=0.10361965902691812 acc=0.9724770642201835\n",
      "test: loss=0.3619472602961863 acc=0.8967889908256881\n",
      "EPOCH=2438\n",
      "train: loss=0.17952287855774698 acc=0.9518348623853211\n",
      "test: loss=0.22537066396804167 acc=0.9288990825688074\n",
      "EPOCH=2439\n",
      "train: loss=0.07133213934213575 acc=0.9747706422018348\n",
      "test: loss=0.23024230301792525 acc=0.9334862385321101\n",
      "EPOCH=2440\n",
      "train: loss=0.20241252557255213 acc=0.9334862385321101\n",
      "test: loss=0.33684502540105427 acc=0.9059633027522935\n",
      "EPOCH=2441\n",
      "train: loss=0.09057848169057969 acc=0.9724770642201835\n",
      "test: loss=0.3542878082257381 acc=0.9220183486238532\n",
      "EPOCH=2442\n",
      "train: loss=0.17940172485728842 acc=0.9587155963302753\n",
      "test: loss=0.30550289071819925 acc=0.9059633027522935\n",
      "EPOCH=2443\n",
      "train: loss=0.21157942911284797 acc=0.9495412844036697\n",
      "test: loss=0.328095196030034 acc=0.9128440366972477\n",
      "EPOCH=2444\n",
      "train: loss=0.2009708401510449 acc=0.9518348623853211\n",
      "test: loss=0.2510292140389468 acc=0.9288990825688074\n",
      "EPOCH=2445\n",
      "train: loss=0.16190615850208895 acc=0.9541284403669725\n",
      "test: loss=0.23234964530105884 acc=0.9243119266055045\n",
      "EPOCH=2446\n",
      "train: loss=0.23126896512023556 acc=0.9311926605504587\n",
      "test: loss=0.32800281239399787 acc=0.8990825688073395\n",
      "EPOCH=2447\n",
      "train: loss=0.18634539311070678 acc=0.9357798165137615\n",
      "test: loss=0.33781163384432483 acc=0.9059633027522935\n",
      "EPOCH=2448\n",
      "train: loss=0.1649796589534768 acc=0.944954128440367\n",
      "test: loss=0.29044674914429336 acc=0.9128440366972477\n",
      "EPOCH=2449\n",
      "train: loss=0.18207209480080683 acc=0.9495412844036697\n",
      "test: loss=0.22194826647955113 acc=0.9334862385321101\n",
      "EPOCH=2450\n",
      "train: loss=0.10472539517511303 acc=0.963302752293578\n",
      "test: loss=0.29395697479878224 acc=0.9059633027522935\n",
      "EPOCH=2451\n",
      "train: loss=0.14668357516301667 acc=0.9564220183486238\n",
      "test: loss=0.2982288051534918 acc=0.9128440366972477\n",
      "EPOCH=2452\n",
      "train: loss=0.08442037764193144 acc=0.9724770642201835\n",
      "test: loss=0.2225342809844502 acc=0.9243119266055045\n",
      "EPOCH=2453\n",
      "train: loss=0.0742112014727271 acc=0.9678899082568807\n",
      "test: loss=0.257846214515351 acc=0.9334862385321101\n",
      "EPOCH=2454\n",
      "train: loss=0.12076555220421126 acc=0.9655963302752294\n",
      "test: loss=0.23210306212928453 acc=0.9174311926605505\n",
      "EPOCH=2455\n",
      "train: loss=0.15675434233755758 acc=0.9610091743119266\n",
      "test: loss=0.3395465264809189 acc=0.9128440366972477\n",
      "EPOCH=2456\n",
      "train: loss=0.14441758382999045 acc=0.9587155963302753\n",
      "test: loss=0.29273219566533865 acc=0.908256880733945\n",
      "EPOCH=2457\n",
      "train: loss=0.09821331706454359 acc=0.9610091743119266\n",
      "test: loss=0.3478246774425563 acc=0.9174311926605505\n",
      "EPOCH=2458\n",
      "train: loss=0.21289257256826194 acc=0.9380733944954128\n",
      "test: loss=0.2226772163810518 acc=0.9495412844036697\n",
      "EPOCH=2459\n",
      "train: loss=0.16175369103045897 acc=0.9518348623853211\n",
      "test: loss=0.31791004175877935 acc=0.908256880733945\n",
      "EPOCH=2460\n",
      "train: loss=0.2994735494210034 acc=0.926605504587156\n",
      "test: loss=0.29165389892109855 acc=0.9105504587155964\n",
      "EPOCH=2461\n",
      "train: loss=0.1427592481872076 acc=0.9472477064220184\n",
      "test: loss=0.3134097889733653 acc=0.9197247706422018\n",
      "EPOCH=2462\n",
      "train: loss=0.18334355258869614 acc=0.9518348623853211\n",
      "test: loss=0.27659646228108953 acc=0.9151376146788991\n",
      "EPOCH=2463\n",
      "train: loss=0.319724603178624 acc=0.9128440366972477\n",
      "test: loss=0.4120462947580562 acc=0.8922018348623854\n",
      "EPOCH=2464\n",
      "train: loss=0.13497134964856913 acc=0.963302752293578\n",
      "test: loss=0.3082163581493677 acc=0.9036697247706422\n",
      "EPOCH=2465\n",
      "train: loss=0.1099496216121649 acc=0.9655963302752294\n",
      "test: loss=0.3011037718364976 acc=0.908256880733945\n",
      "EPOCH=2466\n",
      "train: loss=0.16186379192251027 acc=0.9495412844036697\n",
      "test: loss=0.3392444527817492 acc=0.9174311926605505\n",
      "EPOCH=2467\n",
      "train: loss=0.13609518385611946 acc=0.9655963302752294\n",
      "test: loss=0.3057541379686085 acc=0.9128440366972477\n",
      "EPOCH=2468\n",
      "train: loss=0.19424979594660155 acc=0.9403669724770642\n",
      "test: loss=0.31318209520637236 acc=0.9059633027522935\n",
      "EPOCH=2469\n",
      "train: loss=0.18224023509482515 acc=0.9403669724770642\n",
      "test: loss=0.18881853023345602 acc=0.9197247706422018\n",
      "EPOCH=2470\n",
      "train: loss=0.13425095684959723 acc=0.9587155963302753\n",
      "test: loss=0.2669070364195603 acc=0.9128440366972477\n",
      "EPOCH=2471\n",
      "train: loss=0.21406143879248402 acc=0.9380733944954128\n",
      "test: loss=0.2976508117869584 acc=0.9128440366972477\n",
      "EPOCH=2472\n",
      "train: loss=0.1307967980315098 acc=0.9495412844036697\n",
      "test: loss=0.29236792744244366 acc=0.9197247706422018\n",
      "EPOCH=2473\n",
      "train: loss=0.23824830355743354 acc=0.9334862385321101\n",
      "test: loss=0.330841458563681 acc=0.9059633027522935\n",
      "EPOCH=2474\n",
      "train: loss=0.08141462158931582 acc=0.9839449541284404\n",
      "test: loss=0.33667698629018594 acc=0.9059633027522935\n",
      "EPOCH=2475\n",
      "train: loss=0.22679985780218154 acc=0.9288990825688074\n",
      "test: loss=0.2862174589773938 acc=0.9151376146788991\n",
      "EPOCH=2476\n",
      "train: loss=0.13069037057740543 acc=0.9678899082568807\n",
      "test: loss=0.29490053817849543 acc=0.9288990825688074\n",
      "EPOCH=2477\n",
      "train: loss=0.18115205199569717 acc=0.9495412844036697\n",
      "test: loss=0.26612528885359626 acc=0.9151376146788991\n",
      "EPOCH=2478\n",
      "train: loss=0.22164994354486622 acc=0.9288990825688074\n",
      "test: loss=0.2588129376066136 acc=0.9220183486238532\n",
      "EPOCH=2479\n",
      "train: loss=0.0752843223306445 acc=0.9724770642201835\n",
      "test: loss=0.35672484734375093 acc=0.908256880733945\n",
      "EPOCH=2480\n",
      "train: loss=0.22273902381835559 acc=0.9380733944954128\n",
      "test: loss=0.23173130509362344 acc=0.9128440366972477\n",
      "EPOCH=2481\n",
      "train: loss=0.09503797916511848 acc=0.9724770642201835\n",
      "test: loss=0.21137202516621995 acc=0.9403669724770642\n",
      "EPOCH=2482\n",
      "train: loss=0.1868108082877499 acc=0.9610091743119266\n",
      "test: loss=0.3211848206175402 acc=0.9036697247706422\n",
      "EPOCH=2483\n",
      "train: loss=0.19457160499606935 acc=0.9518348623853211\n",
      "test: loss=0.2257948249764967 acc=0.9311926605504587\n",
      "EPOCH=2484\n",
      "train: loss=0.203260114610674 acc=0.9472477064220184\n",
      "test: loss=0.3255332811151924 acc=0.9128440366972477\n",
      "EPOCH=2485\n",
      "train: loss=0.2567750998505001 acc=0.9288990825688074\n",
      "test: loss=0.3258314056731682 acc=0.9036697247706422\n",
      "EPOCH=2486\n",
      "train: loss=0.14771876998422231 acc=0.9472477064220184\n",
      "test: loss=0.32665711910548073 acc=0.9036697247706422\n",
      "EPOCH=2487\n",
      "train: loss=0.14720866032571467 acc=0.9541284403669725\n",
      "test: loss=0.23066270075580347 acc=0.9220183486238532\n",
      "EPOCH=2488\n",
      "train: loss=0.14428479696798358 acc=0.9495412844036697\n",
      "test: loss=0.3046695518815298 acc=0.9243119266055045\n",
      "EPOCH=2489\n",
      "train: loss=0.22739269671457518 acc=0.9334862385321101\n",
      "test: loss=0.2824163423102825 acc=0.9220183486238532\n",
      "EPOCH=2490\n",
      "train: loss=0.12516073232913005 acc=0.9655963302752294\n",
      "test: loss=0.3135685668483963 acc=0.908256880733945\n",
      "EPOCH=2491\n",
      "train: loss=0.13160961979411756 acc=0.963302752293578\n",
      "test: loss=0.2828524846906217 acc=0.9151376146788991\n",
      "EPOCH=2492\n",
      "train: loss=0.1288000139146466 acc=0.9495412844036697\n",
      "test: loss=0.2791301286112757 acc=0.9311926605504587\n",
      "EPOCH=2493\n",
      "train: loss=0.2731078742381829 acc=0.9128440366972477\n",
      "test: loss=0.3765851985705708 acc=0.8967889908256881\n",
      "EPOCH=2494\n",
      "train: loss=0.20184069674012886 acc=0.9380733944954128\n",
      "test: loss=0.34079006779531296 acc=0.9220183486238532\n",
      "EPOCH=2495\n",
      "train: loss=0.13217979833036186 acc=0.9587155963302753\n",
      "test: loss=0.3217820154905105 acc=0.8990825688073395\n",
      "EPOCH=2496\n",
      "train: loss=0.14109075803103702 acc=0.9518348623853211\n",
      "test: loss=0.3522629372547848 acc=0.8899082568807339\n",
      "EPOCH=2497\n",
      "train: loss=0.14184388583347743 acc=0.9564220183486238\n",
      "test: loss=0.2874529905277428 acc=0.9197247706422018\n",
      "EPOCH=2498\n",
      "train: loss=0.2376483235328551 acc=0.926605504587156\n",
      "test: loss=0.439849730776903 acc=0.8944954128440367\n",
      "EPOCH=2499\n",
      "train: loss=0.2146447631738922 acc=0.9403669724770642\n",
      "test: loss=0.23967113301192305 acc=0.9105504587155964\n",
      "EPOCH=2500\n",
      "train: loss=0.1851222113615513 acc=0.9403669724770642\n",
      "test: loss=0.2728545267850792 acc=0.9174311926605505\n",
      "EPOCH=2501\n",
      "train: loss=0.14982479310367625 acc=0.963302752293578\n",
      "test: loss=0.3092838081821175 acc=0.9059633027522935\n",
      "EPOCH=2502\n",
      "train: loss=0.09111511439770478 acc=0.9701834862385321\n",
      "test: loss=0.31408483463629305 acc=0.9105504587155964\n",
      "EPOCH=2503\n",
      "train: loss=0.15480799024733963 acc=0.9541284403669725\n",
      "test: loss=0.3135530214364749 acc=0.9105504587155964\n",
      "EPOCH=2504\n",
      "train: loss=0.05251920512587138 acc=0.9793577981651376\n",
      "test: loss=0.2302488407395765 acc=0.9151376146788991\n",
      "EPOCH=2505\n",
      "train: loss=0.1655270343544057 acc=0.9518348623853211\n",
      "test: loss=0.2100628417735258 acc=0.9357798165137615\n",
      "EPOCH=2506\n",
      "train: loss=0.21625246021105773 acc=0.9426605504587156\n",
      "test: loss=0.32757971216852577 acc=0.9059633027522935\n",
      "EPOCH=2507\n",
      "train: loss=0.1059858374673567 acc=0.9724770642201835\n",
      "test: loss=0.25325037522050003 acc=0.9128440366972477\n",
      "EPOCH=2508\n",
      "train: loss=0.25002703453953057 acc=0.9380733944954128\n",
      "test: loss=0.3099251139025526 acc=0.9151376146788991\n",
      "EPOCH=2509\n",
      "train: loss=0.24701722703716364 acc=0.9426605504587156\n",
      "test: loss=0.29433658602631146 acc=0.9174311926605505\n",
      "EPOCH=2510\n",
      "train: loss=0.06716719200020868 acc=0.9770642201834863\n",
      "test: loss=0.35605047207728024 acc=0.8967889908256881\n",
      "EPOCH=2511\n",
      "train: loss=0.18517779891996702 acc=0.9357798165137615\n",
      "test: loss=0.27761580659868884 acc=0.9174311926605505\n",
      "EPOCH=2512\n",
      "train: loss=0.20944257410455627 acc=0.9495412844036697\n",
      "test: loss=0.3427293371431164 acc=0.9128440366972477\n",
      "EPOCH=2513\n",
      "train: loss=0.3094314543220929 acc=0.9128440366972477\n",
      "test: loss=0.2952539745263833 acc=0.9059633027522935\n",
      "EPOCH=2514\n",
      "train: loss=0.15723878482482254 acc=0.9380733944954128\n",
      "test: loss=0.2735429366374275 acc=0.926605504587156\n",
      "EPOCH=2515\n",
      "train: loss=0.11848492042307267 acc=0.9724770642201835\n",
      "test: loss=0.22561016415329482 acc=0.9220183486238532\n",
      "EPOCH=2516\n",
      "train: loss=0.2594216193225168 acc=0.9311926605504587\n",
      "test: loss=0.3449574040117086 acc=0.8990825688073395\n",
      "EPOCH=2517\n",
      "train: loss=0.14938837339794744 acc=0.944954128440367\n",
      "test: loss=0.2719965153133525 acc=0.9151376146788991\n",
      "EPOCH=2518\n",
      "train: loss=0.12046408013079572 acc=0.9678899082568807\n",
      "test: loss=0.27501082035871227 acc=0.9197247706422018\n",
      "EPOCH=2519\n",
      "train: loss=0.21916975573446143 acc=0.944954128440367\n",
      "test: loss=0.2781760775746794 acc=0.926605504587156\n",
      "EPOCH=2520\n",
      "train: loss=0.11898284491027623 acc=0.9655963302752294\n",
      "test: loss=0.2753363875244954 acc=0.9220183486238532\n",
      "EPOCH=2521\n",
      "train: loss=0.08432684295237561 acc=0.9701834862385321\n",
      "test: loss=0.3072968960162607 acc=0.9151376146788991\n",
      "EPOCH=2522\n",
      "train: loss=0.3930529564654087 acc=0.9013761467889908\n",
      "test: loss=0.25351221290346804 acc=0.9220183486238532\n",
      "EPOCH=2523\n",
      "train: loss=0.17808283599425467 acc=0.9518348623853211\n",
      "test: loss=0.2589058360860635 acc=0.9197247706422018\n",
      "EPOCH=2524\n",
      "train: loss=0.23863375387539273 acc=0.9288990825688074\n",
      "test: loss=0.3060049472778148 acc=0.9036697247706422\n",
      "EPOCH=2525\n",
      "train: loss=0.23516108817519565 acc=0.9403669724770642\n",
      "test: loss=0.320664114705246 acc=0.908256880733945\n",
      "EPOCH=2526\n",
      "train: loss=0.14679839305431416 acc=0.9541284403669725\n",
      "test: loss=0.3110298182506614 acc=0.9059633027522935\n",
      "EPOCH=2527\n",
      "train: loss=0.09982390621374745 acc=0.9610091743119266\n",
      "test: loss=0.3029676072155349 acc=0.9151376146788991\n",
      "EPOCH=2528\n",
      "train: loss=0.0774516467361404 acc=0.9793577981651376\n",
      "test: loss=0.26370059402670554 acc=0.9220183486238532\n",
      "EPOCH=2529\n",
      "train: loss=0.25278646858095727 acc=0.9357798165137615\n",
      "test: loss=0.2695882067863119 acc=0.926605504587156\n",
      "EPOCH=2530\n",
      "train: loss=0.06116791331094018 acc=0.981651376146789\n",
      "test: loss=0.24172823868796645 acc=0.9151376146788991\n",
      "EPOCH=2531\n",
      "train: loss=0.24391998279404234 acc=0.9334862385321101\n",
      "test: loss=0.2484458468252982 acc=0.9197247706422018\n",
      "EPOCH=2532\n",
      "train: loss=0.2573290591460884 acc=0.9288990825688074\n",
      "test: loss=0.35598857656848615 acc=0.9128440366972477\n",
      "EPOCH=2533\n",
      "train: loss=0.13434620495533567 acc=0.9472477064220184\n",
      "test: loss=0.35220765880133664 acc=0.9036697247706422\n",
      "EPOCH=2534\n",
      "train: loss=0.09169623379426808 acc=0.9610091743119266\n",
      "test: loss=0.24294087926771585 acc=0.9174311926605505\n",
      "EPOCH=2535\n",
      "train: loss=0.12540847747522393 acc=0.9610091743119266\n",
      "test: loss=0.23550476455856878 acc=0.9243119266055045\n",
      "EPOCH=2536\n",
      "train: loss=0.13641978401432153 acc=0.9587155963302753\n",
      "test: loss=0.29590476560466217 acc=0.9243119266055045\n",
      "EPOCH=2537\n",
      "train: loss=0.2588981773890039 acc=0.9357798165137615\n",
      "test: loss=0.1903778995346417 acc=0.9380733944954128\n",
      "EPOCH=2538\n",
      "train: loss=0.12591619783786295 acc=0.9587155963302753\n",
      "test: loss=0.31354711883866193 acc=0.9059633027522935\n",
      "EPOCH=2539\n",
      "train: loss=0.07238638232332296 acc=0.9655963302752294\n",
      "test: loss=0.28638273409990295 acc=0.9151376146788991\n",
      "EPOCH=2540\n",
      "train: loss=0.05494359582965589 acc=0.981651376146789\n",
      "test: loss=0.4333423888263983 acc=0.8761467889908257\n",
      "EPOCH=2541\n",
      "train: loss=0.1625704395601449 acc=0.9357798165137615\n",
      "test: loss=0.302495770933789 acc=0.9174311926605505\n",
      "EPOCH=2542\n",
      "train: loss=0.20845446873681472 acc=0.9357798165137615\n",
      "test: loss=0.2410845764640184 acc=0.9220183486238532\n",
      "EPOCH=2543\n",
      "train: loss=0.18746149371659981 acc=0.9541284403669725\n",
      "test: loss=0.27207287579806966 acc=0.9128440366972477\n",
      "EPOCH=2544\n",
      "train: loss=0.16515632718580112 acc=0.9495412844036697\n",
      "test: loss=0.3304366775086467 acc=0.8967889908256881\n",
      "EPOCH=2545\n",
      "train: loss=0.1555396265009118 acc=0.9518348623853211\n",
      "test: loss=0.2908634245732999 acc=0.9013761467889908\n",
      "EPOCH=2546\n",
      "train: loss=0.0790817493047443 acc=0.9701834862385321\n",
      "test: loss=0.29632168291409344 acc=0.9243119266055045\n",
      "EPOCH=2547\n",
      "train: loss=0.24703147502359907 acc=0.9311926605504587\n",
      "test: loss=0.33170317590137605 acc=0.908256880733945\n",
      "EPOCH=2548\n",
      "train: loss=0.19722216207456625 acc=0.9334862385321101\n",
      "test: loss=0.3081671648381765 acc=0.9220183486238532\n",
      "EPOCH=2549\n",
      "train: loss=0.1613890144246963 acc=0.9403669724770642\n",
      "test: loss=0.233600529491626 acc=0.9197247706422018\n",
      "EPOCH=2550\n",
      "train: loss=0.18324754097774923 acc=0.9495412844036697\n",
      "test: loss=0.2368933517175755 acc=0.908256880733945\n",
      "EPOCH=2551\n",
      "train: loss=0.10459009357487238 acc=0.9403669724770642\n",
      "test: loss=0.2724410825439283 acc=0.9151376146788991\n",
      "EPOCH=2552\n",
      "train: loss=0.26489926103882205 acc=0.9311926605504587\n",
      "test: loss=0.24047942689022903 acc=0.9220183486238532\n",
      "EPOCH=2553\n",
      "train: loss=0.14794123109184892 acc=0.9472477064220184\n",
      "test: loss=0.3176407837157873 acc=0.9174311926605505\n",
      "EPOCH=2554\n",
      "train: loss=0.20054727455603547 acc=0.9564220183486238\n",
      "test: loss=0.3285721387243618 acc=0.9220183486238532\n",
      "EPOCH=2555\n",
      "train: loss=0.16982145217957278 acc=0.9518348623853211\n",
      "test: loss=0.2493408478079559 acc=0.9357798165137615\n",
      "EPOCH=2556\n",
      "train: loss=0.13841108418485934 acc=0.9564220183486238\n",
      "test: loss=0.37154442774464136 acc=0.908256880733945\n",
      "EPOCH=2557\n",
      "train: loss=0.12182599252943871 acc=0.9747706422018348\n",
      "test: loss=0.20006844726554107 acc=0.9334862385321101\n",
      "EPOCH=2558\n",
      "train: loss=0.33280255410832776 acc=0.9197247706422018\n",
      "test: loss=0.3197389580984463 acc=0.9105504587155964\n",
      "EPOCH=2559\n",
      "train: loss=0.15242467811259394 acc=0.9495412844036697\n",
      "test: loss=0.2941436610320253 acc=0.8990825688073395\n",
      "EPOCH=2560\n",
      "train: loss=0.13421234918364092 acc=0.9564220183486238\n",
      "test: loss=0.26816536055455154 acc=0.9220183486238532\n",
      "EPOCH=2561\n",
      "train: loss=0.14092101901295725 acc=0.944954128440367\n",
      "test: loss=0.2930790073261405 acc=0.9036697247706422\n",
      "EPOCH=2562\n",
      "train: loss=0.2897692269914865 acc=0.9541284403669725\n",
      "test: loss=0.3123263904345877 acc=0.908256880733945\n",
      "EPOCH=2563\n",
      "train: loss=0.08779574116518879 acc=0.963302752293578\n",
      "test: loss=0.28482124936045944 acc=0.9151376146788991\n",
      "EPOCH=2564\n",
      "train: loss=0.16278963412100075 acc=0.9518348623853211\n",
      "test: loss=0.2863442390453828 acc=0.9197247706422018\n",
      "EPOCH=2565\n",
      "train: loss=0.23719260535272557 acc=0.9380733944954128\n",
      "test: loss=0.3388565665544416 acc=0.8990825688073395\n",
      "EPOCH=2566\n",
      "train: loss=0.24316712614228272 acc=0.9472477064220184\n",
      "test: loss=0.2766892471142252 acc=0.9243119266055045\n",
      "EPOCH=2567\n",
      "train: loss=0.15253437885347806 acc=0.9541284403669725\n",
      "test: loss=0.24350358886156906 acc=0.9220183486238532\n",
      "EPOCH=2568\n",
      "train: loss=0.09223170768327138 acc=0.9770642201834863\n",
      "test: loss=0.27479226821133 acc=0.9197247706422018\n",
      "EPOCH=2569\n",
      "train: loss=0.11281603844186455 acc=0.9610091743119266\n",
      "test: loss=0.24671172648958975 acc=0.9197247706422018\n",
      "EPOCH=2570\n",
      "train: loss=0.16468110657928395 acc=0.9541284403669725\n",
      "test: loss=0.2507909828430347 acc=0.9243119266055045\n",
      "EPOCH=2571\n",
      "train: loss=0.13276075524933706 acc=0.9610091743119266\n",
      "test: loss=0.28491849047592666 acc=0.9059633027522935\n",
      "EPOCH=2572\n",
      "train: loss=0.23637093225178246 acc=0.9311926605504587\n",
      "test: loss=0.38167403124215943 acc=0.9059633027522935\n",
      "EPOCH=2573\n",
      "train: loss=0.21740477306995407 acc=0.9495412844036697\n",
      "test: loss=0.3302677299416733 acc=0.9059633027522935\n",
      "EPOCH=2574\n",
      "train: loss=0.24666028066698736 acc=0.9357798165137615\n",
      "test: loss=0.3200254561025037 acc=0.908256880733945\n",
      "EPOCH=2575\n",
      "train: loss=0.1809019593104645 acc=0.9541284403669725\n",
      "test: loss=0.3354009017638659 acc=0.9013761467889908\n",
      "EPOCH=2576\n",
      "train: loss=0.10124433014989834 acc=0.9793577981651376\n",
      "test: loss=0.26118516054154334 acc=0.9174311926605505\n",
      "EPOCH=2577\n",
      "train: loss=0.15323489116193773 acc=0.9426605504587156\n",
      "test: loss=0.29997555363654677 acc=0.9059633027522935\n",
      "EPOCH=2578\n",
      "train: loss=0.22233524624756495 acc=0.9426605504587156\n",
      "test: loss=0.3152436169749603 acc=0.9197247706422018\n",
      "EPOCH=2579\n",
      "train: loss=0.2525302488140105 acc=0.9197247706422018\n",
      "test: loss=0.3057093590358541 acc=0.9105504587155964\n",
      "EPOCH=2580\n",
      "train: loss=0.30935599700739613 acc=0.9311926605504587\n",
      "test: loss=0.2758696028220633 acc=0.9311926605504587\n",
      "EPOCH=2581\n",
      "train: loss=0.10742825653290933 acc=0.9564220183486238\n",
      "test: loss=0.3010434019377571 acc=0.9059633027522935\n",
      "EPOCH=2582\n",
      "train: loss=0.13888950408661926 acc=0.9564220183486238\n",
      "test: loss=0.24112228218764517 acc=0.9311926605504587\n",
      "EPOCH=2583\n",
      "train: loss=0.22263749769201882 acc=0.9472477064220184\n",
      "test: loss=0.2860642543627706 acc=0.9197247706422018\n",
      "EPOCH=2584\n",
      "train: loss=0.13735003645420532 acc=0.9610091743119266\n",
      "test: loss=0.3345107858833138 acc=0.9105504587155964\n",
      "EPOCH=2585\n",
      "train: loss=0.10596286452563314 acc=0.9701834862385321\n",
      "test: loss=0.2618070561794342 acc=0.9243119266055045\n",
      "EPOCH=2586\n",
      "train: loss=0.2206036899854885 acc=0.9311926605504587\n",
      "test: loss=0.36151417870876884 acc=0.8967889908256881\n",
      "EPOCH=2587\n",
      "train: loss=0.10087477410204393 acc=0.9724770642201835\n",
      "test: loss=0.23506993299387713 acc=0.9334862385321101\n",
      "EPOCH=2588\n",
      "train: loss=0.20054113587400835 acc=0.926605504587156\n",
      "test: loss=0.2757969616367924 acc=0.9220183486238532\n",
      "EPOCH=2589\n",
      "train: loss=0.09449865502765424 acc=0.9701834862385321\n",
      "test: loss=0.305050749318322 acc=0.908256880733945\n",
      "EPOCH=2590\n",
      "train: loss=0.2049104217840524 acc=0.9174311926605505\n",
      "test: loss=0.29917340348107846 acc=0.9174311926605505\n",
      "EPOCH=2591\n",
      "train: loss=0.2487038510530943 acc=0.9220183486238532\n",
      "test: loss=0.2658904053820649 acc=0.926605504587156\n",
      "EPOCH=2592\n",
      "train: loss=0.127438795357744 acc=0.9541284403669725\n",
      "test: loss=0.299859725852777 acc=0.908256880733945\n",
      "EPOCH=2593\n",
      "train: loss=0.2846983649708274 acc=0.9357798165137615\n",
      "test: loss=0.23873609338158336 acc=0.9151376146788991\n",
      "EPOCH=2594\n",
      "train: loss=0.1466049012274145 acc=0.9541284403669725\n",
      "test: loss=0.26270705288987156 acc=0.908256880733945\n",
      "EPOCH=2595\n",
      "train: loss=0.16703938655897613 acc=0.9472477064220184\n",
      "test: loss=0.3254419581104453 acc=0.9128440366972477\n",
      "EPOCH=2596\n",
      "train: loss=0.22837025217914894 acc=0.9334862385321101\n",
      "test: loss=0.3178354604157596 acc=0.908256880733945\n",
      "EPOCH=2597\n",
      "train: loss=0.1070686903294276 acc=0.9724770642201835\n",
      "test: loss=0.31155580373348724 acc=0.9105504587155964\n",
      "EPOCH=2598\n",
      "train: loss=0.20215503505184867 acc=0.9288990825688074\n",
      "test: loss=0.3351873013277434 acc=0.908256880733945\n",
      "EPOCH=2599\n",
      "train: loss=0.14815861209420786 acc=0.9587155963302753\n",
      "test: loss=0.2591384057056333 acc=0.926605504587156\n",
      "EPOCH=2600\n",
      "train: loss=0.28005899446937654 acc=0.926605504587156\n",
      "test: loss=0.2607112459195829 acc=0.9243119266055045\n",
      "EPOCH=2601\n",
      "train: loss=0.2384324406263636 acc=0.9311926605504587\n",
      "test: loss=0.30342579786751467 acc=0.9105504587155964\n",
      "EPOCH=2602\n",
      "train: loss=0.22456113938935268 acc=0.9403669724770642\n",
      "test: loss=0.35969029744584297 acc=0.9013761467889908\n",
      "EPOCH=2603\n",
      "train: loss=0.2178502152040046 acc=0.9403669724770642\n",
      "test: loss=0.26300041708970523 acc=0.9243119266055045\n",
      "EPOCH=2604\n",
      "train: loss=0.2211859961151691 acc=0.9357798165137615\n",
      "test: loss=0.2663029670450202 acc=0.926605504587156\n",
      "EPOCH=2605\n",
      "train: loss=0.16270052535616694 acc=0.9541284403669725\n",
      "test: loss=0.3771883714656365 acc=0.9059633027522935\n",
      "EPOCH=2606\n",
      "train: loss=0.20935423710516085 acc=0.9357798165137615\n",
      "test: loss=0.28492788342036574 acc=0.9128440366972477\n",
      "EPOCH=2607\n",
      "train: loss=0.12792177767086643 acc=0.944954128440367\n",
      "test: loss=0.40904717413783814 acc=0.8899082568807339\n",
      "EPOCH=2608\n",
      "train: loss=0.09686082017460312 acc=0.9610091743119266\n",
      "test: loss=0.2939277648910516 acc=0.9288990825688074\n",
      "EPOCH=2609\n",
      "train: loss=0.12179858623617836 acc=0.9610091743119266\n",
      "test: loss=0.4037901034124343 acc=0.8990825688073395\n",
      "EPOCH=2610\n",
      "train: loss=0.2599227101029208 acc=0.9472477064220184\n",
      "test: loss=0.3112707744998509 acc=0.9151376146788991\n",
      "EPOCH=2611\n",
      "train: loss=0.10775367986980333 acc=0.9701834862385321\n",
      "test: loss=0.2952775951147695 acc=0.926605504587156\n",
      "EPOCH=2612\n",
      "train: loss=0.21695803731975621 acc=0.9426605504587156\n",
      "test: loss=0.3335538131230125 acc=0.9128440366972477\n",
      "EPOCH=2613\n",
      "train: loss=0.07518379491028689 acc=0.9701834862385321\n",
      "test: loss=0.2933267288924316 acc=0.9197247706422018\n",
      "EPOCH=2614\n",
      "train: loss=0.2254645540854464 acc=0.9495412844036697\n",
      "test: loss=0.34472395287803037 acc=0.9059633027522935\n",
      "EPOCH=2615\n",
      "train: loss=0.22291556647723182 acc=0.9357798165137615\n",
      "test: loss=0.28514684268928886 acc=0.908256880733945\n",
      "EPOCH=2616\n",
      "train: loss=0.1430460118455533 acc=0.9541284403669725\n",
      "test: loss=0.2629770058510909 acc=0.9243119266055045\n",
      "EPOCH=2617\n",
      "train: loss=0.12443869574523493 acc=0.9655963302752294\n",
      "test: loss=0.30362109667707665 acc=0.9174311926605505\n",
      "EPOCH=2618\n",
      "train: loss=0.24276872059917629 acc=0.9311926605504587\n",
      "test: loss=0.28882590025470734 acc=0.9128440366972477\n",
      "EPOCH=2619\n",
      "train: loss=0.1812612040521445 acc=0.9357798165137615\n",
      "test: loss=0.3174295261224843 acc=0.9174311926605505\n",
      "EPOCH=2620\n",
      "train: loss=0.19465727468432725 acc=0.9472477064220184\n",
      "test: loss=0.2959408830791412 acc=0.9197247706422018\n",
      "EPOCH=2621\n",
      "train: loss=0.1050550431080693 acc=0.9701834862385321\n",
      "test: loss=0.29564756097315675 acc=0.9128440366972477\n",
      "EPOCH=2622\n",
      "train: loss=0.17032503360598758 acc=0.9403669724770642\n",
      "test: loss=0.324597028992293 acc=0.9151376146788991\n",
      "EPOCH=2623\n",
      "train: loss=0.1625693183756517 acc=0.9587155963302753\n",
      "test: loss=0.31023261882359393 acc=0.9059633027522935\n",
      "EPOCH=2624\n",
      "train: loss=0.1328923677825485 acc=0.9610091743119266\n",
      "test: loss=0.26138849619859894 acc=0.926605504587156\n",
      "EPOCH=2625\n",
      "train: loss=0.13353425657685503 acc=0.9564220183486238\n",
      "test: loss=0.3298841503405959 acc=0.9036697247706422\n",
      "EPOCH=2626\n",
      "train: loss=0.1784736106761534 acc=0.9495412844036697\n",
      "test: loss=0.2352728965043595 acc=0.9380733944954128\n",
      "EPOCH=2627\n",
      "train: loss=0.15680335232549178 acc=0.9426605504587156\n",
      "test: loss=0.299235366611066 acc=0.9243119266055045\n",
      "EPOCH=2628\n",
      "train: loss=0.2511994448352616 acc=0.9380733944954128\n",
      "test: loss=0.2551395849963559 acc=0.908256880733945\n",
      "EPOCH=2629\n",
      "train: loss=0.149085834411026 acc=0.9495412844036697\n",
      "test: loss=0.39959413708787045 acc=0.9036697247706422\n",
      "EPOCH=2630\n",
      "train: loss=0.17690137064238448 acc=0.9426605504587156\n",
      "test: loss=0.2931227456525984 acc=0.9128440366972477\n",
      "EPOCH=2631\n",
      "train: loss=0.1624787703969479 acc=0.9518348623853211\n",
      "test: loss=0.3327861931504406 acc=0.9220183486238532\n",
      "EPOCH=2632\n",
      "train: loss=0.1432561465644042 acc=0.9587155963302753\n",
      "test: loss=0.30793118702959404 acc=0.9128440366972477\n",
      "EPOCH=2633\n",
      "train: loss=0.21445259607060868 acc=0.9357798165137615\n",
      "test: loss=0.2758255191707687 acc=0.9059633027522935\n",
      "EPOCH=2634\n",
      "train: loss=0.28797936630435034 acc=0.9243119266055045\n",
      "test: loss=0.35611353886082603 acc=0.9197247706422018\n",
      "EPOCH=2635\n",
      "train: loss=0.14648740442465302 acc=0.9541284403669725\n",
      "test: loss=0.30591188696365257 acc=0.9105504587155964\n",
      "EPOCH=2636\n",
      "train: loss=0.053858247198142514 acc=0.981651376146789\n",
      "test: loss=0.36186578375151546 acc=0.9013761467889908\n",
      "EPOCH=2637\n",
      "train: loss=0.19022424249972064 acc=0.9564220183486238\n",
      "test: loss=0.30139879851698365 acc=0.9059633027522935\n",
      "EPOCH=2638\n",
      "train: loss=0.22636484993090172 acc=0.9403669724770642\n",
      "test: loss=0.274000891676288 acc=0.9243119266055045\n",
      "EPOCH=2639\n",
      "train: loss=0.18809194457774567 acc=0.9518348623853211\n",
      "test: loss=0.2283057753273999 acc=0.9334862385321101\n",
      "EPOCH=2640\n",
      "train: loss=0.17277532560040904 acc=0.9495412844036697\n",
      "test: loss=0.36225542961658036 acc=0.8967889908256881\n",
      "EPOCH=2641\n",
      "train: loss=0.17648544657187767 acc=0.9564220183486238\n",
      "test: loss=0.3473005828614298 acc=0.9174311926605505\n",
      "EPOCH=2642\n",
      "train: loss=0.2555874568658679 acc=0.9197247706422018\n",
      "test: loss=0.2823565257039182 acc=0.9197247706422018\n",
      "EPOCH=2643\n",
      "train: loss=0.14378373279659798 acc=0.9610091743119266\n",
      "test: loss=0.2916114985422525 acc=0.9288990825688074\n",
      "EPOCH=2644\n",
      "train: loss=0.15127215936824817 acc=0.9472477064220184\n",
      "test: loss=0.29790880431965594 acc=0.9151376146788991\n",
      "EPOCH=2645\n",
      "train: loss=0.23073274948037228 acc=0.9334862385321101\n",
      "test: loss=0.2608520700803002 acc=0.9151376146788991\n",
      "EPOCH=2646\n",
      "train: loss=0.4323116266149971 acc=0.8967889908256881\n",
      "test: loss=0.32535758709009627 acc=0.9151376146788991\n",
      "EPOCH=2647\n",
      "train: loss=0.18146572581787657 acc=0.9403669724770642\n",
      "test: loss=0.31406977587658985 acc=0.9128440366972477\n",
      "EPOCH=2648\n",
      "train: loss=0.1874805117384589 acc=0.9403669724770642\n",
      "test: loss=0.3385522065412526 acc=0.9128440366972477\n",
      "EPOCH=2649\n",
      "train: loss=0.12634321687495328 acc=0.963302752293578\n",
      "test: loss=0.32020761829975664 acc=0.9036697247706422\n",
      "EPOCH=2650\n",
      "train: loss=0.18568891214936636 acc=0.9518348623853211\n",
      "test: loss=0.25090387349877274 acc=0.9220183486238532\n",
      "EPOCH=2651\n",
      "train: loss=0.19362590914782504 acc=0.944954128440367\n",
      "test: loss=0.3460073177832574 acc=0.9128440366972477\n",
      "EPOCH=2652\n",
      "train: loss=0.14255837256677004 acc=0.963302752293578\n",
      "test: loss=0.33821705237594996 acc=0.908256880733945\n",
      "EPOCH=2653\n",
      "train: loss=0.1754700323675471 acc=0.963302752293578\n",
      "test: loss=0.26902232858015795 acc=0.908256880733945\n",
      "EPOCH=2654\n",
      "train: loss=0.32820273356678975 acc=0.9243119266055045\n",
      "test: loss=0.3207309515437841 acc=0.9013761467889908\n",
      "EPOCH=2655\n",
      "train: loss=0.1230384527784201 acc=0.9541284403669725\n",
      "test: loss=0.3428660600926472 acc=0.9036697247706422\n",
      "EPOCH=2656\n",
      "train: loss=0.23033042558430059 acc=0.9403669724770642\n",
      "test: loss=0.22079171445493728 acc=0.926605504587156\n",
      "EPOCH=2657\n",
      "train: loss=0.14884650088031826 acc=0.9518348623853211\n",
      "test: loss=0.31070997560535546 acc=0.9105504587155964\n",
      "EPOCH=2658\n",
      "train: loss=0.14035893272753128 acc=0.963302752293578\n",
      "test: loss=0.28630057368550216 acc=0.9220183486238532\n",
      "EPOCH=2659\n",
      "train: loss=0.12177111524549383 acc=0.9587155963302753\n",
      "test: loss=0.39908181675640236 acc=0.8922018348623854\n",
      "EPOCH=2660\n",
      "train: loss=0.1448226682677099 acc=0.9518348623853211\n",
      "test: loss=0.26049591566139335 acc=0.9151376146788991\n",
      "EPOCH=2661\n",
      "train: loss=0.11730184281850764 acc=0.9678899082568807\n",
      "test: loss=0.2876653993801906 acc=0.9151376146788991\n",
      "EPOCH=2662\n",
      "train: loss=0.12772957511853728 acc=0.963302752293578\n",
      "test: loss=0.362325950726456 acc=0.9059633027522935\n",
      "EPOCH=2663\n",
      "train: loss=0.08714948405330353 acc=0.9678899082568807\n",
      "test: loss=0.24426589360660977 acc=0.9357798165137615\n",
      "EPOCH=2664\n",
      "train: loss=0.18616830809918788 acc=0.9610091743119266\n",
      "test: loss=0.37280068155678014 acc=0.9105504587155964\n",
      "EPOCH=2665\n",
      "train: loss=0.086959538879909 acc=0.9678899082568807\n",
      "test: loss=0.2528091658736695 acc=0.926605504587156\n",
      "EPOCH=2666\n",
      "train: loss=0.3076249812874357 acc=0.9357798165137615\n",
      "test: loss=0.2623773350682389 acc=0.926605504587156\n",
      "EPOCH=2667\n",
      "train: loss=0.19175939286909366 acc=0.9472477064220184\n",
      "test: loss=0.2958612174437785 acc=0.926605504587156\n",
      "EPOCH=2668\n",
      "train: loss=0.18855013446187888 acc=0.944954128440367\n",
      "test: loss=0.19637508297480327 acc=0.9288990825688074\n",
      "EPOCH=2669\n",
      "train: loss=0.10346173679206504 acc=0.963302752293578\n",
      "test: loss=0.2860664835756781 acc=0.9174311926605505\n",
      "EPOCH=2670\n",
      "train: loss=0.21185993876188064 acc=0.9380733944954128\n",
      "test: loss=0.27398993807718824 acc=0.9105504587155964\n",
      "EPOCH=2671\n",
      "train: loss=0.17647913241193094 acc=0.9380733944954128\n",
      "test: loss=0.3205635180464572 acc=0.9105504587155964\n",
      "EPOCH=2672\n",
      "train: loss=0.17057970114390467 acc=0.9426605504587156\n",
      "test: loss=0.32749976593438207 acc=0.908256880733945\n",
      "EPOCH=2673\n",
      "train: loss=0.15431043006722428 acc=0.9495412844036697\n",
      "test: loss=0.3060536892569831 acc=0.9243119266055045\n",
      "EPOCH=2674\n",
      "train: loss=0.10884425691522084 acc=0.9678899082568807\n",
      "test: loss=0.20968024499949803 acc=0.9288990825688074\n",
      "EPOCH=2675\n",
      "train: loss=0.14514392827144956 acc=0.9610091743119266\n",
      "test: loss=0.3145702475295085 acc=0.9220183486238532\n",
      "EPOCH=2676\n",
      "train: loss=0.0774945977420201 acc=0.9655963302752294\n",
      "test: loss=0.32614380788738884 acc=0.9128440366972477\n",
      "EPOCH=2677\n",
      "train: loss=0.23942731877014098 acc=0.9334862385321101\n",
      "test: loss=0.28134135008954003 acc=0.9220183486238532\n",
      "EPOCH=2678\n",
      "train: loss=0.14839802441498956 acc=0.9610091743119266\n",
      "test: loss=0.23523625227089323 acc=0.9243119266055045\n",
      "EPOCH=2679\n",
      "train: loss=0.08910352766330917 acc=0.9701834862385321\n",
      "test: loss=0.29066225622955194 acc=0.908256880733945\n",
      "EPOCH=2680\n",
      "train: loss=0.16662281292835565 acc=0.9587155963302753\n",
      "test: loss=0.2847629715852716 acc=0.9105504587155964\n",
      "EPOCH=2681\n",
      "train: loss=0.1503211186028864 acc=0.963302752293578\n",
      "test: loss=0.27845204410117175 acc=0.926605504587156\n",
      "EPOCH=2682\n",
      "train: loss=0.26332340781593716 acc=0.926605504587156\n",
      "test: loss=0.3772579886738969 acc=0.8944954128440367\n",
      "EPOCH=2683\n",
      "train: loss=0.17858696613869 acc=0.9518348623853211\n",
      "test: loss=0.2584005638744488 acc=0.926605504587156\n",
      "EPOCH=2684\n",
      "train: loss=0.13827282914706415 acc=0.9701834862385321\n",
      "test: loss=0.3321182087264662 acc=0.908256880733945\n",
      "EPOCH=2685\n",
      "train: loss=0.25991527541335385 acc=0.9197247706422018\n",
      "test: loss=0.3200550338198231 acc=0.8990825688073395\n",
      "EPOCH=2686\n",
      "train: loss=0.14599439164927316 acc=0.9472477064220184\n",
      "test: loss=0.2275453991285767 acc=0.9334862385321101\n",
      "EPOCH=2687\n",
      "train: loss=0.13707893598121887 acc=0.9472477064220184\n",
      "test: loss=0.2388025481003642 acc=0.926605504587156\n",
      "EPOCH=2688\n",
      "train: loss=0.074731109271846 acc=0.9770642201834863\n",
      "test: loss=0.31251877478461537 acc=0.9151376146788991\n",
      "EPOCH=2689\n",
      "train: loss=0.2815815928742427 acc=0.9220183486238532\n",
      "test: loss=0.31431928735195297 acc=0.9128440366972477\n",
      "EPOCH=2690\n",
      "train: loss=0.18785130901638844 acc=0.9518348623853211\n",
      "test: loss=0.26063827234940806 acc=0.926605504587156\n",
      "EPOCH=2691\n",
      "train: loss=0.10088387996958424 acc=0.963302752293578\n",
      "test: loss=0.25962126531776736 acc=0.9174311926605505\n",
      "EPOCH=2692\n",
      "train: loss=0.19465569895680182 acc=0.9518348623853211\n",
      "test: loss=0.3011244777376798 acc=0.9174311926605505\n",
      "EPOCH=2693\n",
      "train: loss=0.1418484124453009 acc=0.9403669724770642\n",
      "test: loss=0.31876185287924136 acc=0.9151376146788991\n",
      "EPOCH=2694\n",
      "train: loss=0.2475272235624275 acc=0.9403669724770642\n",
      "test: loss=0.3114945832610351 acc=0.9105504587155964\n",
      "EPOCH=2695\n",
      "train: loss=0.08816930395895188 acc=0.9862385321100917\n",
      "test: loss=0.3169239177674897 acc=0.908256880733945\n",
      "EPOCH=2696\n",
      "train: loss=0.14191663502018942 acc=0.9564220183486238\n",
      "test: loss=0.3642391203537294 acc=0.9059633027522935\n",
      "EPOCH=2697\n",
      "train: loss=0.2647345640517394 acc=0.9380733944954128\n",
      "test: loss=0.21600384800729774 acc=0.926605504587156\n",
      "EPOCH=2698\n",
      "train: loss=0.15891032654575785 acc=0.963302752293578\n",
      "test: loss=0.28203438347114157 acc=0.9220183486238532\n",
      "EPOCH=2699\n",
      "train: loss=0.1593184644503399 acc=0.9403669724770642\n",
      "test: loss=0.2922596845391047 acc=0.9197247706422018\n",
      "EPOCH=2700\n",
      "train: loss=0.11892396881577173 acc=0.9678899082568807\n",
      "test: loss=0.3222520348676484 acc=0.9105504587155964\n",
      "EPOCH=2701\n",
      "train: loss=0.14743907181074864 acc=0.9357798165137615\n",
      "test: loss=0.3512318418305824 acc=0.9059633027522935\n",
      "EPOCH=2702\n",
      "train: loss=0.07939984728323882 acc=0.9655963302752294\n",
      "test: loss=0.3044228789743048 acc=0.9105504587155964\n",
      "EPOCH=2703\n",
      "train: loss=0.21616867109043636 acc=0.9311926605504587\n",
      "test: loss=0.384780453184402 acc=0.8990825688073395\n",
      "EPOCH=2704\n",
      "train: loss=0.19445219997697327 acc=0.9380733944954128\n",
      "test: loss=0.34751423582704327 acc=0.9105504587155964\n",
      "EPOCH=2705\n",
      "train: loss=0.21204678295767013 acc=0.9564220183486238\n",
      "test: loss=0.29660446008286556 acc=0.9174311926605505\n",
      "EPOCH=2706\n",
      "train: loss=0.15737370711745952 acc=0.9701834862385321\n",
      "test: loss=0.28906387195765937 acc=0.9174311926605505\n",
      "EPOCH=2707\n",
      "train: loss=0.21430846281307317 acc=0.9426605504587156\n",
      "test: loss=0.2850858342433866 acc=0.9105504587155964\n",
      "EPOCH=2708\n",
      "train: loss=0.17869671893242234 acc=0.9518348623853211\n",
      "test: loss=0.3098352976218727 acc=0.908256880733945\n",
      "EPOCH=2709\n",
      "train: loss=0.2285468738607108 acc=0.9518348623853211\n",
      "test: loss=0.29581491659068826 acc=0.926605504587156\n",
      "EPOCH=2710\n",
      "train: loss=0.26377264758414776 acc=0.9311926605504587\n",
      "test: loss=0.35864031237263044 acc=0.9174311926605505\n",
      "EPOCH=2711\n",
      "train: loss=0.19083053286112042 acc=0.9587155963302753\n",
      "test: loss=0.2957538065675222 acc=0.9105504587155964\n",
      "EPOCH=2712\n",
      "train: loss=0.1572364405911866 acc=0.9655963302752294\n",
      "test: loss=0.34111698849725614 acc=0.8990825688073395\n",
      "EPOCH=2713\n",
      "train: loss=0.14284871012891903 acc=0.9564220183486238\n",
      "test: loss=0.31518487549841434 acc=0.8990825688073395\n",
      "EPOCH=2714\n",
      "train: loss=0.08758478284525616 acc=0.9747706422018348\n",
      "test: loss=0.3597549429877336 acc=0.9036697247706422\n",
      "EPOCH=2715\n",
      "train: loss=0.3049914755023157 acc=0.9220183486238532\n",
      "test: loss=0.24713243707210078 acc=0.9288990825688074\n",
      "EPOCH=2716\n",
      "train: loss=0.05684428917514568 acc=0.9747706422018348\n",
      "test: loss=0.2801934567264107 acc=0.9174311926605505\n",
      "EPOCH=2717\n",
      "train: loss=0.2060499326505356 acc=0.9380733944954128\n",
      "test: loss=0.3183627022801392 acc=0.9197247706422018\n",
      "EPOCH=2718\n",
      "train: loss=0.07990398132381084 acc=0.9770642201834863\n",
      "test: loss=0.31590160564292513 acc=0.9059633027522935\n",
      "EPOCH=2719\n",
      "train: loss=0.21811113353844458 acc=0.9564220183486238\n",
      "test: loss=0.3324532780484063 acc=0.8990825688073395\n",
      "EPOCH=2720\n",
      "train: loss=0.2698104122434267 acc=0.9220183486238532\n",
      "test: loss=0.2961341079152447 acc=0.9105504587155964\n",
      "EPOCH=2721\n",
      "train: loss=0.11203648129742962 acc=0.9564220183486238\n",
      "test: loss=0.38822296568740783 acc=0.9059633027522935\n",
      "EPOCH=2722\n",
      "train: loss=0.22206516355839703 acc=0.944954128440367\n",
      "test: loss=0.2709416855824679 acc=0.9105504587155964\n",
      "EPOCH=2723\n",
      "train: loss=0.1099211297886216 acc=0.9678899082568807\n",
      "test: loss=0.25397351119186534 acc=0.9197247706422018\n",
      "EPOCH=2724\n",
      "train: loss=0.1509633722710597 acc=0.9587155963302753\n",
      "test: loss=0.271274715290371 acc=0.9151376146788991\n",
      "EPOCH=2725\n",
      "train: loss=0.15802204528226133 acc=0.9518348623853211\n",
      "test: loss=0.3663455733457757 acc=0.908256880733945\n",
      "EPOCH=2726\n",
      "train: loss=0.1288384830942559 acc=0.963302752293578\n",
      "test: loss=0.26522509760319907 acc=0.9174311926605505\n",
      "EPOCH=2727\n",
      "train: loss=0.14870566904908808 acc=0.9541284403669725\n",
      "test: loss=0.22756413995852506 acc=0.9311926605504587\n",
      "EPOCH=2728\n",
      "train: loss=0.24349075407951581 acc=0.9220183486238532\n",
      "test: loss=0.29067218457540633 acc=0.9105504587155964\n",
      "EPOCH=2729\n",
      "train: loss=0.10379349390881552 acc=0.9655963302752294\n",
      "test: loss=0.33704030431694276 acc=0.9013761467889908\n",
      "EPOCH=2730\n",
      "train: loss=0.1093737743195497 acc=0.9655963302752294\n",
      "test: loss=0.3093746720817445 acc=0.9036697247706422\n",
      "EPOCH=2731\n",
      "train: loss=0.1793395023047506 acc=0.9518348623853211\n",
      "test: loss=0.31483482319262385 acc=0.9128440366972477\n",
      "EPOCH=2732\n",
      "train: loss=0.0822489750092099 acc=0.9701834862385321\n",
      "test: loss=0.2661448977615383 acc=0.926605504587156\n",
      "EPOCH=2733\n",
      "train: loss=0.12500384784927945 acc=0.9770642201834863\n",
      "test: loss=0.3408637416222454 acc=0.9151376146788991\n",
      "EPOCH=2734\n",
      "train: loss=0.1635139738791764 acc=0.944954128440367\n",
      "test: loss=0.34734680557303 acc=0.908256880733945\n",
      "EPOCH=2735\n",
      "train: loss=0.1908044149705991 acc=0.9357798165137615\n",
      "test: loss=0.3333602826760917 acc=0.9105504587155964\n",
      "EPOCH=2736\n",
      "train: loss=0.20858719642686535 acc=0.9518348623853211\n",
      "test: loss=0.29023016965003406 acc=0.9105504587155964\n",
      "EPOCH=2737\n",
      "train: loss=0.16665661942998572 acc=0.944954128440367\n",
      "test: loss=0.3190303938252616 acc=0.9128440366972477\n",
      "EPOCH=2738\n",
      "train: loss=0.1080577599201491 acc=0.9655963302752294\n",
      "test: loss=0.33699942388596166 acc=0.9105504587155964\n",
      "EPOCH=2739\n",
      "train: loss=0.26074168691063954 acc=0.9426605504587156\n",
      "test: loss=0.3863018812506782 acc=0.9036697247706422\n",
      "EPOCH=2740\n",
      "train: loss=0.08215792589461096 acc=0.9793577981651376\n",
      "test: loss=0.3329719270605145 acc=0.9013761467889908\n",
      "EPOCH=2741\n",
      "train: loss=0.04094265359604677 acc=0.9839449541284404\n",
      "test: loss=0.2972983066193587 acc=0.9128440366972477\n",
      "EPOCH=2742\n",
      "train: loss=0.1280231233386271 acc=0.9678899082568807\n",
      "test: loss=0.21320513598018262 acc=0.9243119266055045\n",
      "EPOCH=2743\n",
      "train: loss=0.1994523213576901 acc=0.9380733944954128\n",
      "test: loss=0.45549150212581424 acc=0.8944954128440367\n",
      "EPOCH=2744\n",
      "train: loss=0.16139504254210144 acc=0.9564220183486238\n",
      "test: loss=0.282451173937089 acc=0.9128440366972477\n",
      "EPOCH=2745\n",
      "train: loss=0.21544141551922927 acc=0.9380733944954128\n",
      "test: loss=0.29864190199216495 acc=0.9197247706422018\n",
      "EPOCH=2746\n",
      "train: loss=0.10254493639727769 acc=0.9701834862385321\n",
      "test: loss=0.26518086841771243 acc=0.926605504587156\n",
      "EPOCH=2747\n",
      "train: loss=0.0839804378247891 acc=0.9747706422018348\n",
      "test: loss=0.2683437576672645 acc=0.9197247706422018\n",
      "EPOCH=2748\n",
      "train: loss=0.2401606570145852 acc=0.9472477064220184\n",
      "test: loss=0.30988390075336686 acc=0.9105504587155964\n",
      "EPOCH=2749\n",
      "train: loss=0.22743411246795767 acc=0.9357798165137615\n",
      "test: loss=0.3286461278007113 acc=0.9174311926605505\n",
      "EPOCH=2750\n",
      "train: loss=0.10112046741247467 acc=0.9770642201834863\n",
      "test: loss=0.35330127817227264 acc=0.9105504587155964\n",
      "EPOCH=2751\n",
      "train: loss=0.14709466090280493 acc=0.9380733944954128\n",
      "test: loss=0.29077663305646734 acc=0.9174311926605505\n",
      "EPOCH=2752\n",
      "train: loss=0.14377025517286038 acc=0.9724770642201835\n",
      "test: loss=0.26591448103825105 acc=0.9151376146788991\n",
      "EPOCH=2753\n",
      "train: loss=0.13588477452964032 acc=0.9541284403669725\n",
      "test: loss=0.301141824787635 acc=0.9197247706422018\n",
      "EPOCH=2754\n",
      "train: loss=0.146653129931561 acc=0.9541284403669725\n",
      "test: loss=0.28955950481042353 acc=0.9128440366972477\n",
      "EPOCH=2755\n",
      "train: loss=0.10241571972719316 acc=0.9655963302752294\n",
      "test: loss=0.31890518224216335 acc=0.9036697247706422\n",
      "EPOCH=2756\n",
      "train: loss=0.21780855272052496 acc=0.9472477064220184\n",
      "test: loss=0.24021408960700127 acc=0.9197247706422018\n",
      "EPOCH=2757\n",
      "train: loss=0.17844057450091536 acc=0.9518348623853211\n",
      "test: loss=0.37680280705410063 acc=0.8967889908256881\n",
      "EPOCH=2758\n",
      "train: loss=0.11443899030629635 acc=0.9518348623853211\n",
      "test: loss=0.2500172213349094 acc=0.9311926605504587\n",
      "EPOCH=2759\n",
      "train: loss=0.17065358180992451 acc=0.9426605504587156\n",
      "test: loss=0.2472965942202951 acc=0.9220183486238532\n",
      "EPOCH=2760\n",
      "train: loss=0.14097229842738374 acc=0.9541284403669725\n",
      "test: loss=0.2650788119340191 acc=0.926605504587156\n",
      "EPOCH=2761\n",
      "train: loss=0.10303364401074047 acc=0.9724770642201835\n",
      "test: loss=0.2655762361373951 acc=0.9174311926605505\n",
      "EPOCH=2762\n",
      "train: loss=0.1706248432240742 acc=0.9541284403669725\n",
      "test: loss=0.3228479342402272 acc=0.9036697247706422\n",
      "EPOCH=2763\n",
      "train: loss=0.12509446704504534 acc=0.9587155963302753\n",
      "test: loss=0.32274750055585516 acc=0.9036697247706422\n",
      "EPOCH=2764\n",
      "train: loss=0.12483657811538344 acc=0.9541284403669725\n",
      "test: loss=0.26182844698773494 acc=0.9105504587155964\n",
      "EPOCH=2765\n",
      "train: loss=0.20053937564798904 acc=0.9357798165137615\n",
      "test: loss=0.3679506676106931 acc=0.8990825688073395\n",
      "EPOCH=2766\n",
      "train: loss=0.35150898805458247 acc=0.926605504587156\n",
      "test: loss=0.34505047844101755 acc=0.9128440366972477\n",
      "EPOCH=2767\n",
      "train: loss=0.1555298669964079 acc=0.9472477064220184\n",
      "test: loss=0.27709052262326916 acc=0.9311926605504587\n",
      "EPOCH=2768\n",
      "train: loss=0.17146569209041337 acc=0.944954128440367\n",
      "test: loss=0.3136250753117156 acc=0.9151376146788991\n",
      "EPOCH=2769\n",
      "train: loss=0.18433818915313643 acc=0.9380733944954128\n",
      "test: loss=0.379049949555898 acc=0.8967889908256881\n",
      "EPOCH=2770\n",
      "train: loss=0.22593302504772522 acc=0.944954128440367\n",
      "test: loss=0.3272998437723165 acc=0.908256880733945\n",
      "EPOCH=2771\n",
      "train: loss=0.0990882441808453 acc=0.963302752293578\n",
      "test: loss=0.2841264111863397 acc=0.9197247706422018\n",
      "EPOCH=2772\n",
      "train: loss=0.37328806628941036 acc=0.9128440366972477\n",
      "test: loss=0.34547015006813947 acc=0.9036697247706422\n",
      "EPOCH=2773\n",
      "train: loss=0.23945871953061723 acc=0.9426605504587156\n",
      "test: loss=0.3004419399991014 acc=0.9197247706422018\n",
      "EPOCH=2774\n",
      "train: loss=0.14651350211009484 acc=0.9541284403669725\n",
      "test: loss=0.3772566244763581 acc=0.9105504587155964\n",
      "EPOCH=2775\n",
      "train: loss=0.061203825885867376 acc=0.9747706422018348\n",
      "test: loss=0.3500420291643905 acc=0.9036697247706422\n",
      "EPOCH=2776\n",
      "train: loss=0.18681408382362855 acc=0.9357798165137615\n",
      "test: loss=0.3975163698307511 acc=0.8899082568807339\n",
      "EPOCH=2777\n",
      "train: loss=0.19673442140250552 acc=0.926605504587156\n",
      "test: loss=0.32686835268161274 acc=0.9059633027522935\n",
      "EPOCH=2778\n",
      "train: loss=0.1640403855557277 acc=0.9564220183486238\n",
      "test: loss=0.31545016048654784 acc=0.9243119266055045\n",
      "EPOCH=2779\n",
      "train: loss=0.24927964757985988 acc=0.9174311926605505\n",
      "test: loss=0.33590262689278266 acc=0.9197247706422018\n",
      "EPOCH=2780\n",
      "train: loss=0.36064433032782256 acc=0.9311926605504587\n",
      "test: loss=0.343065455775837 acc=0.9013761467889908\n",
      "EPOCH=2781\n",
      "train: loss=0.06837496628024499 acc=0.9793577981651376\n",
      "test: loss=0.30494744960921544 acc=0.9311926605504587\n",
      "EPOCH=2782\n",
      "train: loss=0.13286679037828394 acc=0.9678899082568807\n",
      "test: loss=0.24025126856899365 acc=0.926605504587156\n",
      "EPOCH=2783\n",
      "train: loss=0.18115153313155702 acc=0.9564220183486238\n",
      "test: loss=0.2919169952020838 acc=0.9151376146788991\n",
      "EPOCH=2784\n",
      "train: loss=0.09014970144469166 acc=0.9747706422018348\n",
      "test: loss=0.32146175488825585 acc=0.9105504587155964\n",
      "EPOCH=2785\n",
      "train: loss=0.10219635108533653 acc=0.9770642201834863\n",
      "test: loss=0.277535487753222 acc=0.9105504587155964\n",
      "EPOCH=2786\n",
      "train: loss=0.24761065230946244 acc=0.9243119266055045\n",
      "test: loss=0.3546345099555419 acc=0.9105504587155964\n",
      "EPOCH=2787\n",
      "train: loss=0.1984944465856833 acc=0.9564220183486238\n",
      "test: loss=0.3082843127990137 acc=0.9059633027522935\n",
      "EPOCH=2788\n",
      "train: loss=0.18607246724345852 acc=0.9472477064220184\n",
      "test: loss=0.2448808446949791 acc=0.9380733944954128\n",
      "EPOCH=2789\n",
      "train: loss=0.08840107719923383 acc=0.9655963302752294\n",
      "test: loss=0.24253134603970528 acc=0.9220183486238532\n",
      "EPOCH=2790\n",
      "train: loss=0.19884200533300503 acc=0.9380733944954128\n",
      "test: loss=0.2621127874616156 acc=0.9220183486238532\n",
      "EPOCH=2791\n",
      "train: loss=0.13788270470384476 acc=0.9541284403669725\n",
      "test: loss=0.23174544629119045 acc=0.9036697247706422\n",
      "EPOCH=2792\n",
      "train: loss=0.1868763441341906 acc=0.944954128440367\n",
      "test: loss=0.32353352455962114 acc=0.9174311926605505\n",
      "EPOCH=2793\n",
      "train: loss=0.12368388095313489 acc=0.9587155963302753\n",
      "test: loss=0.23510899536964913 acc=0.9220183486238532\n",
      "EPOCH=2794\n",
      "train: loss=0.12612267878062655 acc=0.9472477064220184\n",
      "test: loss=0.4206900022381716 acc=0.9013761467889908\n",
      "EPOCH=2795\n",
      "train: loss=0.09115590463387041 acc=0.9678899082568807\n",
      "test: loss=0.30379841871664015 acc=0.9128440366972477\n",
      "EPOCH=2796\n",
      "train: loss=0.1910236238927461 acc=0.963302752293578\n",
      "test: loss=0.2551774118640875 acc=0.9151376146788991\n",
      "EPOCH=2797\n",
      "train: loss=0.2636617213242198 acc=0.9357798165137615\n",
      "test: loss=0.28876938992399814 acc=0.908256880733945\n",
      "EPOCH=2798\n",
      "train: loss=0.15154130315981684 acc=0.9426605504587156\n",
      "test: loss=0.2704324199762962 acc=0.9220183486238532\n",
      "EPOCH=2799\n",
      "train: loss=0.14197160104985987 acc=0.9770642201834863\n",
      "test: loss=0.3622531370098134 acc=0.9151376146788991\n",
      "EPOCH=2800\n",
      "train: loss=0.1459192612567747 acc=0.9655963302752294\n",
      "test: loss=0.39268244575325073 acc=0.9036697247706422\n",
      "EPOCH=2801\n",
      "train: loss=0.22546591044612294 acc=0.9288990825688074\n",
      "test: loss=0.2219800721994598 acc=0.9243119266055045\n",
      "EPOCH=2802\n",
      "train: loss=0.31528238799564395 acc=0.9403669724770642\n",
      "test: loss=0.32814767944224643 acc=0.9151376146788991\n",
      "EPOCH=2803\n",
      "train: loss=0.12679495671852062 acc=0.963302752293578\n",
      "test: loss=0.30832093987171183 acc=0.9151376146788991\n",
      "EPOCH=2804\n",
      "train: loss=0.16131703429101238 acc=0.9541284403669725\n",
      "test: loss=0.26081623124548126 acc=0.9059633027522935\n",
      "EPOCH=2805\n",
      "train: loss=0.19410939225171212 acc=0.9403669724770642\n",
      "test: loss=0.2785437178077868 acc=0.9059633027522935\n",
      "EPOCH=2806\n",
      "train: loss=0.19398124165895866 acc=0.9541284403669725\n",
      "test: loss=0.2855317062806008 acc=0.908256880733945\n",
      "EPOCH=2807\n",
      "train: loss=0.3017506997084183 acc=0.9220183486238532\n",
      "test: loss=0.26660021268856826 acc=0.9243119266055045\n",
      "EPOCH=2808\n",
      "train: loss=0.09465106456622495 acc=0.9678899082568807\n",
      "test: loss=0.2686245611443215 acc=0.9220183486238532\n",
      "EPOCH=2809\n",
      "train: loss=0.1299428072072328 acc=0.9564220183486238\n",
      "test: loss=0.35554497708359023 acc=0.9059633027522935\n",
      "EPOCH=2810\n",
      "train: loss=0.1497125524235721 acc=0.9564220183486238\n",
      "test: loss=0.37914644508505674 acc=0.9151376146788991\n",
      "EPOCH=2811\n",
      "train: loss=0.1504233244051078 acc=0.9564220183486238\n",
      "test: loss=0.29384227433306576 acc=0.908256880733945\n",
      "EPOCH=2812\n",
      "train: loss=0.1774959154320847 acc=0.9403669724770642\n",
      "test: loss=0.2925065254205581 acc=0.9197247706422018\n",
      "EPOCH=2813\n",
      "train: loss=0.12162261585273611 acc=0.9587155963302753\n",
      "test: loss=0.28893860444783875 acc=0.9174311926605505\n",
      "EPOCH=2814\n",
      "train: loss=0.1465279250531849 acc=0.9541284403669725\n",
      "test: loss=0.3284236267930533 acc=0.908256880733945\n",
      "EPOCH=2815\n",
      "train: loss=0.06301658042656216 acc=0.9678899082568807\n",
      "test: loss=0.32089268334825716 acc=0.9059633027522935\n",
      "EPOCH=2816\n",
      "train: loss=0.14590010073294718 acc=0.9495412844036697\n",
      "test: loss=0.3518557956540294 acc=0.9105504587155964\n",
      "EPOCH=2817\n",
      "train: loss=0.18838294561392577 acc=0.9518348623853211\n",
      "test: loss=0.24831506164584255 acc=0.9174311926605505\n",
      "EPOCH=2818\n",
      "train: loss=0.07948635966786341 acc=0.9770642201834863\n",
      "test: loss=0.29894049323443894 acc=0.9197247706422018\n",
      "EPOCH=2819\n",
      "train: loss=0.24829374003063345 acc=0.9518348623853211\n",
      "test: loss=0.443040169831139 acc=0.8761467889908257\n",
      "EPOCH=2820\n",
      "train: loss=0.26028935703756534 acc=0.926605504587156\n",
      "test: loss=0.2325232720819367 acc=0.9288990825688074\n",
      "EPOCH=2821\n",
      "train: loss=0.1299881979928015 acc=0.9541284403669725\n",
      "test: loss=0.39043184335267384 acc=0.8990825688073395\n",
      "EPOCH=2822\n",
      "train: loss=0.20910214548481093 acc=0.9403669724770642\n",
      "test: loss=0.40548730585934284 acc=0.8990825688073395\n",
      "EPOCH=2823\n",
      "train: loss=0.10198482477965375 acc=0.9587155963302753\n",
      "test: loss=0.335084981257372 acc=0.9059633027522935\n",
      "EPOCH=2824\n",
      "train: loss=0.24192389544427945 acc=0.9380733944954128\n",
      "test: loss=0.3423085337220513 acc=0.8967889908256881\n",
      "EPOCH=2825\n",
      "train: loss=0.20967456274795226 acc=0.9288990825688074\n",
      "test: loss=0.31413098788375604 acc=0.908256880733945\n",
      "EPOCH=2826\n",
      "train: loss=0.06134854900240174 acc=0.9770642201834863\n",
      "test: loss=0.37208565203195915 acc=0.9105504587155964\n",
      "EPOCH=2827\n",
      "train: loss=0.12426030533402684 acc=0.9655963302752294\n",
      "test: loss=0.27108717867831805 acc=0.9197247706422018\n",
      "EPOCH=2828\n",
      "train: loss=0.09010663852142083 acc=0.9747706422018348\n",
      "test: loss=0.31275918003596137 acc=0.9036697247706422\n",
      "EPOCH=2829\n",
      "train: loss=0.2013783920000855 acc=0.9518348623853211\n",
      "test: loss=0.3236575651269246 acc=0.9151376146788991\n",
      "EPOCH=2830\n",
      "train: loss=0.1974756782546125 acc=0.9403669724770642\n",
      "test: loss=0.30830059125855014 acc=0.908256880733945\n",
      "EPOCH=2831\n",
      "train: loss=0.05773052263792869 acc=0.9839449541284404\n",
      "test: loss=0.2552605619369372 acc=0.926605504587156\n",
      "EPOCH=2832\n",
      "train: loss=0.20769648790683098 acc=0.9564220183486238\n",
      "test: loss=0.3715597954145457 acc=0.9036697247706422\n",
      "EPOCH=2833\n",
      "train: loss=0.25387249859560473 acc=0.9220183486238532\n",
      "test: loss=0.3020625699621708 acc=0.9151376146788991\n",
      "EPOCH=2834\n",
      "train: loss=0.17557529008852718 acc=0.9334862385321101\n",
      "test: loss=0.25681928384096964 acc=0.9220183486238532\n",
      "EPOCH=2835\n",
      "train: loss=0.0733552080756813 acc=0.981651376146789\n",
      "test: loss=0.34455649237336344 acc=0.908256880733945\n",
      "EPOCH=2836\n",
      "train: loss=0.12049742160027026 acc=0.9678899082568807\n",
      "test: loss=0.4128204244370124 acc=0.8876146788990825\n",
      "EPOCH=2837\n",
      "train: loss=0.19409707709418364 acc=0.9518348623853211\n",
      "test: loss=0.3810369174025682 acc=0.8899082568807339\n",
      "EPOCH=2838\n",
      "train: loss=0.2423321161886379 acc=0.9357798165137615\n",
      "test: loss=0.29166513335799094 acc=0.9151376146788991\n",
      "EPOCH=2839\n",
      "train: loss=0.20340546733492212 acc=0.9541284403669725\n",
      "test: loss=0.2959908546769459 acc=0.9151376146788991\n",
      "EPOCH=2840\n",
      "train: loss=0.17326091889162337 acc=0.944954128440367\n",
      "test: loss=0.26463692839452624 acc=0.926605504587156\n",
      "EPOCH=2841\n",
      "train: loss=0.24438389716831152 acc=0.9495412844036697\n",
      "test: loss=0.24964012562461727 acc=0.9197247706422018\n",
      "EPOCH=2842\n",
      "train: loss=0.1372026204369107 acc=0.9610091743119266\n",
      "test: loss=0.23211378929511695 acc=0.9288990825688074\n",
      "EPOCH=2843\n",
      "train: loss=0.16438608721748718 acc=0.9495412844036697\n",
      "test: loss=0.38657240119737224 acc=0.8967889908256881\n",
      "EPOCH=2844\n",
      "train: loss=0.1290647980131108 acc=0.9518348623853211\n",
      "test: loss=0.3069727744643206 acc=0.9151376146788991\n",
      "EPOCH=2845\n",
      "train: loss=0.2198856608143996 acc=0.9495412844036697\n",
      "test: loss=0.2935823824155001 acc=0.9174311926605505\n",
      "EPOCH=2846\n",
      "train: loss=0.1074952170008291 acc=0.9678899082568807\n",
      "test: loss=0.33529546517438263 acc=0.9013761467889908\n",
      "EPOCH=2847\n",
      "train: loss=0.10307813425338294 acc=0.9724770642201835\n",
      "test: loss=0.3324329945503858 acc=0.9128440366972477\n",
      "EPOCH=2848\n",
      "train: loss=0.11077696776332921 acc=0.9747706422018348\n",
      "test: loss=0.3072231140997873 acc=0.9128440366972477\n",
      "EPOCH=2849\n",
      "train: loss=0.15392375898555144 acc=0.9541284403669725\n",
      "test: loss=0.3521890107869496 acc=0.9013761467889908\n",
      "EPOCH=2850\n",
      "train: loss=0.2523282902209106 acc=0.9380733944954128\n",
      "test: loss=0.2634070548099287 acc=0.9243119266055045\n",
      "EPOCH=2851\n",
      "train: loss=0.25086577765954166 acc=0.9380733944954128\n",
      "test: loss=0.369547155597093 acc=0.9036697247706422\n",
      "EPOCH=2852\n",
      "train: loss=0.11572060772795258 acc=0.963302752293578\n",
      "test: loss=0.28347189730235406 acc=0.9334862385321101\n",
      "EPOCH=2853\n",
      "train: loss=0.2870107624159306 acc=0.9334862385321101\n",
      "test: loss=0.3780834921371941 acc=0.9059633027522935\n",
      "EPOCH=2854\n",
      "train: loss=0.10125776682567501 acc=0.9724770642201835\n",
      "test: loss=0.27833789907842593 acc=0.9197247706422018\n",
      "EPOCH=2855\n",
      "train: loss=0.25780498091987647 acc=0.9243119266055045\n",
      "test: loss=0.24841207560581866 acc=0.9220183486238532\n",
      "EPOCH=2856\n",
      "train: loss=0.24706998933124835 acc=0.9288990825688074\n",
      "test: loss=0.3084975200062887 acc=0.9151376146788991\n",
      "EPOCH=2857\n",
      "train: loss=0.1480279014172162 acc=0.9587155963302753\n",
      "test: loss=0.27960234068230766 acc=0.9243119266055045\n",
      "EPOCH=2858\n",
      "train: loss=0.24222239074850227 acc=0.9288990825688074\n",
      "test: loss=0.35927449253229155 acc=0.9036697247706422\n",
      "EPOCH=2859\n",
      "train: loss=0.28909840702426215 acc=0.9288990825688074\n",
      "test: loss=0.33591102669820866 acc=0.9197247706422018\n",
      "EPOCH=2860\n",
      "train: loss=0.17833421484007284 acc=0.944954128440367\n",
      "test: loss=0.39144404710145614 acc=0.9220183486238532\n",
      "EPOCH=2861\n",
      "train: loss=0.15660046209977785 acc=0.9541284403669725\n",
      "test: loss=0.3402727754088234 acc=0.908256880733945\n",
      "EPOCH=2862\n",
      "train: loss=0.14007567273930221 acc=0.9495412844036697\n",
      "test: loss=0.3051948330652738 acc=0.908256880733945\n",
      "EPOCH=2863\n",
      "train: loss=0.2919859153466065 acc=0.9472477064220184\n",
      "test: loss=0.19576909624200586 acc=0.9403669724770642\n",
      "EPOCH=2864\n",
      "train: loss=0.16390136536390998 acc=0.9541284403669725\n",
      "test: loss=0.2807326111842063 acc=0.9334862385321101\n",
      "EPOCH=2865\n",
      "train: loss=0.10673043645158975 acc=0.9724770642201835\n",
      "test: loss=0.46585215314865724 acc=0.8876146788990825\n",
      "EPOCH=2866\n",
      "train: loss=0.29573903602315965 acc=0.9174311926605505\n",
      "test: loss=0.3432950636172905 acc=0.9197247706422018\n",
      "EPOCH=2867\n",
      "train: loss=0.14122373582083156 acc=0.9518348623853211\n",
      "test: loss=0.3320208357506764 acc=0.9036697247706422\n",
      "EPOCH=2868\n",
      "train: loss=0.14967822260934205 acc=0.9655963302752294\n",
      "test: loss=0.29408469196951176 acc=0.9151376146788991\n",
      "EPOCH=2869\n",
      "train: loss=0.11917990556443579 acc=0.9564220183486238\n",
      "test: loss=0.2571038566461254 acc=0.9174311926605505\n",
      "EPOCH=2870\n",
      "train: loss=0.18916641578714308 acc=0.9472477064220184\n",
      "test: loss=0.3046635114985325 acc=0.9151376146788991\n",
      "EPOCH=2871\n",
      "train: loss=0.18436308203365384 acc=0.9426605504587156\n",
      "test: loss=0.3164157917357522 acc=0.9036697247706422\n",
      "EPOCH=2872\n",
      "train: loss=0.2434522984527071 acc=0.944954128440367\n",
      "test: loss=0.2879487131483072 acc=0.9243119266055045\n",
      "EPOCH=2873\n",
      "train: loss=0.17167770565476612 acc=0.9587155963302753\n",
      "test: loss=0.21287983682119513 acc=0.926605504587156\n",
      "EPOCH=2874\n",
      "train: loss=0.16979342237597672 acc=0.9587155963302753\n",
      "test: loss=0.3359334046763039 acc=0.9013761467889908\n",
      "EPOCH=2875\n",
      "train: loss=0.10931113348409396 acc=0.9655963302752294\n",
      "test: loss=0.3597859058380462 acc=0.8967889908256881\n",
      "EPOCH=2876\n",
      "train: loss=0.15480592410990243 acc=0.9518348623853211\n",
      "test: loss=0.29460692173080216 acc=0.9013761467889908\n",
      "EPOCH=2877\n",
      "train: loss=0.3048041732693726 acc=0.9220183486238532\n",
      "test: loss=0.28740415949008863 acc=0.9380733944954128\n",
      "EPOCH=2878\n",
      "train: loss=0.19174310032073966 acc=0.9495412844036697\n",
      "test: loss=0.40951621739071814 acc=0.8967889908256881\n",
      "EPOCH=2879\n",
      "train: loss=0.15984455173285528 acc=0.9564220183486238\n",
      "test: loss=0.31598873802781924 acc=0.9128440366972477\n",
      "EPOCH=2880\n",
      "train: loss=0.15860242736536373 acc=0.9564220183486238\n",
      "test: loss=0.2902297849820478 acc=0.9197247706422018\n",
      "EPOCH=2881\n",
      "train: loss=0.32615924890669395 acc=0.9380733944954128\n",
      "test: loss=0.27412436489446257 acc=0.926605504587156\n",
      "EPOCH=2882\n",
      "train: loss=0.20861496383363687 acc=0.9403669724770642\n",
      "test: loss=0.33779513057756977 acc=0.9128440366972477\n",
      "EPOCH=2883\n",
      "train: loss=0.20849071653654785 acc=0.9472477064220184\n",
      "test: loss=0.3045280205622704 acc=0.908256880733945\n",
      "EPOCH=2884\n",
      "train: loss=0.24176526605644658 acc=0.9403669724770642\n",
      "test: loss=0.300387968225274 acc=0.9128440366972477\n",
      "EPOCH=2885\n",
      "train: loss=0.12814803181572976 acc=0.9655963302752294\n",
      "test: loss=0.3595096749260235 acc=0.9013761467889908\n",
      "EPOCH=2886\n",
      "train: loss=0.137327961070955 acc=0.9678899082568807\n",
      "test: loss=0.3422903770816548 acc=0.9059633027522935\n",
      "EPOCH=2887\n",
      "train: loss=0.15986121915660487 acc=0.9587155963302753\n",
      "test: loss=0.2459483943851572 acc=0.9197247706422018\n",
      "EPOCH=2888\n",
      "train: loss=0.222678675209532 acc=0.9357798165137615\n",
      "test: loss=0.33774650375153065 acc=0.9105504587155964\n",
      "EPOCH=2889\n",
      "train: loss=0.15902581586822975 acc=0.9541284403669725\n",
      "test: loss=0.3362313148174789 acc=0.9128440366972477\n",
      "EPOCH=2890\n",
      "train: loss=0.3508113154916328 acc=0.908256880733945\n",
      "test: loss=0.3131788768874871 acc=0.9105504587155964\n",
      "EPOCH=2891\n",
      "train: loss=0.23167186326673356 acc=0.9311926605504587\n",
      "test: loss=0.3735516741089251 acc=0.9105504587155964\n",
      "EPOCH=2892\n",
      "train: loss=0.13812864349307308 acc=0.9678899082568807\n",
      "test: loss=0.4640354528484902 acc=0.8899082568807339\n",
      "EPOCH=2893\n",
      "train: loss=0.05516007805097784 acc=0.9839449541284404\n",
      "test: loss=0.28656387266857075 acc=0.9197247706422018\n",
      "EPOCH=2894\n",
      "train: loss=0.33779655970449296 acc=0.9197247706422018\n",
      "test: loss=0.25002018182433494 acc=0.926605504587156\n",
      "EPOCH=2895\n",
      "train: loss=0.20604882721534368 acc=0.9426605504587156\n",
      "test: loss=0.3602369895025221 acc=0.9059633027522935\n",
      "EPOCH=2896\n",
      "train: loss=0.26867431298712746 acc=0.9311926605504587\n",
      "test: loss=0.3473946507583119 acc=0.9128440366972477\n",
      "EPOCH=2897\n",
      "train: loss=0.10542550288851908 acc=0.963302752293578\n",
      "test: loss=0.32212570501262283 acc=0.9059633027522935\n",
      "EPOCH=2898\n",
      "train: loss=0.10902653701753265 acc=0.9655963302752294\n",
      "test: loss=0.4504123778486641 acc=0.8853211009174312\n",
      "EPOCH=2899\n",
      "train: loss=0.2056924480918062 acc=0.9564220183486238\n",
      "test: loss=0.2982813298614599 acc=0.9105504587155964\n",
      "EPOCH=2900\n",
      "train: loss=0.2593285078155739 acc=0.9174311926605505\n",
      "test: loss=0.39224933723398336 acc=0.9036697247706422\n",
      "EPOCH=2901\n",
      "train: loss=0.13496050200364754 acc=0.9541284403669725\n",
      "test: loss=0.30696209062941976 acc=0.8990825688073395\n",
      "EPOCH=2902\n",
      "train: loss=0.23543319251103273 acc=0.9357798165137615\n",
      "test: loss=0.4404467127562154 acc=0.8944954128440367\n",
      "EPOCH=2903\n",
      "train: loss=0.19720728619426522 acc=0.9495412844036697\n",
      "test: loss=0.2989916938676607 acc=0.9151376146788991\n",
      "EPOCH=2904\n",
      "train: loss=0.1379055171645241 acc=0.9610091743119266\n",
      "test: loss=0.29919576746547216 acc=0.9151376146788991\n",
      "EPOCH=2905\n",
      "train: loss=0.20734555965883897 acc=0.9518348623853211\n",
      "test: loss=0.4472855815820998 acc=0.9036697247706422\n",
      "EPOCH=2906\n",
      "train: loss=0.19794706483927418 acc=0.9403669724770642\n",
      "test: loss=0.37890760321967537 acc=0.8990825688073395\n",
      "EPOCH=2907\n",
      "train: loss=0.05614486933784542 acc=0.981651376146789\n",
      "test: loss=0.3288790330004183 acc=0.9128440366972477\n",
      "EPOCH=2908\n",
      "train: loss=0.17082837071463078 acc=0.9334862385321101\n",
      "test: loss=0.41473061059428296 acc=0.8944954128440367\n",
      "EPOCH=2909\n",
      "train: loss=0.20935217514089202 acc=0.9403669724770642\n",
      "test: loss=0.3046479627821082 acc=0.9174311926605505\n",
      "EPOCH=2910\n",
      "train: loss=0.2510689635412168 acc=0.926605504587156\n",
      "test: loss=0.34424703532646367 acc=0.9105504587155964\n",
      "EPOCH=2911\n",
      "train: loss=0.11406340923566947 acc=0.9724770642201835\n",
      "test: loss=0.31311595152487776 acc=0.9243119266055045\n",
      "EPOCH=2912\n",
      "train: loss=0.15085558673262847 acc=0.9610091743119266\n",
      "test: loss=0.33942834413692713 acc=0.9059633027522935\n",
      "EPOCH=2913\n",
      "train: loss=0.23473550944502022 acc=0.9311926605504587\n",
      "test: loss=0.3652278837991612 acc=0.8990825688073395\n",
      "EPOCH=2914\n",
      "train: loss=0.21311667875702328 acc=0.9495412844036697\n",
      "test: loss=0.36528543635833194 acc=0.8990825688073395\n",
      "EPOCH=2915\n",
      "train: loss=0.14755447680060166 acc=0.9541284403669725\n",
      "test: loss=0.36602602253640637 acc=0.9059633027522935\n",
      "EPOCH=2916\n",
      "train: loss=0.13537844758336964 acc=0.9426605504587156\n",
      "test: loss=0.33401877120651763 acc=0.9059633027522935\n",
      "EPOCH=2917\n",
      "train: loss=0.1996380429196744 acc=0.9541284403669725\n",
      "test: loss=0.38205307858747567 acc=0.8990825688073395\n",
      "EPOCH=2918\n",
      "train: loss=0.1967056889558203 acc=0.9334862385321101\n",
      "test: loss=0.32443742169762035 acc=0.9128440366972477\n",
      "EPOCH=2919\n",
      "train: loss=0.15773352142937902 acc=0.963302752293578\n",
      "test: loss=0.3550896266244828 acc=0.9105504587155964\n",
      "EPOCH=2920\n",
      "train: loss=0.23659931459030423 acc=0.9403669724770642\n",
      "test: loss=0.28134998413614254 acc=0.9174311926605505\n",
      "EPOCH=2921\n",
      "train: loss=0.08540039141991648 acc=0.9678899082568807\n",
      "test: loss=0.2893953269531854 acc=0.926605504587156\n",
      "EPOCH=2922\n",
      "train: loss=0.12873784145283945 acc=0.9701834862385321\n",
      "test: loss=0.28539773468622326 acc=0.9059633027522935\n",
      "EPOCH=2923\n",
      "train: loss=0.2307780466696243 acc=0.9243119266055045\n",
      "test: loss=0.2887833672369297 acc=0.9174311926605505\n",
      "EPOCH=2924\n",
      "train: loss=0.24909999254157722 acc=0.926605504587156\n",
      "test: loss=0.3399245951572805 acc=0.9243119266055045\n",
      "EPOCH=2925\n",
      "train: loss=0.3919631607268918 acc=0.9059633027522935\n",
      "test: loss=0.22973011712725744 acc=0.9334862385321101\n",
      "EPOCH=2926\n",
      "train: loss=0.24140884674500604 acc=0.944954128440367\n",
      "test: loss=0.3127277911113362 acc=0.9059633027522935\n",
      "EPOCH=2927\n",
      "train: loss=0.2531042851477169 acc=0.9220183486238532\n",
      "test: loss=0.3629463236333199 acc=0.9059633027522935\n",
      "EPOCH=2928\n",
      "train: loss=0.1853162737536655 acc=0.9495412844036697\n",
      "test: loss=0.39675187864039213 acc=0.9174311926605505\n",
      "EPOCH=2929\n",
      "train: loss=0.156827162892345 acc=0.9541284403669725\n",
      "test: loss=0.32475715900239555 acc=0.9128440366972477\n",
      "EPOCH=2930\n",
      "train: loss=0.11915815724602005 acc=0.9655963302752294\n",
      "test: loss=0.27534900708553445 acc=0.9220183486238532\n",
      "EPOCH=2931\n",
      "train: loss=0.1282784986257966 acc=0.9495412844036697\n",
      "test: loss=0.3475692092308488 acc=0.9059633027522935\n",
      "EPOCH=2932\n",
      "train: loss=0.25561281027182353 acc=0.9472477064220184\n",
      "test: loss=0.419660711120577 acc=0.8967889908256881\n",
      "EPOCH=2933\n",
      "train: loss=0.22794296962396554 acc=0.9403669724770642\n",
      "test: loss=0.27110529971428216 acc=0.9288990825688074\n",
      "EPOCH=2934\n",
      "train: loss=0.18059246204853266 acc=0.9495412844036697\n",
      "test: loss=0.2602045424804739 acc=0.9220183486238532\n",
      "EPOCH=2935\n",
      "train: loss=0.21771715001218342 acc=0.9334862385321101\n",
      "test: loss=0.32904837178479796 acc=0.9174311926605505\n",
      "EPOCH=2936\n",
      "train: loss=0.14990992798107758 acc=0.9655963302752294\n",
      "test: loss=0.3540898750727842 acc=0.9151376146788991\n",
      "EPOCH=2937\n",
      "train: loss=0.09266600078580646 acc=0.9747706422018348\n",
      "test: loss=0.4125077747723969 acc=0.8967889908256881\n",
      "EPOCH=2938\n",
      "train: loss=0.07874309224384768 acc=0.9655963302752294\n",
      "test: loss=0.4212749299850704 acc=0.8990825688073395\n",
      "EPOCH=2939\n",
      "train: loss=0.17497369773761381 acc=0.9495412844036697\n",
      "test: loss=0.30308439241460267 acc=0.9105504587155964\n",
      "EPOCH=2940\n",
      "train: loss=0.17766629157539646 acc=0.9541284403669725\n",
      "test: loss=0.4217916681626867 acc=0.8967889908256881\n",
      "EPOCH=2941\n",
      "train: loss=0.2823922473582252 acc=0.9197247706422018\n",
      "test: loss=0.33700157266181124 acc=0.9197247706422018\n",
      "EPOCH=2942\n",
      "train: loss=0.12036120614876102 acc=0.963302752293578\n",
      "test: loss=0.3157778761195796 acc=0.9243119266055045\n",
      "EPOCH=2943\n",
      "train: loss=0.24888467252397786 acc=0.9311926605504587\n",
      "test: loss=0.29683826495767496 acc=0.9128440366972477\n",
      "EPOCH=2944\n",
      "train: loss=0.12729950194420672 acc=0.9587155963302753\n",
      "test: loss=0.3417015277220052 acc=0.9128440366972477\n",
      "EPOCH=2945\n",
      "train: loss=0.30004346671271304 acc=0.9426605504587156\n",
      "test: loss=0.29196906691556235 acc=0.908256880733945\n",
      "EPOCH=2946\n",
      "train: loss=0.07579873852197319 acc=0.9701834862385321\n",
      "test: loss=0.27602085167691726 acc=0.9197247706422018\n",
      "EPOCH=2947\n",
      "train: loss=0.08763457247254824 acc=0.9724770642201835\n",
      "test: loss=0.37041517313929734 acc=0.9059633027522935\n",
      "EPOCH=2948\n",
      "train: loss=0.12271230351360933 acc=0.963302752293578\n",
      "test: loss=0.32341013864790735 acc=0.8990825688073395\n",
      "EPOCH=2949\n",
      "train: loss=0.2933554693333413 acc=0.9174311926605505\n",
      "test: loss=0.3405926217105567 acc=0.8967889908256881\n",
      "EPOCH=2950\n",
      "train: loss=0.126606423792905 acc=0.9587155963302753\n",
      "test: loss=0.3672508025797362 acc=0.9036697247706422\n",
      "EPOCH=2951\n",
      "train: loss=0.2561189977558903 acc=0.9243119266055045\n",
      "test: loss=0.2987594493908436 acc=0.9197247706422018\n",
      "EPOCH=2952\n",
      "train: loss=0.1708115643091257 acc=0.9610091743119266\n",
      "test: loss=0.38744360834297026 acc=0.9059633027522935\n",
      "EPOCH=2953\n",
      "train: loss=0.16179268072834968 acc=0.944954128440367\n",
      "test: loss=0.3883989045818043 acc=0.9036697247706422\n",
      "EPOCH=2954\n",
      "train: loss=0.13825817441786786 acc=0.9518348623853211\n",
      "test: loss=0.38591622564992356 acc=0.9036697247706422\n",
      "EPOCH=2955\n",
      "train: loss=0.13824033537746885 acc=0.9655963302752294\n",
      "test: loss=0.3567290711462308 acc=0.9128440366972477\n",
      "EPOCH=2956\n",
      "train: loss=0.11230881641974019 acc=0.9724770642201835\n",
      "test: loss=0.3448994003183726 acc=0.9036697247706422\n",
      "EPOCH=2957\n",
      "train: loss=0.22114663099807172 acc=0.9403669724770642\n",
      "test: loss=0.31645626795677373 acc=0.9105504587155964\n",
      "EPOCH=2958\n",
      "train: loss=0.2330128071626458 acc=0.9472477064220184\n",
      "test: loss=0.38567857070992617 acc=0.9013761467889908\n",
      "EPOCH=2959\n",
      "train: loss=0.22691095059947428 acc=0.9495412844036697\n",
      "test: loss=0.3565805824782741 acc=0.908256880733945\n",
      "EPOCH=2960\n",
      "train: loss=0.08335361940965613 acc=0.9724770642201835\n",
      "test: loss=0.352836494297129 acc=0.908256880733945\n",
      "EPOCH=2961\n",
      "train: loss=0.09499473207181955 acc=0.9655963302752294\n",
      "test: loss=0.3672321872569183 acc=0.9013761467889908\n",
      "EPOCH=2962\n",
      "train: loss=0.10209965421522722 acc=0.9701834862385321\n",
      "test: loss=0.3036552741479588 acc=0.9059633027522935\n",
      "EPOCH=2963\n",
      "train: loss=0.16915640104417726 acc=0.9587155963302753\n",
      "test: loss=0.3118378849445605 acc=0.9128440366972477\n",
      "EPOCH=2964\n",
      "train: loss=0.17779308255624574 acc=0.9587155963302753\n",
      "test: loss=0.30278640297958576 acc=0.9197247706422018\n",
      "EPOCH=2965\n",
      "train: loss=0.11494804706488525 acc=0.963302752293578\n",
      "test: loss=0.28991932359513445 acc=0.9243119266055045\n",
      "EPOCH=2966\n",
      "train: loss=0.3789001926498017 acc=0.9036697247706422\n",
      "test: loss=0.39217628632034446 acc=0.8944954128440367\n",
      "EPOCH=2967\n",
      "train: loss=0.20297891649468494 acc=0.9403669724770642\n",
      "test: loss=0.3505467382853005 acc=0.9013761467889908\n",
      "EPOCH=2968\n",
      "train: loss=0.13526885211037104 acc=0.9518348623853211\n",
      "test: loss=0.3081478477058539 acc=0.9174311926605505\n",
      "EPOCH=2969\n",
      "train: loss=0.43824531604509853 acc=0.8761467889908257\n",
      "test: loss=0.3955711413111543 acc=0.8876146788990825\n",
      "EPOCH=2970\n",
      "train: loss=0.1723851647428065 acc=0.944954128440367\n",
      "test: loss=0.29414976148259225 acc=0.9128440366972477\n",
      "EPOCH=2971\n",
      "train: loss=0.2895008947826663 acc=0.9220183486238532\n",
      "test: loss=0.3185168871225507 acc=0.9197247706422018\n",
      "EPOCH=2972\n",
      "train: loss=0.18611665541895936 acc=0.9426605504587156\n",
      "test: loss=0.29095539941945947 acc=0.908256880733945\n",
      "EPOCH=2973\n",
      "train: loss=0.19648445186992874 acc=0.9518348623853211\n",
      "test: loss=0.24603093678320356 acc=0.9151376146788991\n",
      "EPOCH=2974\n",
      "train: loss=0.15826671850273155 acc=0.9495412844036697\n",
      "test: loss=0.2798982392831815 acc=0.9220183486238532\n",
      "EPOCH=2975\n",
      "train: loss=0.4283512854694984 acc=0.8990825688073395\n",
      "test: loss=0.35921431785191166 acc=0.9013761467889908\n",
      "EPOCH=2976\n",
      "train: loss=0.3184305756201408 acc=0.9128440366972477\n",
      "test: loss=0.31068774160758117 acc=0.9174311926605505\n",
      "EPOCH=2977\n",
      "train: loss=0.0965557331986622 acc=0.9724770642201835\n",
      "test: loss=0.3192735154713221 acc=0.9036697247706422\n",
      "EPOCH=2978\n",
      "train: loss=0.17221037558023508 acc=0.9587155963302753\n",
      "test: loss=0.3152199345867135 acc=0.9174311926605505\n",
      "EPOCH=2979\n",
      "train: loss=0.09146210512441072 acc=0.9724770642201835\n",
      "test: loss=0.20940114545612037 acc=0.9403669724770642\n",
      "EPOCH=2980\n",
      "train: loss=0.152204293500593 acc=0.9541284403669725\n",
      "test: loss=0.3496388806981545 acc=0.9036697247706422\n",
      "EPOCH=2981\n",
      "train: loss=0.22916801631692807 acc=0.9380733944954128\n",
      "test: loss=0.33799337692607656 acc=0.9174311926605505\n",
      "EPOCH=2982\n",
      "train: loss=0.106097774643892 acc=0.9701834862385321\n",
      "test: loss=0.26545545129122367 acc=0.9174311926605505\n",
      "EPOCH=2983\n",
      "train: loss=0.2427668228572721 acc=0.9220183486238532\n",
      "test: loss=0.3707829598687855 acc=0.908256880733945\n",
      "EPOCH=2984\n",
      "train: loss=0.17364203613230655 acc=0.9495412844036697\n",
      "test: loss=0.4943110381321644 acc=0.8990825688073395\n",
      "EPOCH=2985\n",
      "train: loss=0.06965349567798482 acc=0.9770642201834863\n",
      "test: loss=0.41249208653336533 acc=0.9059633027522935\n",
      "EPOCH=2986\n",
      "train: loss=0.18787450760783375 acc=0.9403669724770642\n",
      "test: loss=0.569544266407597 acc=0.8876146788990825\n",
      "EPOCH=2987\n",
      "train: loss=0.17954505061564136 acc=0.9472477064220184\n",
      "test: loss=0.43216359861741 acc=0.8990825688073395\n",
      "EPOCH=2988\n",
      "train: loss=0.13009298171113254 acc=0.9564220183486238\n",
      "test: loss=0.42636574604039423 acc=0.908256880733945\n",
      "EPOCH=2989\n",
      "train: loss=0.1727434948163881 acc=0.9380733944954128\n",
      "test: loss=0.36477839996699285 acc=0.8990825688073395\n",
      "EPOCH=2990\n",
      "train: loss=0.20085623308620254 acc=0.9587155963302753\n",
      "test: loss=0.35986589542245806 acc=0.9174311926605505\n",
      "EPOCH=2991\n",
      "train: loss=0.09422081455852652 acc=0.9701834862385321\n",
      "test: loss=0.37671005648943534 acc=0.908256880733945\n",
      "EPOCH=2992\n",
      "train: loss=0.18060815100494423 acc=0.9541284403669725\n",
      "test: loss=0.32003522242344074 acc=0.9059633027522935\n",
      "EPOCH=2993\n",
      "train: loss=0.13664909588027457 acc=0.9655963302752294\n",
      "test: loss=0.4868741601769135 acc=0.8876146788990825\n",
      "EPOCH=2994\n",
      "train: loss=0.26255689155402356 acc=0.9564220183486238\n",
      "test: loss=0.369020313337498 acc=0.9105504587155964\n",
      "EPOCH=2995\n",
      "train: loss=0.1401086306629797 acc=0.9701834862385321\n",
      "test: loss=0.37306304922241773 acc=0.8990825688073395\n",
      "EPOCH=2996\n",
      "train: loss=0.22390714668800027 acc=0.9357798165137615\n",
      "test: loss=0.3148684582254749 acc=0.9197247706422018\n",
      "EPOCH=2997\n",
      "train: loss=0.21747738237898687 acc=0.944954128440367\n",
      "test: loss=0.3998673398316173 acc=0.9059633027522935\n",
      "EPOCH=2998\n",
      "train: loss=0.2212416433789881 acc=0.9426605504587156\n",
      "test: loss=0.39365735522876855 acc=0.9013761467889908\n",
      "EPOCH=2999\n",
      "train: loss=0.14454275347297843 acc=0.9541284403669725\n",
      "test: loss=0.317664617958336 acc=0.9059633027522935\n",
      "EPOCH=3000\n",
      "train: loss=0.05878748800002245 acc=0.9747706422018348\n",
      "test: loss=0.42050646443645273 acc=0.9013761467889908\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "metrics_names = ['loss_train','loss_test','acc_train','acc_test']\n",
    "losses = []\n",
    "\n",
    "net.to(DEVICE)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(f'EPOCH={epoch + 1}')\n",
    "    for X, y in train_dl:\n",
    "        X = X.float().to(DEVICE)\n",
    "        y = y.long().to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = net(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        \n",
    "    train_ll, train_acc = evaluate_model(net, train_dl)\n",
    "    test_ll, test_acc = evaluate_model(net, test_dl)\n",
    "    \n",
    "    \n",
    "    print(f'train: loss={train_ll} acc={train_acc}')\n",
    "    print(f'test: loss={test_ll} acc={test_acc}')\n",
    "          \n",
    "    metrics.append([train_ll, test_ll, train_acc, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pd.DataFrame(metrics, columns=['train-loss','test-loss','train-acc','test-acc']).plot(subplots=False, figsize=(16,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), './model/sequence_classifier.pt')\n",
    "\n",
    "# m_state_dict = torch.load('mymodule.pt')\n",
    "# new_m = MyModule()\n",
    "# new_m.load_state_dict(m_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsr-dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
